% Manual for the SIESTA program
%
% To generate the printed version:
%
% latex siesta
% makeindex siesta    (Optional if you have a current siesta.ind)
% latex siesta
% [ dvips siesta ]
%
%
\documentclass[11pt]{article}
\usepackage{makeidx}
\usepackage{url}
\usepackage{hyperref}
\usepackage{hyperref}
% Hyperref setup
\hypersetup{
    hyperindex=true,
    bookmarksopen=true,
    bookmarksopenlevel=2,
}

\tolerance 10000
\textheight 22cm
\textwidth 16cm
\oddsidemargin 1mm
\topmargin -15mm

\makeindex

\parindent=0cm
\baselineskip=14pt
\parskip 5pt

\begin{document}

% TITLE PAGE --------------------------------------------------------------

\begin{titlepage}

\begin{center}

\vspace{1cm}
{\Huge {\sc U s e r' s \, \, G u i d e}}

\vspace{1cm}
\hrulefill
\vspace{1cm}

{\Huge {\bf S I E S T A \, \, 3.2}}

\vspace{1cm}
\hrulefill
\vspace{1cm}

{\Large March 24, 2013 }

\vspace{1.5cm}

\hbox{ \hskip 1.5cm
\begin{tabular}{ll}

{\Large Emilio Artacho} &
   \Large{\it University of Cambridge} \\ \\

{\Large Jos\'e Mar\'{\i}a Cela} &
   \Large{\it Barcelona Supercomputing Center} \\ \\

{\Large Julian D. Gale} &
   \Large{\it Curtin University of Technology, Perth} \\ \\

{\Large Alberto Garc\'{\i}a} &
   \Large{\it Institut de Ci\`encia de Materials, CSIC, Barcelona} \\ \\

{\Large Javier Junquera} &
   \Large{\it Universidad de Cantabria, Santander} \\ \\

{\Large Richard M. Martin} &
   \Large{\it University of Illinois at Urbana-Champaign} \\ \\

{\Large Pablo Ordej\'on} &
   \Large{\it Centre de Investigaci\'o en Nanoci\`encia} \\
                                 &
   \Large{\it   i Nanotecnologia, (CSIC-ICN), Barcelona} \\ \\

{\Large Daniel S\'anchez-Portal} &
   \Large{\it Unidad de F\'{\i}sica de Materiales,} \\
                                 &
   \Large{\it Centro Mixto CSIC-UPV/EHU, San Sebasti\'an} \\ \\

{\Large Jos\'e M. Soler} &
   \Large{\it Universidad Aut\'onoma de Madrid} \\ \\

\end{tabular}
}

\vspace{0.5cm}
{\Large {\tt http://www.uam.es/siesta} }

\vspace{0.5cm}
Copyright \copyright\  Fundaci\'on General Universidad Aut\'onoma de Madrid:
E.Artacho, J.D.Gale, A.Garc\'{\i}a, J.Junquera, P.Ordej\'on,
D.S\'anchez-Portal and J.M.Soler, 1996-2013

\end{center}

\end{titlepage}

% END TITLE PAGE --------------------------------------------------------------

\newpage

\tableofcontents

\newpage

\section{INTRODUCTION}

{\it This Reference Manual contains descriptions of all the input,
  output and execution features of {\sc Siesta}, but is not really a
  tutorial introduction to the program. The development team is
  planning a documentation overhaul that will address this
  shortcoming. In the meantime, interested users can find tutorial
  material prepared for {\sc Siesta} schools and workshops at the
  project's web page {\tt http://www.uam.es/siesta}}


{\sc Siesta}\index{Siesta@{\sc Siesta}} (Spanish Initiative for
Electronic Simulations with
Thousands of Atoms) is both a method and its computer program implementation,
to perform electronic structure calculations and {\it ab initio} molecular
dynamics simulations of molecules and solids. Its main characteristics are:
\begin{itemize}
\item
It uses the standard Kohn-Sham self-consistent density functional
method in the local density (LDA-LSD) or generalized gradient (GGA)
approximations.
\item
It uses norm-conserving pseudopotentials in their fully nonlocal
(Kleinman-Bylander) form.
\item
It uses atomic orbitals as a basis set, allowing unlimited multiple-zeta
and angular momenta, polarization and off-site orbitals. The radial
shape of every orbital is numerical and any shape can be used and provided
by the user, with the only condition that it has to be of finite support,
i.e., it has to be strictly zero beyond a user-provided distance from the
corresponding nucleus.
Finite-support basis sets are the key for calculating the Hamiltonian
and overlap matrices in $O(N)$ operations.
\item
Projects the electron wavefunctions and density onto a real-space
grid in order to calculate the Hartree and exchange-correlation
potentials and their matrix elements.
\item
Besides the standard Rayleigh-Ritz eigenstate method, it allows
the use of localized linear combinations of the occupied orbitals
(valence-bond or Wannier-like functions), making the computer
time and memory scale linearly with the number of atoms.
Simulations with several hundred atoms are feasible with
modest workstations.
\item
It is written in Fortran 95 and memory is allocated dynamically.
\item
It may be compiled for serial or parallel execution (under MPI).

\end{itemize}

It routinely provides:
\begin{itemize}
\item Total and partial energies.
\item Atomic forces.
\item Stress tensor.
\item Electric dipole moment.
\item Atomic, orbital and bond populations.
\item Electron density.
\end{itemize}

And also (though not all options are compatible):
\begin{itemize}
\item Geometry relaxation, fixed or variable cell.
\item Constant-temperature molecular dynamics (Nose thermostat).
\item Variable cell dynamics (Parrinello-Rahman).
\item Spin polarized calculations (collinear or not).
\item k-sampling of the Brillouin zone.
\item Local and orbital-projected density of states.
\item COOP and COHP curves for chemical bonding analysis.
\item Dielectric polarization.
\item Vibrations (phonons).
\item Band structure.
\item Ballistic electron transport (through {\sc TranSiesta})
\end{itemize}


Starting from version 3.0, {\sc Siesta} includes the {\sc
  TranSiesta}\index{TranSIESTA@{\sc TranSiesta}} module.  {\sc
  TranSiesta} provides the ability to model open-boundary systems
where ballistic electron transport is taking place.  Using {\sc
  TranSiesta} one can compute electronic transport properties, such as
the zero bias conductance and the I-V characteristic, of a nanoscale
system in contact with two electrodes at different electrochemical
potentials.  The method is based on using non equilibrium Green's
functions (NEGF), that are constructed using the density functional
theory Hamiltonian obtained from a given electron density. A new
density is computed using the NEGF formalism, which closes the
DFT-NEGF self consistent cycle.

For more details on the formalism, see the main {\sc TranSiesta}
reference cited below. A section has been added to this User's Guide,
that describes the necessary steps involved in doing transport
calculations, together with the currently implemented input options.

\vspace{0.5cm}
{\large {\bf References:} }

\begin{itemize}

\item
``Unconstrained minimization approach for electronic computations
that scales linearly with system size"
P. Ordej\'on, D. A. Drabold, M. P. Grumbach and R. M. Martin,
Phys. Rev. B {\bf 48}, 14646 (1993);
``Linear system-size methods for electronic-structure calculations"
Phys. Rev. B {\bf 51} 1456 (1995), and references therein.

Description of the order-{\it N} eigensolvers
implemented in this code.

\item
``Self-consistent order-$N$ density-functional
calculations for very large systems"
P. Ordej\'on, E. Artacho and J. M. Soler,
Phys. Rev. B {\bf 53}, 10441, (1996).

Description of a previous version of this methodology.

\item
``Density functional method for very large systems with LCAO basis sets"
D. S\'anchez-Portal, P. Ordej\'on, E. Artacho and J. M. Soler,
Int. J. Quantum Chem., {\bf 65}, 453 (1997).

Description of the present method and code.

\item
``Linear-scaling ab-initio calculations for large and complex systems"
E. Artacho, D. S\'anchez-Portal, P. Ordej\'on, A. Garc\'{\i}a and
J. M. Soler, Phys. Stat. Sol. (b) {\bf 215}, 809 (1999).

Description of the numerical atomic orbitals (NAOs) most commonly
used in the code, and brief review of applications as of March 1999.

\item
``Numerical atomic orbitals for linear-scaling calculations"
J. Junquera, O. Paz, D. S\'anchez-Portal, and E. Artacho, Phys. Rev. B
 {\bf 64}, 235111, (2001).

Improved, soft-confined NAOs.

\item
``The {\sc Siesta} method for ab initio order-$N$ materials simulation"
J. M. Soler, E. Artacho, J.D. Gale, A. Garc\'{\i}a, J. Junquera, P. Ordej\'on,
and D. S\'anchez-Portal, J. Phys.: Condens. Matter {\bf 14}, 2745-2779 (2002)

Extensive description of the {\sc Siesta} method.

\item
``Computing the properties of materials from first principles
with  {\sc Siesta}", D. S\'anchez-Portal, P. Ordej\'on,
and E. Canadell, Structure and Bonding {\bf 113},
103-170 (2004).

Extensive review of applications as of summer 2003.

\item
 ``Density-functional method for nonequilibrium electron transport'',
 Mads Brandbyge, Jose-Luis Mozos, Pablo Ordej\'on, Jeremy Taylor,
 and Kurt Stokbro, Phys. Rev. B {\bf 65}, 165401 (2002).

 Description of the {\sc TranSiesta} method.

\end{itemize}

For more information you can visit the web page
{\tt http://www.uam.es/siesta}.

\section{COMPILATION}

\subsection{The building directory}

Rather than using the top-level Src directory as building directory,
the user has to use an ad-hoc building directory (by default the
top-level {\tt Obj} directory, but it can be any (new) directory in
the top level).  The building directory will hold the object files,
module files, and libraries resulting from the compilation of the
sources in {\tt Src}.  The {\tt VPATH} mechanism of modern {\tt make}
programs is used. This scheme has many advantages. Among them:

\begin{itemize}
\item The Src directory is kept pristine.
\item Many different object directories can be used concurrently to
  compile the program with different compilers or optimization levels.
\end{itemize}

If you just want to compile the program, go to {\tt Obj} and issue the
command:

\begin{verbatim}
  sh ../Src/obj_setup.sh
\end{verbatim}

to populate this directory with the minimal scaffolding of makefiles,
and then make sure that you create or generate an appropriate {\tt arch.make}
file (see below, in Sect.~\ref{sec:arch-make}). Then, type

\begin{verbatim}
  make
\end{verbatim}

The executable should work for any job. (This is not exactly true,
since some of the parameters in the atomic routines are still
hardwired (see {\tt Src/atmparams.f}), but those would seldom need to
be changed.)

To compile utility programs (those living in {\tt Util}), you can just
simply use the provided makefiles, typing ``make'' as appropriate.

\subsubsection{Multiple-target compilation}

The mechanism described here can be repeated in other directories at
the same level as Obj, with different names. In this way one can
compile as many different versions of the {\sc Siesta} executable as
needed (for example, with different levels of optimization, serial,
parallel, debug, etc), by working in separate building directories.

Simply provide the appropriate arch.make, and issue the setup command
above. To compile utility programs, you need to use the form:

\begin{verbatim}
   make OBJDIR=ObjName
\end{verbatim}

where {\tt ObjName} is the name of the object directory of your
choice. Be sure to type {\tt make clean} before attempting to
re-compile a utility program.

(The pristine Src directory should be kept "clean", without objects, or else
the compilation in the build directories will get confused)


\subsection{The arch.make file}
\label{sec:arch-make}

The compilation of the program is done using a {\tt Makefile} that is
provided with the code.\index{Makefile} This {\tt Makefile} will
generate the executable for any of several architectures, with a
minimum of tuning required from the user and encapsulated in a
separate file called {\tt arch.make}.

You are strongly encouraged to look at {\tt
  Src/Sys/DOCUMENTED-TEMPLATE.make} for information about the fine
points of the {\tt arch.make} file. You can also get inspiration by
looking at the actual {\tt arch.make} examples in the {\tt Src/Sys}
subdirectory. If you intend to create a parallel version of {\sc
  Siesta}, make sure you have all the extra support libraries ({\tt
  MPI, scalapack, blacs...} (see Sect.~\ref{sec:parallel}).
  
One important compilation option is -DGRID\_DP, which tells the
compiler to use double precision arithmetic in grid-related arrays.
Unless you find memory problems running siesta, we strongly 
recommend it, and we will likely make it the default in future
versions. If you use GRID\_DP, please note that it is advantageous
to enable also PHI\_GRID\_SP, since the array that stores orbital
values on the grid can safely be kept in single precision, with significant
savings in memory and negligible numerical changes.


Optionally, the command {\tt ../Src/configure} will
start an automatic scan of your system and try to build an {\tt
  arch.make} for you. Please note that the configure script might need
some help in order to find your Fortran compiler, and that the created
{\tt arch.make} may not be optimal, mostly in regard to compiler
switches and preprocessor definitions, but the process should provide
a reasonable first version. Type {\tt ../Src/configure --help} to see
the flags understood by the script, and take a look at the {\tt
  Src/Confs} subdirectory for some examples of their explicit use.


\section{EXECUTION OF THE PROGRAM}

A fast way to test your installation of {\sc Siesta} and get a feeling
for the workings of the program is implemented in directory
{\tt Tests}\index{Tests}. In it you can find several subdirectories
with pre-packaged FDF files and pseudopotential references. Everything
is automated: after compiling {\sc Siesta} you can just go into any
subdirectory and type {\tt make}. The program does its work in
subdirectory {\tt work}, and there you can find all the resulting
files. For convenience, the output file is copied to the parent
directory. A collection of reference output files can be found in {\tt
  Tests/Reference}. Please note that small numerical and
formatting differences are to be expected, depending on the compiler.
(For non-standard execution environments, including queuing systems,
so can have a look at the Scripts in Tests/Scripts, and see also Sect.~\ref{sec:parallel}.)

Other examples are provided in the {\tt Examples} directory. This
directory contains basically {\tt .fdf} files and the appropriate
pseudopotential generation input files. Since at some point you will
have to generate your own pseudopotentials and run your own jobs, we
describe here the whole process by means of the simple example of the
water-molecule. It is advisable to create independent directories for
each job, so that everything is clean and neat, and out of the {\tt
siesta} directory, so that one can easily update version by replacing
the whole {\tt siesta} tree. Go to your favorite working directory
and:

{\tt \$ mkdir h2o}

{\tt \$ cd h2o}

{\tt \$ cp path-to-package/Examples/H2O/h2o.fdf .}

You need to make the siesta executable visible in your path. 
You can do it in many ways, but a simple one is

{\tt ln -s  path-to-package/Obj/siesta .}

\noindent
We need to generate the required pseudopotentials.
\index{pseudopotential!example generation}
(We are going to streamline this process for this time, but
you must realize that this is a tricky business that you
must master before using {\sc Siesta} responsibly. Every
pseudopotential must be thoroughly checked before use. Please refer to
the {\sc ATOM} program manual in {\tt Pseudo/atom/Docs}
for details regarding what follows.)

{\tt \$ cd path-to-package/Pseudo/atom}

{\tt \$ make}

{\tt \$ cd Tutorial/PS\_Generation/O}

{\tt \$ cat O.tm2.inp}

\noindent
This is the input file, for the oxygen pseudopotential,
that we have prepared for you.
It is in a standard (but ancient and obscure) format that
you will need to understand in the future:
\begin{verbatim}
------------------------------------------------------------
   pg      Oxygen
        tm2  2.0
 n=O  c=ca
       0.0       0.0       0.0       0.0       0.0       0.0
    1    4
    2    0     2.00      0.00
    2    1     4.00      0.00
    3    2     0.00      0.00
    4    3     0.00      0.00
   1.15     1.15     1.15     1.15
------------------------------------------------------------
\end{verbatim}

To generate the pseudopotential do the following;

{\tt \$ sh ../../Utils/pg.sh O.tm2.inp}

\noindent
Now there should be a new subdirectory called O.tm2 (O for oxygen)
and {\tt O.tm2.vps} (binary) and {\tt O.tm2.psf} (ASCII) files.

{\tt \$ cp O.tm2.psf path-to-working-dir/h2o/O.psf}

\noindent
copies the generated pseudopotential file to your working directory.
(The unformatted and ASCII files are functionally equivalent, but
the latter is more transportable and easier to look at, if you so
desire.) The same could be repeated for the pseudopotential for H,
but you may as well copy {\tt H.psf} from {\tt Examples/Vps/}
to your {\tt h2o} working directory.

\noindent
Now you are ready to run the program:

{\tt ./siesta < h2o.fdf | tee h2o.out}

\noindent
(If you are running the parallel version you should use some other
invocation, such as {\tt mpirun -np 2 siesta ...}, but we cannot
go into that here --- see Sect.~\ref{sec:parallel}).

After a successful run of the program, you should have several
files in your directory including the following:
\begin{itemize}

\item fdf.log\index{fdf.log}
 (contains all the data used, explicit or chosen by default)
\item O.ion and H.ion\index{species.ion@{\it species.}ion}
 (complete information about the basis and KB projectors)
\item h2o.XV\index{Systemlabel.XV@{\it Systemlabel.}XV}
 (contains positions and velocities)
\item h2o.STRUCT\_OUT
\index{Systemlabel.STRUCT\_OUT@{{\it Systemlabel}.STRUCT\_OUT}}
 (contains the final cell vectors and positions in
 ``crystallographic'' format)
\item h2o.DM\index{Systemlabel.DM@{\it Systemlabel.}DM}
 (contains the density matrix to allow a restart)
\item h2o.ANI\index{Systemlabel.ANI@{\it Systemlabel.}.ANI}
 (contains the coordinates of every MD step, in this case only one)
\item h2o.FA\index{Systemlabel.FA@{\it Systemlabel.}.FA}
 (contains the forces on the atoms)
\item h2o.EIG\index{Systemlabel.EIG@{\it Systemlabel.}.EIG}
 (contains the eigenvalues of the Kohn-Sham Hamiltonian)
\item h2o.xml\index{Systemlabel.xml@{\it Systemlabel.}xml}
 (XML marked-up output)
\end{itemize}

The prefix h2o of all these files is the 
{\tt SystemLabel}\index{Systemlabel}
specified in the input h2o.fdf file (see FDF section below).
The standard output of the program, that you
have already seen passing on the screen, was copied to
file h2o.out by the tee command. Have a look at it
and refer to the output-explanation section if necessary.
You may also want to look at the fdf.log\index{fdf.log} file to see all
the default values that siesta has chosen for you, before
studying the input-explanation section and start changing them.

Now look at the other data files in {\tt Examples}
(all with an .fdf suffix) choose one and repeat the process for it.

\section{THE FLEXIBLE DATA FORMAT (FDF)}\index{FDF}

The main input file,\index{input file}
which is read as the standard input (unit 5),
contains all the physical data of the system and the parameters of
the simulation to be performed.
This file is written in a special format called FDF, developed by
Alberto Garc\'{\i}a and Jos\'e M. Soler. This format allows data to be
given in any order, or to be omitted in favor of default values.
Refer to documentation in $\sim$/siesta/Src/fdf for details.
Here we offer a glimpse of it through the following rules:

\begin{itemize}

\item[$\bullet$] The FDF syntax is a 'data label' followed by its value.
Values that are not specified in the datafile are assigned
a default value.

\item[$\bullet$] FDF labels are case insensitive, and characters - \_ .
in a data label are ignored. Thus, LatticeConstant and
lattice\_constant represent the same label.

\item[$\bullet$] All text following the \# character is taken as comment.

\item[$\bullet$] Logical values can be specified as T, true, .true.,
yes, F, false, .false., no. Blank is also equivalent to true.

\item[$\bullet$] Character strings should {\bf not} be in apostrophes.

\item[$\bullet$] Real values which represent a physical magnitude must be
followed by its units. Look at function fdf\_convfac in
file $\sim$/siesta/Src/fdf/fdf.f for the units that are currently supported.
It is important to include a decimal point in a real number to distinguish
it from an integer, in order to prevent ambiguities when mixing the types
on the same input line.

\item[$\bullet$] Complex data structures are called blocks and are
placed between `\%block label'\index{block@\%block} and a `\%endblock label'
(without the quotes).

\item[$\bullet$] You may `include' other FDF files and redirect the search
for a particular data label to another file.
If a data label appears more than once, its first appearance
is used.

\item[$\bullet$] If the same label is specified twice, the first one takes precedence.

\item[$\bullet$] If a label is misspelled it will not be recognized (there is no
  internal list of ``accepted'' tags in the program). You can check 
  the actual value used by siesta by looking for the label in the
  output {\it fdf.log}\index{fdf.log} file.

\end{itemize}

\noindent
These are some examples:

\begin{verbatim}
           SystemName      Water molecule  # This is a comment
           SystemLabel     h2o
           SpinPolarized        yes
           SaveRho
           NumberOfAtoms         64
           LatticeConstant       5.42 Ang
           %block LatticeVectors
                    1.000  0.000  0.000
                    0.000  1.000  0.000
                    0.000  0.000  1.000
           %endblock LatticeVectors
           KgridCutoff < BZ_sampling.fdf

           # Reading the coordinates from a file
           %block AtomicCoordinatesAndAtomicSpecies < coordinates.data

           # Even reading more FDF information from somewhere else
           %include mydefaults.fdf
\end{verbatim}

The file {\it fdf.log} contains all the parameters used by {\sc Siesta}
in a given run, both those specified in the input fdf file and
those taken by default. They are written in fdf format, so that
you may reuse them as input directly. Input data blocks are
copied to the fdf.log file only if you specify the {\it dump} option
for them.

\section{PROGRAM OUTPUT}

\subsection{Standard output} \index{output!main output file}

{\sc Siesta} writes a log of its workings to standard output (unit 6),
which is usually redirected to an ``output file''.

A brief description follows. See the example cases in the
siesta/Tests directory for illustration.

The program starts writing the version of the code which is
used. Then, the input FDF file is dumped into the output file as is
(except for empty lines). The program does part of the reading and
digesting of the data at the beginning within the {\tt redata}
subroutine. It prints some of the information it digests. It is
important to note that it is only part of it, some other information
being accessed by the different subroutines when they need it during
the run (in the spirit of FDF input).  A complete list of the input
used by the code can be found at the end in the file {\tt fdf.log},
including defaults used by the code in the run.

After that, the program reads the pseudopotentials, factorizes them
into Kleinman-Bylander form, and generates (or reads) the atomic basis
set to be used in the simulation. These stages are documented in the
output file.

The simulation begins after that, the output showing information of
the MD (or CG) steps and the SCF cycles within.  Basic descriptions of
the process and results are presented. The user has the option to
customize it, however,\index{output!customization} by defining
different options that control the printing of informations like
coordinates, forces, $\vec k$ points, etc.  The options are discussed
in the appropriate sections, but take into account the behavior of the
legacy {\bf LongOutput} option, as in the current implementation might
silently activate output to the main .out file at the expense of
auxiliary files.

\begin{description}

\item[{\bf LongOutput}] ({\it logical}):
\index{LongOutput@{\bf LongOutput}}\index{output!long}
{\sc Siesta} can write to standard output different data sets
depending on the values for output options described below.
By default {\sc Siesta} will not write most of them. They can be
large for large systems (coordinates, eigenvalues, forces, etc.)
and, if written to standard output, they accumulate for all the steps of
the dynamics. {\sc Siesta} writes the information in other files
(see Output Files) in addition to the standard output, and these
can be cumulative or not.

Setting {\bf LongOutput} to {\tt .true.} changes the default of
some options, obtaining more information in the output (verbose).
In particular, it redefines the defaults for the following:

\begin{itemize}

\item
{\bf WriteKpoints}\index{WriteKpoints@{\bf WriteKpoints}}
\index{output!grid $\vec k$ points}
\item
{\bf WriteKbands}\index{WriteKbands@{\bf WriteKbands}}
\index{output!band $\vec k$ points}
\item
{\bf WriteCoorStep}\index{WriteCoorStep@{\bf WriteCoorStep}}
\index{output!atomic coordinates!in a dynamics step}
\item
{\bf WriteForces}\index{WriteForces@{\bf WriteForces}}
\index{output!forces}
\item
{\bf WriteEigenvalues}\index{WriteEigenvalues@{\bf WriteEigenvalues}}
\index{output!eigenvalues}
\item
{\bf WriteWaveFunctions}
\index{WriteWaveFunctions@{\bf WriteWaveFunctions}}
\index{output!wave functions}
\item
{\bf WriteMullikenPop}\index{WriteMullikenPop@{\bf WriteMullikenPop}}
\index{output!Mulliken analysis}\index{Mulliken population analysis}
(it sets it to 1)
\end{itemize}

The specific changing of any of these options overrides the
{\bf LongOutput} setting for it.

{\it Default value:} {\tt .false.}

\end{description}

\subsection{Output to dedicated files} \index{output!dedicated files}

{\sc Siesta} can produce a wealth of information in dedicated files,
with specific formats, that can be used for further analysis. See the
appropriate sections, and the appendix on file formats.
Please take into account the behavior of
{\bf LongOutput}, as in the current implementation might silently
activate output to the main .out file at the expense of auxiliary
files.

\section{DETAILED DESCRIPTION OF PROGRAM OPTIONS}


Here follows a description of the variables that you can define in
your {\sc Siesta} input file, with their data types and default
values. For historical reasons the names of the tags do not have an
uniform structure, and can be confusing at times.

Almost all of the tags are optional: {\sc Siesta} will assign a
default if a given tag is not found when needed (see {\tt fdf.log}).


\vspace{5pt}
\subsection{General system descriptors}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf SystemName}] ({\it string}):
\index{Systemname@{\bf SystemName}}
A string of one or several words containing a descriptive
name of the system (max. 150 characters).

{\it Default value:} blank

\item[{\bf SystemLabel}] ({\it string}):
\index{SystemLabel@{\bf SystemLabel}}
A {\bf single} word (max. 20 characters {\bf without blanks})
containing a nickname of the system, used to name output files.

{\it Default value:} {\tt siesta}\index{siesta}

\item[{\bf NumberOfSpecies}] ({\it integer}):
\index{NumberOfSpecies@{\bf NumberOfSpecies}}
Number of different atomic species in the simulation.
Atoms of the same species, but with a different
pseudopotential or basis set are counted as different species.

{\it Default value:} There is no default. You must supply this variable.

\item[{\bf NumberOfAtoms}] ({\it integer}):
\index{NumberOfAtoms@{\bf NumberOfAtoms}}
Number of atoms in the simulation.

{\it Default value:} There is no default. You must supply this variable.

\item[{\bf ChemicalSpeciesLabel}] ({\it data block}):
\index{ChemicalSpeciesLabel@{\bf ChemicalSpeciesLabel}}
It specifies the different chemical species\index{species} that are present,
assigning them a number for further identification.
{\sc Siesta} recognizes the different atoms by the given atomic number.

\begin{verbatim}
         %block Chemical_Species_label
            1   6   C
            2  14   Si
            3  14   Si_surface
         %endblock Chemical_Species_label
\end{verbatim}

The first number in a line is the species number, it is followed by the
atomic number, and then by the desired label. This label will be used
to identify corresponding files, namely, pseudopotential file, user basis
file, basis output file, and local pseudopotential output file.

This construction allows you to have atoms of the same species but with
different basis or pseudopotential, for example.

Negative atomic numbers are used for {\it ghost} atoms\index{ghost atoms}
(see {\bf PAO.basis}).

Atomic numbers over 200 are used to represent {\it synthetic atoms}
\index{synthetic atoms} (created for example as a ``mixture'' of two
real ones for a ``virtual crystal'' (VCA)\index{VCA} calculation). In
this special case a new 'SyntheticAtoms' block
\index{SyntheticAtoms@{\bf SyntheticAtoms}}  must be present to give
{\sc Siesta} information about the ``ground state'' of the synthetic
atom.

\begin{verbatim}
         %block Chemical_Species_label
            1   201 ON-0.50000
         %endblock Chemical_Species_label
         %block SyntheticAtoms
         1               # Species index
         2 2 3 4         # n numbers for valence states  with l=0,1,2,3
         2.0 3.5 0.0 0.0 # occupations of valence states with l=0,1,2,3
         %endblock SyntheticAtoms
\end{verbatim}

Pseudopotentials for synthetic atoms can be created using the {\tt
  mixps} and {\tt fractional} programs \index{mixps
  program}\index{fractional program} in the {\tt Util/VCA} directory.

{\it Use:} This block is mandatory.

{\it Default:} There is no default. You must supply this block.



\item[{\bf AtomicMass}] ({\it data block}):
\index{AtomicMass@{\bf AtomicMass}}
It allows the user to introduce
the atomic masses of the different species used in the calculation, useful
for the dynamics with isotopes,\index{isotopes} for example. If
a species index is not found within the block, the natural mass for the
corresponding atomic number is assumed. If the block is absent all masses
are the natural ones. One line per species with the species index (integer)
and the desired mass (real). The order is not important. If there is no
integer and/or no real numbers within the line, the line is disregarded.

\begin{verbatim}
         %block AtomicMass
            3  21.5
            1  3.2
         %endblock AtomicMass
\end{verbatim}

{\it Default:} (Block absent or empty) Natural masses assumed. For
{\it ghost} atoms (i.e. floating orbitals), a default of 1.d30 a.u. is
assigned.


\end{description}

\vspace{5pt}
\subsection{Pseudopotentials}
\index{pseudopotential!generation}

{\sc Siesta} uses pseudopotentials to represent the electron-ion
interaction (as do most plane-wave codes and in contrast to so-called
``all-electron'' programs). In particular, the pseudopotentials are of
the ``norm-conserving'' kind, and can be generated by the {\sc Atom} program,
included (with permission) in {\tt Pseudo/atom} (see {\tt
  Pseudo/atom/README} for more complete authorship and
copyright acknowledgements). Remember that {\bf all pseudopotentials
  should be thoroughly tested} before using them. We refer you to the
standard literature on pseudopotentials and to the {\sc ATOM} manual
{\tt siesta/Pseudo/atom/atom.tex} for more information. A number of
other codes (such as {\tt Opium}) can generate pseudopotentials that
{\sc Siesta} can use directly (typically in the {\tt .psf} format).

The pseudopotentials will be read by {\sc Siesta} from different files, one
for each defined species (species defined either in block
{\bf ChemicalSpeciesLabel}).\index{pseudopotential!files}
The name of the files should be:

{\it Chemical\_label}{\tt .vps} (unformatted) or
{\it Chemical\_label}{\tt .psf} (ASCII)

\noindent
where {\it Chemical\_label} corresponds to the label defined in the
{\bf ChemicalSpeciesLabel} block.

Siesta can also handle pseudopotential files in the XML format
designed by Junquera, Garcia, and Verstraete (to be published), which
enables interoperability with the ABINIT code. The directory
{\tt Util/pseudo-xml} contains a program to translate the pseudo
XML files to the {\tt .psf} form.


\vspace{5pt}
\subsection{Basis set and KB projectors}

\subsubsection{Overview of atomic-orbital bases implemented in {\sc Siesta}}

The main advantage of atomic orbitals is their efficiency (fewer orbitals
needed per electron for similar precision)
and their main disadvantage is the lack of systematics for optimal
convergence, an issue that quantum chemists have been working on for
many years. They have also clearly shown that there
is no limitation on precision intrinsic to LCAO.
This section provides some information about how basis sets can be
generated for {\sc Siesta}.

It is important to stress at this point that neither the {\sc Siesta}
method nor the program
are bound to the use of any particular kind of atomic orbitals. The
user can feed into {\sc Siesta} the atomic basis set he/she choses by
means of radial tables (see {\bf User.Basis} below), the
only limitations being: $(i)$ the functions have to be atomic-like (radial
functions mutiplied by spherical harmonics), and $(ii)$ they have to be
of finite support, i.e., each orbital becomes strictly zero beyond some
cutoff radius chosen by the user.

Most users, however, do not have their own basis sets. For these users
we have devised some schemes to generate basis sets within the program
with a minimum input from the user.  If nothing is specified in the
input file, Siesta generates a default basis set of a reasonable
quality that might constitute a good starting point.  Of course,
depending on the accuracy required in the particular problem, the user
has the degree of freedom to tune several parameters that can be
important for quality and efficiency. A description of these basis
sets and some performance tests can be found in the references quoted
below.

\noindent
``Numerical atomic orbitals for linear-scaling calculations",
J. Junquera, O. Paz, D. S\'anchez-Portal, and E. Artacho, Phys. Rev. B
{\bf 64}, 235111, (2001)

An important point here is that the basis set selection is a
variational problem and, therefore, minimizing the energy with respect
to any parameters defining the basis is an ``ab initio" way to
define them.

We have also devised a quite simple and systematic way of generating
basis sets based on specifying only one main parameter (the energy shift)
besides the basis size. It does not offer the best NAO results one can get
for a given basis size but it has the important advantages mentioned above.
More about it in:

\noindent
``Linear-scaling ab-initio calculations for large and complex systems",
E. Artacho, D. S\'anchez-Portal, P. Ordej\'on, A. Garc\'{\i}a and
J. M. Soler, Phys. Stat. Sol. (b) {\bf 215}, 809 (1999).

In addition to {\sc Siesta} we provide the program {\sc
Gen-basis}\index{Gen-basis@{\sc Gen-basis}}, which reads {\sc
Siesta}'s input and generates basis files for later use. {\sc
Gen-basis} can be found in {\tt Util/Gen-basis}.
It should be run from the {\tt Tutorials/Bases} directory,
using the {\tt gen-basis.sh} script. It is limited to a single species.

Of course, as it happens for the pseudopotential, it is the
responsibility of the user to check that the physical results obtained
are converged with respect to the basis set used before starting any
production run.

In the following we give some clues on the basics of the basis sets
that {\sc Siesta} generates.
  The starting point is always the solution of Kohn-Sham's Hamiltonian
for the isolated pseudo-atoms, solved in a radial grid,
with the same approximations as for the solid or molecule
(the same exchange-correlation functional and  pseudopotential),
plus some way of confinement (see below).
  We describe in the following three main features of a
basis set of atomic orbitals: size, range, and radial shape.

{\bf Size:} number of orbitals per atom

  Following the nomenclature of Quantum Chemistry, we establish
a hierarchy of basis sets, from single-$\zeta$ to multiple-$\zeta$
with polarization and diffuse orbitals, covering from quick calculations
of low quality to high precision, as high as the finest obtained in
Quantum Chemistry.
  A single-$\zeta$ (also called minimal) basis set (SZ in the following)
has one single radial function per angular momentum channel, and only for
those angular momenta with substantial electronic population in the valence of
the free atom.
  It offers quick calculations and some insight on qualitative trends
in the chemical bonding and other properties.
  It remains too rigid, however, for more quantitative calculations
requiring both radial and angular flexibilization.

  Starting by the radial flexibilization of SZ, a better basis is obtained
by adding a second function per channel: double-$\zeta$ (DZ).
  In Quantum Chemistry, the {\it split valence} scheme
is widely used: starting from the expansion in Gaussians of one atomic
orbital, the most contracted Gaussians are used to define the first
orbital of the double-$\zeta$ and the most extended ones for the second.
  For strictly localized functions there was a first proposal
of using the excited states of the confined atoms, but it would work only
for tight confinement (see {\bf PAO.BasisType} {\tt nodes} below).
  This construction was proposed and tested in D. S\'anchez-Portal
{\it et al.}, J. Phys.: Condens. Matter {\bf 8}, 3859-3880 (1996).

  We found that the basis set convergence is slow, requiring high levels
of multiple-$\zeta$ to achieve what other schemes do at the double-$\zeta$
level.
  This scheme is related with the basis sets used in the OpenMX project
[see T. Ozaki, Phys. Rev. B {\bf 67}, 155108 (2003); T. Ozaki and H. Kino,
Phys. Rev. B {\bf 69}, 195113 (2004)].

  We then proposed an extension of the split valence idea of Quantum Chemistry
to strictly localized NAO which has become the standard and has been used
quite successfully in many systems (see {\bf PAO.BasisType} {\tt split} below).
  It is based on the idea of suplementing the first $\zeta$ with, instead of
a gaussian, a numerical orbital that reproduces the tail of the original PAO
outside a matching radius $r_{m}$, and continues smoothly towards the origin as
$r^l(a-br^2)$, with $a$ and $b$ ensuring continuity and differentiability
at $r_{m}$.
  Within exactly the same
Hilbert space, the second orbital can be chosen to be the difference between
the smooth one and the original PAO, which gives a basis orbital strictly
confined within the matching radius $r_{m}$ (smaller than the
original PAO!) continuously differentiable throughout.

  Extra parameters have thus appeared: one $r_m$ per orbital to be doubled.
The user can again introduce them by hand (see {\bf PAO.Basis} below).
Alternatively, all the $r_m$'s can be defined at once by specifying
the value of the tail of the original PAO beyond $r_m$, the so-called
split norm. Variational optimization
of this split norm performed on different systems
shows a very general and stable performance for values around
15\% (except for the $\sim 50\%$ for hydrogen).
  It generalizes to multiple-$\zeta$ trivially by adding an additional
matching radius per new zeta.

Note: What is actually used is the norm of the tail {\em plus} the
norm of the parabola-like inner function.

Angular flexibility is obtained by adding shells of higher angular
momentum.  Ways to generate these so-called polarization orbitals have
been described in the literature for Gaussians.  For NAOs there are
two ways for {\sc Siesta} and {\sc Gen-basis} to generate them: $(i)$
Use atomic PAO's of higher angular momentum with suitable confinement,
and $(ii)$ solve the pseudoatom in the presence of an electric field
and obtain the $l+1$ orbitals from the perturbation of the $l$
orbitals by the field.

So-called diffuse orbitals, that might be important in the description
of open systems such as surfaces, can be simply added by specifying
extra ``n'' shells. [See S. Garcia-Gil, A. Garcia, N. Lorente,
  P. Ordejon, Phys. Rev. B {\bf 79}, 075441 (2009)]

Finally, the method allows the inclusion of off-site (ghost) orbitals
(not centered around any specific atom), useful for example in the
calculation of the counterpoise correction for basis-set superposition
errors.  Bessel functions for any radius and any excitation level can
also be added anywhere to the basis set.

{\bf Range:} cutoff radii of orbitals.

Strictly localized orbitals (zero beyond a cutoff radius) are used in
order to obtain sparse Hamiltonian and overlap matrices for linear
scaling. One cutoff radius per angular momentum channel has to be
given for each species.

A balanced and systematic starting point for defining all the
different radii is achieved by giving one single parameter, the energy
shift, i.e., the energy increase experienced by the orbital when confined.
Allowing for system and physical-quantity variablity, as a rule of
thumb $\Delta E_{\small \rm PAO} \approx 100$ meV gives typical
precisions within the accuracy of current GGA functionals.  The user
can, nevertheless, change the cutoff radii at will.

{\bf Shape}

Within the pseudopotential framework it is important to keep the
consistency between the pseudopotential and the form of the
pseudoatomic orbitals in the core region.  The shape of the orbitals
at larger radii depends on the cutoff radius (see above) and on the
way the localization is enforced.

The first proposal (and quite a standard among {\sc Siesta} users)
uses an infinite square-well potential.  It was originally proposed
and has been widely and successfully used by Otto Sankey and
collaborators, for minimal bases within the ab initio tight-binding
scheme, using the {\sc Fireball } program, but also for more flexible
bases using the methodology of {\sc Siesta}.  This scheme has the
disadavantage, however, of generating orbitals with a discontinuous
derivative at $r_c$.  This discontinuity is more pronounced for
smaller $r_c$'s and tends to disappear for long enough values of this
cutoff.  It does remain, however, appreciable for sensible values of
$r_c$ for those orbitals that would be very wide in the free atom.  It
is surprising how small an effect such a kink produces in the total
energy of condensed systems.  It is, on the other hand, a problem for
forces and stresses, especially if they are calculated using a
(coarse) finite three-dimensional grid.

Another problem of this scheme is related to its defining the basis
starting from the free atoms.  Free atoms can present extremely extended
orbitals, their extension being, besides problematic, of no practical
use for the calculation in condensed systems: the electrons far away
from the atom can be described by the basis functions of other atoms.

A traditional scheme to deal with this is one based on the radial
scaling of the orbitals by suitable scale factors.  In addition to
very basic bonding arguments, it is soundly based on restoring
the virial's theorem for finite bases, in the case of Coulombic potentials
(all-electron calculations).  The use of pseudopotentials limits its
applicability, allowing only for extremely small deviations from unity
($\sim 1\%$) in the scale factors obtained variationally (with the
exception of hydrogen that can contract up to 25\%). This possiblity
is available to the user.

Another way of dealing with the above problem and that of the kink at the
same time is adding a soft confinement potential to the atomic
Hamiltonian used to generate the basis orbitals: it smoothens the kink
and contracts the orbital as suited. Two additional parameters are
introduced for the purpose, which can be defined again variationally.
The confining potential is flat (zero) in the core region, starts off
at some internal radius $r_i$ with all derivatives continuous and
diverges at $r_c$ ensuring the strict localization there.  It is
\begin{equation}
  V(r) = V_{\rm o} { e^{- { {r_c - r_i} \over {r - r_i} } } \over {r_c -r} }
\end{equation}
and both $r_i$ and $V_{\rm o}$ can be given to {\sc Siesta} together
with $r_c$ in the input (see {\bf PAO.Basis} below).

Finally, the shape of an orbital is also changed by the ionic
character of the atom.  Orbitals in cations tend to shrink, and they
swell in anions.  Introducing a $\delta Q$ in the basis-generating
free-atom calculations gives orbitals better adapted to ionic
situations in the condensed systems.

More information about basis sets can be found in the proposed
literature.


\noindent

There are quite a number of options for the input of the basis-set and
KB projector specification, and they are all optional! By default,
{\sc Siesta} will use a DZP basis set with appropriate choices for the
determination of the range, etc. Of course, the more you experiment
with the different options, the better your basis set can get. To aid
in this process we offer an auxiliary program for optimization which
can be used in particular to obtain variationally optimal basis sets
(within a chosen basis size). See {\tt Util/Optimizer}
for general information, and {\tt Util/Optimizer/Examples/Basis\_Optim}
for an example. The directory {\tt Tutorials/Bases} in the main {\sc Siesta
distribution} contains some tutorial material for the generation of
basis sets and KB projectors.

Finally, some optimized basis sets for particular elements are
available at the {\sc Siesta} web page.  Again, it is the
responsability of the users to test the transferability of the basis
set to their problem under consideration.


\subsubsection{Type of basis sets}

\begin{description}

\item[{\bf PAO.BasisType}] ({\it string}):
\index{PAO.BasisType@{\bf PAO.BasisType}}
\index{basis!PAO}

The kind of basis to be generated is chosen. All are based on
finite-range pseudo-atomic orbitals\index{finite-range pseudo-atomic
orbitals} [PAO's of Sankey and Niklewsky, PRB 40, 3979 (1989)]. The
original PAO's were described only for minimal bases. {\sc Siesta}
generates extended bases (multiple-$\zeta$,\index{multiple-$\zeta$}
polarization,\index{polarization orbitals} and diffuse
orbitals\index{diffuse orbitals}) applying different schemes of choice:

\begin{itemize}

\item[-] Generalization of the PAO's: uses the excited orbitals of the
finite-range pseudo-atomic problem, both for multiple-$\zeta$ and for
polarization [see S\'anchez-Portal, Artacho, and Soler, JPCM {\bf 8},
3859 (1996)]. Adequate for short-range orbitals.

\item[-] Multiple-$\zeta$ in the spirit of split valence,\index{split
valence} decomposing the original PAO in several pieces of different
range, either defining more (and smaller) confining radii, or
introducing Gaussians\index{Gaussians} from known bases (Huzinaga's
book).
\end{itemize}

\noindent
All the remaining options
give the same minimal basis\index{minimal basis}.
The different options and their FDF descriptors are the following:

\begin{itemize}

\item {\tt split:} Split-valence scheme for multiple-zeta.
The split is based on different radii.

\item {\tt splitgauss:}\index{splitgauss@{\tt splitgauss}}
Same as {\tt split} but using gaussian functions
$e^{-(x/\alpha_i)^2}$. The gaussian widths $\alpha_i$ are read instead
of the scale factors (see below). There is no cutting algorithm, so that
a large enough $r_c$ should be defined for the gaussian to have decayed
sufficiently.

\item {\tt nodes:}\index{nodes@{\tt nodes}} Generalized PAO's.

\item {\tt nonodes:}\index{nonodes@{\tt nonodes}}
The original PAO's are used, multiple-zeta is generated
by changing the scale-factors, instead of using the excited orbitals.

\end{itemize}

\noindent
Note that, for the {\tt split} and {\tt nodes} cases
the whole basis can be generated by {\sc Siesta} with no further information
required. {\sc Siesta} will use default values as defined in the following
({\bf PAO.BasisSize},
{\bf PAO.EnergyShift}, and {\bf PAO.SplitNorm}, see below).

{\it Default value:} {\tt split}

\end{description}

\subsubsection{Size of the basis set}
\begin{description}

\item[{\bf PAO.BasisSize}] ({\it string}):
\index{PAO.BasisSize@{\bf PAO.BasisSize}}\index{basis!PAO}
It defines usual basis sizes. It has effect only if there is no
block {\bf PAO.Basis} present.

\begin{itemize}

\item {\tt SZ}\index{SZ@{\tt SZ}} or {\tt MINIMAL}:\index{MINIMAL@{\tt
MINIMAL}} minimal or single-$\zeta$
basis.\index{basis!minimal}\index{single-$\zeta$}

\item {\tt DZ}:\index{DZ@{\tt DZ}} Double zeta basis, in the scheme
defined by {\bf PAO.BasisType}.

\item {\tt SZP}:\index{SZP@{\tt SZP}} Single-zeta basis plus polarization
orbitals.

\item {\tt DZP}\index{DZP@{\tt DZP}} or {\tt
STANDARD}:\index{STANDARD@{\tt STANDARD}} Like {\tt DZ} plus
polarization orbitals.  Polarization orbitals are constructed from
perturbation theory,\index{perturbative polarization} and they are
defined so they have\index{basis!polarization} the minimum angular
momentum $l$ such that there are not occupied orbitals with the same
$l$ in the valence shell of the ground-state atomic
configuration. They polarize the corresponding $l-1$ shell.

{\bf Note}: The ground-state atomic configuration used internally
by {\sc Siesta} is defined in the source file {\tt Src/periodic\_table.f}.
For some elements (e.g., Pd), the configuration might not be the
standard one\index{Ground-state atomic configuration}.

\end{itemize}

{\it Default value:} {\tt DZP}

\item[{\bf PAO.BasisSizes}]({\it data block}):
\index{PAO.BasisSizes@{\bf PAO.BasisSizes}}\index{basis!PAO}
Block which allows to specify a different value of the variable
PAO.BasisSize for each species. For example,
\begin{verbatim}
          %block    PAO.BasisSizes
               Si      DZ
               H       DZP
               O       SZP
          %endblock PAO.BasisSizes
\end{verbatim}

\end{description}

\subsubsection{Range of the orbitals}

\begin{description}
\item[{\bf PAO.EnergyShift}] ({\it real energy}): A standard for
orbital-confining cutoff radii. It is the excitation energy
of the PAO's due to the confinement to a finite-range. It offers a
general procedure for defining the confining radii of the original
(first-zeta) PAO's for all the species guaranteeing the compensation
of the basis. It only has an effect when the block
{\bf PAO.Basis} is not present or when the radii
specified in that block are zero for the first zeta.

{\it Use:} It has to be positive.

{\it Default value:} {\tt 0.02 Ry}

\end{description}

\subsubsection{Generation of multiple-zeta orbitals}
\begin{description}

\item[{\bf PAO.SplitNorm}] ({\it real}):
\index{PAO.SplitNorm@{\bf PAO.SplitNorm}}\index{basis!split valence}
A standard to define sensible default
radii for the split-valence type of basis. It gives the amount of norm that
the second-$\zeta$ split-off piece has to carry. The split radius is defined
accordingly. If multiple-$\zeta$\index{multiple-$\zeta$}
is used, the corresponding radii are obtained
by imposing smaller fractions of the SplitNorm (1/2, 1/4 ...) value as
norm carried by the higher zetas. It only has an effect when the block
{\bf PAO.Basis} is not present or when the radii
specified in that block are zero for zetas higher than one.

{\it Default value:} {\tt 0.15} (sensible values range between 0.05 and 0.5).

\item[{\bf PAO.SplitNormH}] ({\it real}):
\index{PAO.SplitNormH@{\bf PAO.SplitNormH}}\index{basis!split valence
  for H}
This option is as per {\bf PAO.SplitNorm} but allows a separate
default to be
specified for hydrogen which typically needs larger values than those
for other
elements.

\item[{\bf PAO.NewSplitCode}] ({\it boolean}):
\index{PAO.NewSplitCode@{\bf PAO.NewSplitCode}}\index{basis!new
  split-valence code}

Enables a new, simpler way to match the multiple-zeta radii.

If an old-style (tail+parabola) calculation is being done, perform a
scan of the tail+parabola norm in the whole range of the 1st-zeta
orbital, and store that in a table. The construction of the
2nd-zeta orbital involves simply scanning the table to find the
appropriate place. Due to the idiosyncracies of the old algorithm,
the new one is not guaranteed to produce exactly the same results,
as it might settle on a neighboring grid point for the matching.

{\it Default value:} {\tt .false.}

\item[{\bf PAO.FixSplitTable}] ({\it boolean}):
\index{PAO.FixSplitTable@{\bf PAO.FixSplitTable}}\index{basis!fix
  split-valence table}

After the scan of the allowable split-norm values, apply a damping
function to the tail to make sure that the table goes to zero at
the radius of the first-zeta orbital.

{\it Default value:} {\tt .false.}

\item[{\bf PAO.SplitTailNorm}] ({\it boolean}):
\index{PAO.SplitTailNorm@{\bf PAO.SplitTailNorm}}\index{basis!new
  split-valence code}

Use the norm of the tail instead of the full tail+parabola
norm. This is the behavior described in the JPC paper. (But note
that, for numerical reasons, the square root of the tail norm is used
in the algorithm.) This is the preferred mode of operation for
automatic operation, as in non-supervised basis-optimization runs.

{\it Default value:} {\tt .false.}

As a summary of the above options:
\begin{itemize}
\item For complete backwards compatibility, do nothing.
\item To exercise the new code, set {\tt PAO.NewSplitCode}.
\item To maintain the old split-norm heuristic, but
making sure that the program finds a solution (even
if not optimal, in the sense of producing a second-$\zeta$ $r_c$
very close to the first-$\zeta$ one), set {\tt PAO.FixSplitTable}
(this will automatically set {\tt PAO.NewSplitCode}).
\item If the old heuristic is of no interest (for example, if
only a robust way of mapping split-norms to radii is needed), set
{\tt PAO.SplitTailNorm} (this will set {\tt PAO.NewSplitCode}
automatically).
\end{itemize}

\end{description}
\subsubsection{Soft-confinement options}
\begin{description}

\item[{\bf PAO.SoftDefault}] ({\it boolean}):
\index{PAO.SoftDefault@{\bf PAO.SoftDefault}}\index{basis!default soft
  confinement}
If set to true then this option causes soft confinement to be the
default form
of potential during orbital generation. The default potential and
inner radius
are set by the commands given below.

{\it Default value:} {\tt .false.}

\item[{\bf PAO.SoftInnerRadius}] ({\it real}):
\index{PAO.SoftInnerRadius@{\bf
    PAO.SoftInnerRadius}}\index{basis!default soft confinement radius}
For default soft confinement, the inner radius is set at a fraction of
the outer
confinement radius determined by the energy shift. This option
controls the fraction
of the confinement radius to be used.

{\it Default value:} {\tt 0.9}

\item[{\bf PAO.SoftPotential}] ({\it real}):
\index{PAO.SoftPotential@{\bf PAO.SoftPotential}}\index{basis!default
  soft confinement potential}
For default soft confinement, this option controls the value of the
potential used
for all orbitals.

{\it Default value:} {\tt 40.0 Ry}


Note: Soft-confinement options (inner radius, prefactor) have been
traditionally used to optimize the basis set, even though formally
they are just a technical necessity to soften the decay of the
orbitals at rc. To achieve this, it might be enough to use the above
global options.

\end{description}

\subsubsection{Kleinman-Bylander projectors}


\begin{description}

\item[{\bf PS.lmax}]  ({\it data block}):
\index{PS.lmax@{\bf PS.lmax}}
Block with the maximum angular momentum of the Kleinman-Bylander
projectors,\index{Kleinman-Bylander projectors} {\tt lmxkb}.
This information is optional. If the block
is absent, or for a species which is not mentioned inside
it, {\sc Siesta} will take {\tt lmxkb(is) = lmxo(is) + 1}, where {\tt lmxo(is)}
is the maximum angular momentum of the basis orbitals of species {\tt is}.
\begin{verbatim}
         %block Ps.lmax
              Al_adatom   3
              H           1
              O           2
         %endblock Ps.lmax
\end{verbatim}
{\it Default:} (Block absent or empty). Maximum angular momentum
of the basis orbitals plus one.
\noindent

\item[{\bf PS.KBprojectors}] ({\it data block}):
\index{PS.KBprojectors@{\bf PS.KBprojectors} }
This block provides information about the number of Kleinman-Bylander
projectors per angular momentum, and for each species, that will used
in the calculation. This block is optional.
If the block is absent, or for species not mentioned in it, only
one projector will be used for each angular momentum. The projectors
will be constructed using the eigenfunctions of the respective
pseudopotentials.


This block allows to specify the number of projector for each l, and also
the reference energies of the wavefunctions used to build them.
The specification of the reference energies is optional. If these
energies are not given, the program will use the eigenfunctions with an
increasing number of nodes (if there is not bound state with
the corresponding number of nodes, the ``eigenstates" are taken to be just
functions which are made zero at very long distance of the nucleus).
The units for the energy can be optionally specified, if not, the
program will assumed that are given in Rydbergs.
The data provided in this block must be consistent with those
read from the block {\bf PS.lmax}. For example,

\begin{verbatim}
         %block PS.KBprojectors
             Si  3
              2   1
             -0.9     eV
              0   2
             -0.5  -1.0d4 Hartree
              1   2
             Ga  1
              1  3
             -1.0  1.0d5 -6.0
         %endblock PS.KBprojectors
\end{verbatim}

The reading is done this way (those variables in brackets are optional,
therefore they are only read if
present):

\begin{verbatim}
    From is = 1 to  nspecies
         read: label(is), l_shells(is)
         From lsh=1 to l_shells(is)
              read: l, nkbl(l,is)
              read: {erefKB(izeta,il,is)}, from ikb = 1 to nkbl(l,is), {units}
\end{verbatim}

When a very high energy, higher that 1000 Ry, is specified, the
default is taken instead.  On the other hand, very low (negative)
energies, lower than -1000 Ry, are used to indicate that the energy
derivative of the last state must be used. For example, in the example
given above, two projectors will be used for the {\it s}
pseudopotential of Si. One generated using a reference energy of -0.5
Hartree, and the second one using the energy derivative of this
state. For the {\it p} pseudopotential of Ga, three projectors will be
used.  The second one will be constructed from an automatically
generated wavefunction with one node, and the other projectors from
states at -1.0 and -6.0 Rydberg.

The analysis looking for possible {\it ghost} states is only performed
when a single projector is used.  Using several projectors some
attention should be paid to the ``KB cosine" (kbcos), given in the
output of the program.  The KB cosine gives the value of the overlap
between the reference state and the projector generated from it.  If
these numbers are very small ( $<$ 0.01, for example) for {\bf all}
the projectors of some angular momentum, one can have problems related
with the presence of ghost states.

{\it Default:} (Block absent or empty). Only one KB projector,
constructed from the nodeless eigenfunction, used for each angular
momentum.
\noindent

\end{description}

\subsubsection{The PAO.Basis block}
\begin{description}

\item[{\bf PAO.Basis}] ({\it data block}): \index{PAO.Basis@{\bf
PAO.Basis}\index{basis!PAO}}
Block with data to define explicitly the
basis to be used.  It allows the definition by hand of all the
parameters that are used to construct the atomic basis. There is no
need to enter information for all the species present in the
calculation. The basis\index{basis!PAO} for the species not mentioned in
this block will be generated automatically using the parameters {\bf
PAO.BasisSize}, {\bf PAO.BasisType}, {\bf PAO.EnergyShift}, {\bf
PAO.SplitNorm} (or {\bf PAO.SplitNormH}), and the soft-confinement
defaults, if used (See {\bf PAO.SoftDefault}).

Some parameters can be set to zero, or
left out completely.  In these cases the values will be generated from the
magnitudes defined above, or from the appropriate default values. For
example, the radii\index{cutoff radius} will be obtained from {\bf
PAO.EnergyShift} or from {\bf PAO.SplitNorm} if they are zero; the
scale factors will be put to 1 if they are zero or not given in the
input.  An example block for a two-species calculation (H and O) is
the following ({\tt opt} means optional):

\begin{verbatim}
%block PAO.Basis     # Define Basis set
O    2  nodes  1.0   # Label, l_shells, type (opt), ionic_charge (opt)
 n=2 0 2  E 50.0 2.5 # n (opt if not using semicore levels),l,Nzeta,Softconf(opt
     3.50  3.50      #     rc(izeta=1,Nzeta)(Bohr)
     0.95  1.00      #     scaleFactor(izeta=1,Nzeta) (opt)
     1 1  P 2        # l, Nzeta, PolOrb (opt), NzetaPol (opt)
     3.50            #     rc(izeta=1,Nzeta)(Bohr)
H    1               # Label, l_shells, type (opt), ionic_charge (opt)
     0 2 S 0.2       # l, Nzeta, Per-shell split norm parameter
     5.00  0.00      #     rc(izeta=1,Nzeta)(Bohr)
%endblock PAO.Basis
\end{verbatim}

\noindent
The reading is done this way (those variables in brackets are
optional, therefore they are only read if present) (See
the routines in {\tt Src/basis\_specs.f} for detailed information):

\begin{verbatim}
    From js = 1 to  nspecies
       read: label(is), l_shells(is), { type(is) }, { ionic_charge(is) }
       From lsh=1 to l_shells(is)
        read:
         { n }, l(lsh), nzls(lsh,is), { PolOrb(l+1) }, { NzetaPol(l+1) },
         {SplitNormfFlag(lsh,is)}, {SplitNormValue(lsh,is)}
         {SoftConfFlag(lsh,is)}, {PrefactorSoft(lsh,is)}, {InnerRadSoft(lsh,is)}
           read: rcls(izeta,lsh,is), from izeta = 1 to nzls(l,is)
           read: { contrf(izeta,il,is) }, from izeta = 1 to nzls(l,is)
\end{verbatim}

\noindent
And here is the variable description:
\begin{itemize}
\item[-] {\tt Label}: Species label, this label determines
the species index {\tt is} according to the block {\bf ChemicalSpecieslabel}
\item[-] {\tt l\_shells(is)}: Number of shells of orbitals
with different angular momentum for species {\tt is}
\item[-] {\tt type(is)}: {\it Optional input}.
Kind of basis set generation procedure for species {\tt is}.
Same options as {\bf PAO.BasisType}
\item[-] {\tt ionic\_charge(is)}: {\it Optional input}.
Net charge of species {\tt is}. This is  only used for
basis set generation purposes. {\it Default value}: {\tt 0.0} (neutral
atom). Note that if the pseudopotential was generated in an ionic
configuration, and no charge is specified in PAO.Basis, the ionic
charge setting will be that of pseudopotential generation.
\item[-] {\tt n}: Principal quantum number of the shell. This is an optional
input for normal atoms, however it must be specified when there are
{\it semicore} states (i.e. when states that usually are not
considered to belong to the
valence shell have been included in the calculation)
\item[-] {\tt l}: Angular momentum of
basis orbitals of this shell
\item[-] {\tt nzls(lsh,is)}: Number of 'zetas' for this shell.
\item[-] {\tt PolOrb(l+1)}: {\it Optional input}. If set equal to {\tt P}, a
shell of
polarization functions (with angular momentum $l+1$)  will be constructed
from the first-zeta orbital of angular momentum $l$. {\it Default value}: ' '
(blank = No polarization orbitals).
\item[-] {\tt NzetaPol(l+1)}: {\it Optional input}. Number of
'zetas' for the
polarization shell (generated automatically in a split-valence fashion).
Only active if {\tt PolOrb = P}. {\it Default value}: {\tt 1}
\item[-] {\tt SplitNormFlag(lsh,is)}:\index{basis!per-shell split norm}
{\it Optional input}. If set equal to
{\tt S}, the following number sets the split-norm parameter for that shell.
\item[-] {\tt SoftConfFlag(l,is)}:\index{basis!soft confinement potential}
{\it Optional input}. If set equal to
{\tt E}, the new soft confinement potential proposed in formula (1) of
the paper by J. Junquera {\it et al.}, Phys. Rev. B {\bf 64}, 235111 (2001),
is used instead of the Sankey hard-well potential.
\item[-] {\tt PrefactorSoft(l,is)}: {\it Optional input}. Prefactor
of the soft confinement potential ($V_{0}$ in the formula). Units in Ry.
{\it Default value}: 0 Ry.
\item[-] {\tt InnerRadSoft(l,is)}: {\it Optional input}. Inner radius where
the soft confinemet potential starts off ($r_{i}$ in the formula).
If negative, the inner radius will be computed as the given fraction
of the PAO cutoff radius.
Units in bohrs. {\it Default value}: 0 bohrs.
\item[-] {\tt rcls(izeta,l,is)}: Cutoff radius (Bohr) of
each 'zeta' for this shell. For the second zeta onwards, if this value
is negative, the actual rc used will be the given fraction of the
first zeta's rc.
\item[-] {\tt contrf(izeta,l,is)}: {\it Optional input}.
Contraction factor\index{scale factor} of
each 'zeta' for this shell.
{\it Default value}: {\tt 1.0}
\end{itemize}

Polarization orbitals\index{perturbative
polarization}\index{basis!polarization} are generated by solving the
atomic problem in the presence of a polarizing electric field. The
orbitals are generated applying perturbation theory to the first-zeta
orbital of lower angular momentum.  They have the same cutoff radius
as the orbitals from which they are constructed.

Note: The perturbative method has traditionally used the 'l' component
of the pseudopotential. It can be argued that it should use the 'l+1'
component. By default, for backwards compatibility, the traditional
method is used, but the alternative one can be activated by setting
the logical {\bf PAO.OldStylePolOrbs} variable to {\tt .false.}

There is a different possibility for generating polarization orbitals:
by introducing them explicitly in the {\bf PAO.Basis} block.
It has to be remembered, however, that they sometimes correspond to
unbound states of the atom, their shape depending very much on the
cutoff radius, not converging by increasing it, similarly to the
multiple-zeta orbitals generated with the {\tt nodes} option.
Using {\bf PAO.EnergyShift} makes no sense, and a cut off
radius different from zero must be explicitly given (the same cutoff radius
as the orbitals they polarize is usually a sensible choice).

A species with atomic number = -100 will be considered by {\sc Siesta} as
a constant-pseudopotential atom, {\it i.e.}, the basis functions
generated will be spherical Bessel functions\index{Bessel functions}
with the specified $r_c$. In this case, $r_c$ has to be given, as
{\bf EnergyShift} will not calculate it.\index{basis!Bessel functions}

Other negative atomic numbers will be interpreted by {\sc Siesta} as
{\it ghosts}\index{ghost atoms}\index{basis!ghost atoms}
of the corresponding positive value: the orbitals
are generated and put in position as determined by the coordinates,
but neither pseudopotential nor electrons are considered for that
ghost atom. Useful for BSSE\index{basis!basis set superposition
error (BSSE)} correction.

{\it Use:} This block is optional, except when Bessel functions or
semicore states are present.

{\it Default:} Basis characteristics defined by global definitions given
above.

\end{description}

\subsubsection{Filtering}
\label{sec:filtering}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf FilterCutoff}] ({\it physical energy}):
\index{FilterCutoff@{\bf
    FilterCutoff}}\index{basis!filtering}
Kinetic energy cutoff of plane waves used to filter all the
atomic basis functions, the pseudo-core densities
for partial core corrections, and the neutral-atom potentials.
The basis functions (which must be squared to obtain the
valence density) are really filtered with a cutoff reduced by an
empirical factor $0.7^2 \simeq 0.5$. The \textbf{FilterCutoff} should
be similar or lower than the \textbf{MeshCutoff} to avoid the
{\it eggbox effect} on the atomic forces.
However, one should
not try to converge \textbf{MeshCutoff} while simultaneously
changing \textbf{FilterCutoff}, since the latter in fact changes
the used basis functions. Rather, fix a sufficiently large
\textbf{FilterCutoff} and converge only \textbf{MeshCutoff}.
If \textbf{FilterCutoff} is not explicitly set, its value is
calculated from \textbf{FilterTol}.

\item[{\bf FilterTol}] ({\it physical energy}):
\index{FilterTol@{\bf
    FilterTol}}\index{basis!filtering}
Residual kinetic-energy leaked by filtering each basis function.
While \textbf{FilterCutoff} sets a common reciprocal-space cutoff
for all the basis functions, \textbf{FilterTol} sets a specific 
cutoff for each basis function, much as the \textbf{EnergyShift}
sets their real-space cutoff. Therefore,
it is reasonable to use similar values for both parameters.
The maximum cutoff required to meet the \textbf{FilterTol},
among all the basis functions, is used (multiplied by the
empirical factor $1/0.7^2 \simeq 2$) to filter the pseudo-core
densities and the neutral-atom potentials. \textbf{FilterTol} is ignored if
\textbf{FilterCutoff} is present in the input file.
If neither \textbf{FilterCutoff} nor \textbf{FilterTol} are
present, no filtering is performed.
See Soler and Anglada, arXiv:0807.5030, for details of the
filtering procedure.

{\bf Warning:} If the value of \textbf{FilterCutoff} is
made too small (or \textbf{FilterTol} too large) some of
the filtered basis orbitals may be meaningless, leading to
incorrect results or even a program crash.

To be implemented: If \textbf{MeshCutoff} is not present in the input
file, it can be set using the maximum filtering cutoff used for the given 
\textbf{FilterTol} (for the time being, you can use {\tt AtomSetupOnly T} 
to stop the program after basis generation, look at the maximum filtering
cutoff used, and set the mesh-cutoff manually in a later run.)

\end{description}

\subsubsection{Saving and reading basis-set information}

\index{basis}\index{output!basis}
{\sc Siesta} (and the standalone program {\sc Gen-basis})
\index{basis!Gen-basis standalone program}
always generate the files
{\it Atomlabel}{\tt .ion}, where {\it Atomlabel} is the atomic label
specified in block {\it ChemicalSpeciesLabel}.  Optionally, if
NetCDF support is compiled in, the programs generate
NetCDF files \index{NetCDF format}
{\it Atomlabel}{\tt .ion.nc}.
See an Appendix for information on the optional NetCDF package.

These files can be used to read back information into {\sc Siesta}.

\begin{description}
\itemsep 10pt
\parsep 0pt
\item[{\bf User.Basis}] ({\it logical}):
\index{User.Basis@{\bf User.Basis}}\index{basis!User basis}

If true, the basis, KB projector, and other information is read from
files {\it Atomlabel}{\tt .ion}, where {\it Atomlabel} is the atomic
species label specified in block {\it ChemicalSpeciesLabel}. These
files can be generated by a previous {\sc Siesta} run or (one by one) by the
standalone program {\sc Gen-basis}.\index{Gen-basis program@{\sc
Gen-basis}}\index{basis!Gen-basis standalone program} No pseudopotential
files are necessary.

\item[{\bf User.Basis.NetCDF}] ({\it logical}):
\index{User.Basis.NetCDF@{\bf User.Basis.NetCDF}}
\index{basis!User basis (NetCDF format)}
\index{NetCDF format}

If true, the basis, KB projector, and other information is read from
NetCDF files {\it Atomlabel}{\tt .ion.nc}, where {\it Atomlabel} is
the atomic label specified in block {\it ChemicalSpeciesLabel}. These
files can be generated by a previous {\sc Siesta} run or by the
standalone program {\sc Gen-basis}.\index{Gen-basis program@{\sc
Gen-basis}}\index{basis!Gen-basis standalone program} No pseudopotential
files are necessary. NetCDF support is needed.

\end{description}

\subsubsection{Tools to inspect the orbitals and KB projectors}

The program {\tt ioncat} in {\tt Util/Gen-basis} can be used to
extract orbital, KB projector, and other information contained in the
{\tt .ion} files. The output can be easily plotted with a graphics
program.  If the option {\bf WriteIonPlotFiles} is enabled, {\sc
  Siesta} will generate and extra set of files that can be plotted
with the {\tt gnuplot} scripts in {\tt Tutorials/Bases}.
The stand-alone program {\tt gen-basis} sets that option by default, and
the script {\tt Tutorials/Bases/gen-basis.sh} can be used to automate
the process. See also the NetCDF-based utilities in {\tt
  Util/PyAtom}.

\subsubsection{Basis optimization}

There are quite a number of options for the input of the basis-set and
KB projector specification, and they are all optional! By default,
{\sc Siesta} will use a DZP basis set with appropriate choices for the
determination of the range, etc. Of course, the more you experiment
with the different options, the better your basis set can get. To aid
in this process we offer an auxiliary program for optimization which
can be used in particular to obtain variationally optimal basis sets
(within a chosen basis size). See {\tt Util/Optimizer}
for general information, and {\tt Util/Optimizer/Examples/Basis\_Optim}
for an example.

\begin{description}
\itemsep 10pt
\parsep 0pt
\item[{\bf BasisPressure}] ({\it real pressure}):
\index{BasisPressure@{\bf
    BasisPressure}}\index{basis!effective pressure}

{\sc Siesta} will compute and print the value of the ``effective basis
enthalpy'' constructed by adding a term of the form
$p_{basis}V_{orbs}$ to the total energy. Here $p_{basis}$ is a
fictitious basis pressure and $V_{orbs}$ is the volume of the system's
orbitals. This is a useful quantity for basis optimization (See
Anglada {\it et al.\/}). The total basis enthalpy is also written to
the ASCII file {\tt BASIS\_ENTHALPY}.

{\it Default value:} { $0.2$ GPa}

\end{description}

\subsubsection{Low-level options regarding the radial grid}

For historical reasons, the basis-set and KB projector code in {\sc
  Siesta} uses a logarithmic radial grid, which is taken from the
pseudopotential file. Any ``interesting'' radii have to fall on a grid
point, which introduces a certain degree of coarseness that can limit
the accuracy of the results and the faithfulness of the mapping of
input parameters to actual operating parameters. For example, the same
orbital will be produced by a finite range of {\bf PAO.EnergyShift}
values, and any user-defined cutoffs will not be exactly reflected in
the actual cutoffs. This is particularly troublesome for automatic
optimization procedures (such as those implemented in {\tt
  Util/Optimizer}), as the engine might be confused by the extra level
of indirection. The following options can be used to fine-tune the mapping.
They are not enabled by default, as they change the numerical results
apreciably (in effect, they lead to different basis orbitals and
projectors). 

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf Reparametrize.Pseudos}] ({\it logical}):
\index{Reparametrize.Pseudos@{\bf Reparametrize.Pseudos}}

By changing the $a$ and $b$ parameters of the logarithmic grid, a new
one with a more adequate grid-point separation can be used for the
generation of basis sets and projectors. For example, by using
$a=0.001$ and $b=0.01$, the grid point separations at $r=0$ and 10
bohrs are 0.00001 and 0.01 bohrs, respectively. More points are needed
to reach r's of the order of a hundred bohrs, but the extra
computational effort is negligible.  The net effect of this option
(notably when coupled to {\bf Restricted.Radial.Grid} {\tt .false.})
is a closer mapping of any user-specified cutoff radii and of the
radii implicitly resulting from other input parameters to the actual
values used by the program. (The small grid-point separation near r=0
is still needed to avoid instabilities for s channels that occurred
with the previous (reparametrized) default spacing of 0.005 bohr. This
effect is not yet completely understood. )



{\it Default value:} { \tt .false.}

\item[{\bf New.A.Parameter}] ({\it real}):
\index{New.A.Parameter@{\bf
    New.A.Parameter}}\index{basis!reparametrization of pseudopotential}

New setting for the pseudopotential grid's $a$ parameter

{\it Default value:} { $0.001$}

\item[{\bf New.B.Parameter}] ({\it real}):
\index{New.B.Parameter@{\bf
    New.B.Parameter}}\index{basis!reparametrization of pseudopotential}

New setting for the pseudopotential grid's $b$ parameter

{\it Default value:} { $0.01$}

\item[{\bf Rmax.Radial.Grid}] ({\it real}):
\index{Rmax.Radial.Gridr@{\bf
    Rmax.Radial.Grid}}\index{basis!point at infinity}

New setting for the maximum value of the radial coordinate for
integration of the atomic Schrodinger equation.

{\it Default value:} { $50.0$} if {\tt Reparametrize.Pseudos} is set,
zero otherwise (which means that the maximum radius from the pseudopotential
file is used).

\item[{\bf Restricted.Radial.Grid}] ({\it logical}):
\index{Restricted.Radial.Grid@{\bf Restricted.Radial.Grid}}

In normal operation of the basis-set and projector generation code the
radial grid is restricted to having an odd number of points, and the
cutoffs are shifted accordingly. This restriction can be lifted by
setting this parameter to {\tt .false.}

{\it Default value:} { \tt .true.}
\end{description}


\vspace{5pt}
\subsection{Structural information}

There are many ways to give {\sc Siesta} structural information.

\begin{itemize}
\item Directly from the fdf file in traditional format.
\item Directly from the fdf file in the newer Z-Matrix format, using
a \textbf{Zmatrix} block.
\item From an external data file
\item From a FIFO file, when working in ``server'' mode.
\end{itemize}

Note that, regardless of the way in which the structure is described,
the tags
{\bf NumberOfSpecies}, \index{NumberOfSpecies@{\bf NumberOfSpecies}}
{\bf NumberOfAtoms}, \index{NumberOfAtoms@{\bf NumberOfAtoms}}
and {\bf ChemicalSpeciesLabel}
\index{ChemicalSpeciesLabel@{\bf ChemicalSpeciesLabel}} are mandatory.

In the following sections we document the different structure input
methods, and provide a guide to their precedence.

\subsubsection{Traditional structure input in the fdf file}

Firstly, the size of the cell itself should be specified, using
some combination of the options
\textbf{LatticeConstant}, \textbf{LatticeParameters},
and \textbf{LatticeVectors}, and \textbf{SuperCell}.
If nothing is specified, {\sc Siesta} will construct a cubic
cell in which the atoms will reside as a cluster.

Secondly, the positions of the atoms within the cells
must be specified, using either the traditional {\sc Siesta}
input format (a modified xyz format) which must be described
within
a \textbf{AtomicCoordinatesAndAtomicSpecies} block.

\begin{description}
\itemsep 10pt
\parsep 0pt
\item[{\bf LatticeConstant}] ({\it real length}):
\index{LatticeConstant@{\bf LatticeConstant}}
Lattice constant. This is just to define the scale of the lattice vectors.

{\it Default value:} Minimum size to include the system (assumed to be a
molecule) without intercell interactions, plus 10\%.

NOTE: A LatticeConstant value, even if redundant, might be needed for
other options, such as the units of the k-points used for
band-structure calculations. This mis-feature will be corrected in
future versions.

\item[{\bf LatticeParameters}] ({\it data block}):
\index{LatticeParameters@{\bf LatticeParameters}}
Crystallographic way of specifying the lattice vectors, by giving
six real numbers: the three vector modules, $a$, $b$, and $c$, and
the three angles $\alpha$ (angle between $\vec b$ and $\vec c$),
$\beta$, and $\gamma$. The three modules are in units of
{\bf LatticeConstant}, the three angles are in degrees.

{\it Default value:}
{\tt
\begin{verbatim}
           1.0   1.0   1.0    90.   90.  90.
\end{verbatim}
}
\noindent
(see the following)

\item[{\bf LatticeVectors}] ({\it data block}):
\index{LatticeVectors@{\bf LatticeVectors}}
The cell vectors are read in units of the lattice constant defined above.
They are read as a matrix {\tt CELL(ixyz,ivector)}, each vector being
one line.

{\it Default value:}
{\tt
\begin{verbatim}
            1.0    0.0    0.0
            0.0    1.0    0.0
            0.0    0.0    1.0
\end{verbatim}
}
\noindent
If the {\bf LatticeConstant} default is used, the default of
{\bf LatticeVectors} is still diagonal but not necessarily cubic.


\item[{\bf SuperCell}] ({\it data block}): 
\index{SuperCell@{\bf SuperCell}} 
Integer 3x3 matrix defining a supercell in terms of the unit cell: 

\begin{verbatim}
     %block SuperCell
        M(1,1)  M(2,1)  M(3,1) 
        M(1,2)  M(2,2)  M(3,2) 
        M(1,3)  M(2,3)  M(3,3) 
     %endblock SuperCell
\end{verbatim}

and the supercell is defined as
$SuperCell(ix,i) = \sum_j CELL(ix,j)*M(j,i)$.
Notice that the matrix indexes are inverted: each input line 
specifies one supercell vector.

{\it Warning:} {\bf SuperCell} is disregarded if the geometry is read
from
the XV file, which can happen unadvertedly.

{\it Use:} The atomic positions must be given only for the unit cell,
and they are 'cloned' automatically in the rest of the supercell.
The {\bf NumberOfAtoms} given must also be that in a single unit cell.
However, all values in the output are given for the entire supercell. 
In fact, CELL is inmediately redefined as the whole supercell and the 
program no longer knows the existence of an underlying unit cell.
All other input (apart from NumberOfAtoms and atomic positions), 
including {\bf kgridMonkhorstPack} must refer to the supercell 
(this is a change over previous versions). Therefore, to avoid
confusions, we recommend to use {\bf SuperCell} only to
generate atomic positions, and then to copy them from the output
to a new input file with all the atoms specified explicitly and
with the supercell given as a normal unit cell.

{\it Default value:} No supercell (supercell equal to unit cell).


\item[{\bf AtomicCoordinatesFormat}] ({\it string}):
\index{AtomicCoordinatesFormat@{\bf AtomicCoordinatesFormat}}
Character string to specify the format of the atomic positions in
input. These can be expressed in four forms:
\begin{itemize}
\item {\tt Bohr} or {\tt NotScaledCartesianBohr} (atomic positions
are given directly in Bohr, in Cartesian coordinates)
\item {\tt Ang} or {\tt NotScaledCartesianAng} (atomic positions
are given directly in {\AA}ngstr\"om, in Cartesian coordinates)
\item {\tt ScaledCartesian} (atomic positions are given
in Cartesian coordinates, in units of the lattice constant)
\item {\tt Fractional} or {\tt ScaledByLatticeVectors} (atomic positions
are given referred to the lattice vectors)
\end{itemize}

{\it Default value:} {\tt NotScaledCartesianBohr}


\item[{\bf AtomCoorFormatOut}] ({\it string}):
\index{AtomCoorFormatOut@{\bf AtomCoorFormatOut}}
Character string to specify the format of the atomic positions in output.
Same possibilities as for input ({\bf AtomicCoordinatesFormat}).

{\it Default value:} value of {\bf AtomicCoordinatesFormat}


\item[{\bf AtomicCoordinatesOrigin}] ({\it data block}):
\index{AtomicCoordinatesOrigin@{\bf AtomicCoordinatesOrigin}}
Vector specifying a rigid shift to apply to the atomic coordinates,
given in the same format and units as these. Notice that the atomic
positions (shifted or not) need not be within the cell formed by
{\bf LatticeVectors}, since periodic boundary conditions are always
assumed.

{\it Default value:}
{\tt
\begin{verbatim}
  0.000   0.000   0.000
\end{verbatim}
}

\item[{\bf AtomicCoordinatesAndAtomicSpecies}] ({\it data block}):
\index{AtomicCoordinatesAndAtomicSpecies@{\bf
AtomicCoordinatesAndAtomicSpecies}}
Block specifying the position and species of each atom.
One line per atom, the reading is done this way:
\begin{verbatim}
       From ia = 1 to natoms
            read: xa(ix,ia), isa(ia)
\end{verbatim}
where {\tt xa(ix,ia)} is the {\tt ix} coordinate of atom
{\tt iai} in the format (units) specified by
{\bf AtomCoordinatesFormat}, and {\tt isa(ia)} is the species
index of atom {\tt ia}.

{\it Default:} There is no default. The positions must be introduced
either using this block or the $Z$ matrix (see {\bf Zmatrix}).

\end{description}
\subsubsection{Z-matrix format and constraints}
\label{sec:Zmatrix}

The advantage of the traditional format is that it is
much easier to set up a system. However, when working
on systems with constraints, there are only a limited
number of (very simple) constraints that may be expressed
within this format, and recompilation is needed for each
new constraint.

For any more involved set of constraints, a
full \textbf{Zmatrix} formulation should be used - this
offers much more control, and may be specified fully at
run time (thus not requiring recompilation) - but
it is more work to generate the input files for this form.


\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf Zmatrix}] ({\it data block}): \index{Zmatrix@{\bf Zmatrix}}
  This block provides a means for inputting the system geometry using
  a Z-matrix format, as well as controlling the optimization
  variables. This is particularly useful when working with molecular
  systems or restricted optimizations (such as locating transition
  states or rigid unit movements). The format also allows for hybrid
  use of Z-matrices and Cartesian or fractional blocks, as is
  convenient for the study of a molecule on a surface.  As is always
  the case for a Z-matrix, the responsibility falls to the user to
  chose a sensible relationship between the variables to avoid triads
  of atoms that become linear.

Below is an example of a Z-matrix input for a water molecule:
\begin{verbatim}
    %block Zmatrix

    molecule fractional
      1 0 0 0   0.0 0.0 0.0 0 0 0
      2 1 0 0   HO1 90.0 37.743919 1 0 0
      2 1 2 0   HO2 HOH 90.0 1 1 0
    variables
        HO1 0.956997
        HO2 0.956997
        HOH 104.4
    %endblock Zmatrix
\end{verbatim}

The sections that can be used within the Zmatrix block are as follows:

Firstly, all atomic positions must be specified within either a
``\texttt{molecule}'' block or a ``\texttt{cartesian}'' block.  Any
atoms subject to constraints more complicated than ``do not change
this coordinate of this atom'' must be specified within a
``\texttt{molecule}'' block.

\item \texttt{molecule}:

There must be one of these blocks for each independent set of
constrained atoms within the simulation.

This specifies the atoms that make up each molecule and their
geometry. In addition, an option of ``\texttt{fractional}'' or
``\texttt{scaled}'' may be passed, which indicates that distances are
specified in scaled or fractional units. In the absence of such an
option, the distance units are taken to be the value of
``\texttt{ZM.UnitsLength}''.

A line is needed for each atom in the molecule; the format of each
line should be:

\noindent\texttt{    Nspecies i j k r a t ifr ifa ift}

Here the values \texttt{Nspecies}, \texttt{i}, \texttt{j}, \texttt{k},
\texttt{ifr}, \texttt{ifa}, and \texttt{ift} are integers and
\texttt{r}, \texttt{a}, and \texttt{t} are double precision reals.

For most atoms, \texttt{Nspecies} is the species number of the atom,
\texttt{r} is distance to atom number \texttt{i}, \texttt{a} is the
angle made by the present atom with atoms \texttt{j} and \texttt{i},
while \texttt{t} is the torsional angle made by the present atom with
atoms \texttt{k}, \texttt{j}, and \texttt{i}. The values \texttt{ifr},
\texttt{ifa} and \texttt{ift} are integer flags that indicate whether
\texttt{r}, \texttt{a}, and \texttt{t}, respectively, should be
varied; 0 for fixed, 1 for varying.


The first three atoms in a molecule are a special case. Because there
are insufficient atoms defined to specify a distance/angle/torsion,
the values are set differently. For atom 1, \texttt{r}, \texttt{a},
and \texttt{t}, are the Cartesian coordinates of the atom.  For the
second atom, \texttt{r}, \texttt{a}, and \texttt{t} are the
coordinates in spherical form of the second atom relative to the
first: first the radius, then the polar angle (angle between the
$z$-axis and the displacement vector) and then the azimuthal angle
(angle between the $x$-axis and the projection of the displacement
vector on the $x$-$y$ plane). Finally, for the third atom, the numbers
take their normal form, but the torsional angle is defined relative to
a notional atom 1 unit in the z-direction above the atom \texttt{j}.

Secondly. blocks of atoms all of which are subject to the simplest of
constraints may be specified in one of the following three ways,
according to the units used to specify their coordinates:


\item \texttt{cartesian}: This section specifies a block of atoms
whose coordinates are to be specified in Cartesian coordinates. Again,
an option of ``\texttt{fractional}'' or ``\texttt{scaled}'' may be
added, to specify the units used; and again, in their absence, the
value of ``\texttt{ZM.UnitsLength}'' is taken.

The format of each atom in the block will look like:

\noindent\texttt{      Nspecies x y z ix iy iz}

Here \texttt{Nspecies}, \texttt{ix}, \texttt{iy}, and \texttt{iz} are
integers and \texttt{x}, \texttt{y}, \texttt{z} are
reals. \texttt{Nspecies} is the species number of the atom being
specified, while \texttt{x}, \texttt{y}, and \texttt{z} are the
Cartesian coordinates of the atom in whichever units are being
used. The values \texttt{ix}, \texttt{iy} and \texttt{iz} are integer
flags that indicate whether the \texttt{x}, \texttt{y}, and \texttt{z}
coordinates, respectively, should be varied or not. A value of 0
implies that the coordinate is fixed, while 1 implies that it should
be varied.  {\bf NOTE}: When performing ``variable cell''
optimization while using a Zmatrix format for input, the algorithm
will not work if some of the coordinates of an atom in a {\tt
cartesian} block are variables and others are not (i.e.,
\texttt{ix iy iz} above must all be 0 or 1). This will be fixed in
future versions of the program.

A Zmatrix block may also contain the following, additional, sections, which
are designed to make it easier to read.

\item \texttt{constants}: Instead of specifying a numerical value, it
  is possible to specify a symbol within the above geometry
  definitions. This section allows the user to define the value of the
  symbol as a constant. The format is just a symbol followed by the
  value:

\noindent\texttt{      HOH 104.4}

\item \texttt{variables}: Instead of specifying a numerical value, it
  is possible to specify a symbol within the above geometry
  definitions. This section allows the user to define the value of the
  symbol as a variable. The format is just a symbol followed by the
  value:

\noindent\texttt{      HO1 0.956997}

Finally, constraints must be specified in a \texttt{constraints} block.

\item \texttt{constraint} This sub-section allows the user to create
  constraints between symbols used in a Z-matrix:
\begin{verbatim}
    constraint
      var1 var2 A B
\end{verbatim}
Here var1 and var2 are text symbols for two quantities in the Z-matrix
definition, and A and B are real numbers. The variables are related by
$var1 = A*var2 + B$.

An example of a Z-matrix input for a benzene molecule over a metal surface is:
\begin{verbatim}
    %block Zmatrix
    molecule
      2 0 0 0 xm1 ym1 zm1 0 0 0
      2 1 0 0 CC 90.0 60.0 0 0 0
      2 2 1 0 CC CCC 90.0 0 0 0
      2 3 2 1 CC CCC 0.0 0 0 0
      2 4 3 2 CC CCC 0.0 0 0 0
      2 5 4 3 CC CCC 0.0 0 0 0
      1 1 2 3 CH CCH 180.0 0 0 0
      1 2 1 7 CH CCH 0.0 0 0 0
      1 3 2 8 CH CCH 0.0 0 0 0
      1 4 3 9 CH CCH 0.0 0 0 0
      1 5 4 10 CH CCH 0.0 0 0 0
      1 6 5 11 CH CCH 0.0 0 0 0
    fractional
      3 0.000000 0.000000 0.000000 0 0 0
      3 0.333333 0.000000 0.000000 0 0 0
      3 0.666666 0.000000 0.000000 0 0 0
      3 0.000000 0.500000 0.000000 0 0 0
      3 0.333333 0.500000 0.000000 0 0 0
      3 0.666666 0.500000 0.000000 0 0 0
      3 0.166667 0.250000 0.050000 0 0 0
      3 0.500000 0.250000 0.050000 0 0 0
      3 0.833333 0.250000 0.050000 0 0 0
      3 0.166667 0.750000 0.050000 0 0 0
      3 0.500000 0.750000 0.050000 0 0 0
      3 0.833333 0.750000 0.050000 0 0 0
      3 0.000000 0.000000 0.100000 0 0 0
      3 0.333333 0.000000 0.100000 0 0 0
      3 0.666666 0.000000 0.100000 0 0 0
      3 0.000000 0.500000 0.100000 0 0 0
      3 0.333333 0.500000 0.100000 0 0 0
      3 0.666666 0.500000 0.100000 0 0 0
      3 0.166667 0.250000 0.150000 0 0 0
      3 0.500000 0.250000 0.150000 0 0 0
      3 0.833333 0.250000 0.150000 0 0 0
      3 0.166667 0.750000 0.150000 0 0 0
      3 0.500000 0.750000 0.150000 0 0 0
      3 0.833333 0.750000 0.150000 0 0 0
    constants
        ym1 3.68
    variables
        zm1 6.9032294
        CC 1.417
        CH 1.112
        CCH 120.0
        CCC 120.0
    constraints
        xm1 CC -1.0 3.903229
    %endblock Zmatrix
\end{verbatim}

Here the species 1, 2 and 3 represent H, C, and the metal of the
surface, respectively.

(Note: the above example shows the usefulness of symbolic names
for the relevant coordinates, in particular for those which are
allowed to vary. The current output options for Zmatrix information
work best when this approach is taken. By using a ``fixed'' symbolic
Zmatrix block and specifying the actual coordinates in a ``variables''
section, one can monitor the progress of the optimization and
easily reconstruct the coordinates of intermediate steps in the
original format.)

{\it Use:} Specifies the geometry of the system according to a Z-matrix
{\it Default value:} Geometry is not specified using a Z-matrix

\item[{\bf ZM.UnitsLength}] ({\it length}):
\index{ZM.UnitsLength@{\bf ZM.UnitsLength}}
Parameter that specifies the units of length used during Z-matrix input.

{\it Use:} This option allows the user to chose between inputing distances
in Bohr or Angstroms within the Z-matrix data block.

{\it Default value:} {\tt Bohr}

\item[{\bf ZM.UnitsAngle}] ({\it angle}):
\index{ZM.UnitsAngle@{\bf ZM.UnitsAngle}}
Parameter that specifies the units of angles used during Z-matrix input.

{\it Use:} This option allows the user to chose between inputing angles
in radians or degrees within the Z-matrix data block.

{\it Default value:} {\tt rad}

\end{description}



\subsubsection{Output of structural information}

{\sc Siesta} is able to generate several kinds of files containing
structural information (maybe too many).

\begin{itemize}

\item{\bf STRUCT\_OUT file:}
\index{Systemlabel.STRUCT\_OUT@{{\it Systemlabel}.STRUCT\_OUT}}
Siesta always produces a {\tt .STRUCT\_OUT} file with cell vectors in {\AA}
and atomic positions in fractional coordinates. This file, renamed to
{\it SystemLabel}.STRUCT\_IN can be used for crystal-structure input.
Note that the geometry reported is the last one for which forces and
stresses were computed.
See {\bf MD.UseStructFile}\index{MD.UseStructFile@{\bf MD.UseStructFile}}.

\item{\bf STRUCT\_NEXT\_ITER file:}
\index{Systemlabel.STRUCT\_NEXT\_ITER@{{\it Systemlabel}.STRUCT\_NEXT\_ITER}}
This file is always written, in the same format as {\tt .STRUCT\_OUT}
file. The only difference is that it contains the structural
information {\em after} it has been updated by the relaxation or the
molecular-dynamics
algorithms, and thus it could be used as input (renamed as
{\it SystemLabel}.STRUCT\_IN) for a continuation run, in the same way
as the {\tt XV} file.

See {\bf MD.UseStructFile}\index{MD.UseStructFile@{\bf MD.UseStructFile}}.

\item{\bf XV file:} The coordinates are always written in the {\it
  Systemlabel}.XV file, and overriden at every step.

\item{\bf OUT.UCELL.ZMATRIX file:}
\index{OUT.UCELL.ZMATRIX}@{{\it OUT.UCELL.ZMATRIX}}

This file is produced if the Zmatrix format is being used for
input. (Please note that {\it SystemLabel} is not used as a prefix.)
It contains the structural information in fdf form, with
blocks for unit-cell vectors and for Zmatrix coordinates. The
Zmatrix block is in a ``canonical'' form with the following
characteristics:

\begin{verbatim}
1. No symbolic variables or constants are used.
2. The position coordinates of the first atom in each molecule
   are absolute Cartesian coordinates.
3. Any coordinates in ``cartesian'' blocks are also absolute Cartesians.
4. There is no provision for output of constraints.
5. The units used are those initially specified by the user, and are
   noted also in fdf form.
\end{verbatim}

Note that the geometry reported is the last one for which forces and
stresses were computed.

\item{\bf NEXT\_ITER.UCELL.ZMATRIX file:}
\index{NEXT\_ITER.UCELL.ZMATRIX}@{{\it NEXT\_ITER.UCELL.ZMATRIX}}

A file with the same format as {\tt OUT.UCELL.ZMATRIX} but with
a possibly updated geometry.

\item The coordinates can be also accumulated
in the {\it Systemlabel}.MD or {\it Systemlabel}.MDX files
depending on {\bf WriteMDhistory}.

\item Additionally, several optional formats are supported:

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf WriteCoorXmol}] ({\it logical}):
\index{WriteCoorXmol@{\bf WriteCoorXmol}}\index{XMol@{\sc XMol}}
\index{JMol@{\sc JMol}}
If {\tt .true.} it originates the writing of an extra file
named {\it SystemLabel}{\tt .xyz} containing the final atomic
coordinates in a format directly readable by {\sc XMol}.\footnote{XMol
is under \copyright\ copyright of Research Equipment Inc., dba Minnesota
Supercomputer Center Inc.} Coordinates come out in {\AA}ngstr\"om
independently of what specified in {\bf AtomicCoordinatesFormat} and
in {\bf AtomCoorFormatOut}. There is a present {\sc Java} implementation
of {\sc XMol} called {\sc JMol}.

{\it Default value:} {\tt .false.}


\item[{\bf WriteCoorCerius}] ({\it logical}):
\index{WriteCoorCerius@{\bf WriteCoorCerius}}\index{Cerius2@{\sc Cerius2}}
If {\tt .true.} it originates the writing of an extra file
named {\it SystemLabel}{\tt .xtl} containing the final atomic
coordinates in a format directly readable by {\sc Cerius}.\footnote{{\sc
Cerius} is under \copyright\ copyright of Molecular Simulations Inc.}
Coordinates come out in
{\tt Fractional} format (the same as {\tt ScaledByLatticeVectors})
independently of what specified in {\bf AtomicCoordinatesFormat} and
in {\bf AtomCoorFormatOut}.
If negative coordinates are to be avoided, it has to be
done from the start by shifting all the coordinates rigidly
to have them positive, by using {\bf AtomicCoordinatesOrigin}.
See the {\sc Sies2arc}\index{Sies2arc@{\sc Sies2arc}} utility in the Util/
directory for generating .arc files for CERIUS animation.

{\it Default value:} {\tt .false.}


\item[{\bf WriteMDXmol}] ({\it logical}):
\index{WriteMDXmol@{\bf WriteMDXmol}}\index{XMol@{\sc XMol}}
If {\tt .true.} it causes the writing of an extra file
named {\it SystemLabel}{\tt .ANI} containing all the atomic
coordinates of the simulation in a format directly readable by
{\sc XMol} for animation.\index{animation} Coordinates come out in
{\AA}ngstr\"om independently of what is specified in
{\bf AtomicCoordinatesFormat} and in {\bf AtomCoorFormatOut}.
This file is accumulative even for different runs.

There is an alternative for animation by generating a .arc file for
CERIUS. It is through the {\sc Sies2arc}\index{Sies2arc@{\sc
    Sies2arc}} postprocessing utility in the Util/ directory, and it
requires the coordinates to be accumulated in the output file, i.e.,
WriteCoorStep = {\tt .true.}

{\it Default value:} {\tt .false.}

Note change with respect to previous versions. This option is no
longer coupled to {\bf WriteCoorStep}.

\end{description}

\end{itemize}

\subsubsection{Input of structural information from external files}

The structural information can be also read from external files. Note
that the NumberOfAtoms, NumberOfSpecies, and ChemicalSpeciesLabel
options are still mandatory in the fdf file.

\begin{itemize}

\item The XV file.
\index{MD.UseSaveXV@{\bf MD.UseSaveXV}} \index{reading saved data!XV}
The logical variable {\bf MD.UseSaveXV} instructs {\sc Siesta} to
read the atomic positions and velocities stored in file {\tt
SystemLabel.XV} by a previous run.

If the required file does not exist, a warning is printed but the
program does not stop. Overrides {\bf UseSaveData}, but can be
implicitly set by it.

{\it Default value:} {\tt .false.}

\item A .STRUCT\_IN file. The logical fdf variable {\bf UseStructFile}
  (for historical reasons, {\bf MD.UseStructFile} is also accepted,
  but deprecated)
  controls whether the structural information is read from an external
  file of name {\it SystemLabel}.STRUCT\_IN.  If \texttt{.true.}, all
  other structural information in the fdf file will be
  ignored.\index{UseStructFile@{\bf UseStructFile}}
  \index{Systemlabel.STRUCT\_IN@{{\it Systemlabel}.STRUCT\_IN}}

The format of the file is implied by the following code:

\begin{verbatim}
read(*,*) ((cell(ixyz,ivec),ixyz=1,3),ivec=1,3)  ! Cell vectors, in Angstroms
read(*,*) na
do ia = 1,na
   read(iu,*) isa(ia), dummy, xfrac(1:3,ia)  ! Species number
                                             ! Dummy numerical column
                                             ! Fractional coordinates
enddo
\end{verbatim}

{\it Warning:} Note that the resulting geometry could be clobbered if
an XV file is read after this file. It is up to the user to remove
any XV files.\index{MD.UseSaveXV@{\bf MD.UseSaveXV}}.

{\it Default value:} {\tt .false.}


\item A Zmatrix input file
{\bf MD.UseSaveZM} ({\it logical}):
\index{MD.UseSaveZM@{\bf MD.UseSaveZM}}
\index{reading saved data!ZM}
instructs the program to read the Zmatrix information stored
in file {\tt SystemLabel}.ZM by a previous run.

{\it Use:} If the required file does not exist, a warning is
printed but the program does not stop. Overrides {\bf UseSaveData},
but can be implicitly set by it.

{\it Warning:} Note that the resulting geometry could be clobbered if
an XV file is read after this file. It is up to the user to remove
any XV files.\index{MD.UseSaveXV@{\bf MD.UseSaveXV}}.

{\it Default value:} {\tt .false.}
\end{itemize}

\subsubsection{Input from a FIFO file}

See the ``Forces'' option in {\bf MD.TypeOfRun}.
Note that the NumberOfAtoms, NumberOfSpecies, and ChemicalSpeciesLabel
options are still mandatory in the fdf file.

\subsubsection{Precedence issues in structural input}
\index{structure input precedence issues}

\begin{itemize}
\item If the ``server'' option is active, it takes precedence over
everything (it will overwrite all other input with the information it
gets from the FIFO file).

\item If MD.UseSaveXV is active, it takes precedence over the options below.

\item If UseStructFile (or MD.UseStructFile) is active, it takes precedence
over the options below.

\item For atomic coordinates, the traditional and Zmatrix formats in
  the fdf file are mutually exclusive. If {\bf MD.UseSaveZM} is
  active, the contents of the ZM file, if found, take precedence over
  the Zmatrix information in the fdf file.

\end{itemize}

\subsubsection{Interatomic distances}

\begin{description}
\item[{\bf WarningMinimumAtomicDistance}] ({\it physical}):
\index{WarningMinimumAtomicDistance@{\bf WarningMinimumAtomicDistance}}
Fixes a threshold interatomic distance below which a warning
message is printed.

{\it Default value:} {\tt 1.0 Bohr}

\item[{\bf MaxBondDistance}] ({\it physical}):
\index{MaxBondDistance@{\bf MaxBondDistance}} {\sc Siesta} prints the
interatomic distances\index{interatomic distances}, up to a range of
{\tt MaxBondDistance}, to file {\tt SystemLabel.BONDS} upon first
reading the structural information, and to file {\tt
SystemLabel.BONDS\_FINAL} after the last geometry iteration. The
reference atoms are all the atoms in the unit cell. The routine now
prints the real location of the neighbor atoms in space, and not, as in
earlier versions, the location of the equivalent representative in the
unit cell.

{\it Default value:} {\tt 6.0 Bohr}

\end{description}

\subsection{$k$-point sampling}

These are options for the k-point grid used in the SCF cycle. For
other specialized grids, see the Macroscopic Polarization and Density
of States sections.

\begin{description}
\itemsep 10pt
\parsep 0pt


\item[{\bf kgrid\_cutoff}] ({\it real length}):
\index{kgrid\_cutoff@{\bf kgrid\_cutoff}}
Parameter which determines
the fineness of the k-grid used for Brillouin zone sampling.
It is half the length of the smallest lattice vector of the supercell
required to obtain the same sampling precision with a single k point.
Ref: Moreno and Soler, PRB 45, 13891 (1992).

{\it Use:} If it is zero, only the gamma point is used.  The resulting
k-grid is chosen in an optimal way, according to the method of Moreno
and Soler (using an effective supercell which is as spherical as
possible, thus minimizing the number of k-points for a given
precision). The grid is displaced for even numbers of effective mesh
divisions.  This parameter is not used if {\bf kgrid\_Monkhorst\_Pack}
is specified. If the unit cell changes during the calculation (for
example, in a cell-optimization run, the k-point
grid will change accordingly (see {\bf ChangeKgridInMD} for the case
of variable-cell molecular-dynamics runs, such as Parrinello-Rahman).
This is analogous to the changes in the
real-space grid, whose fineness is specified by an energy cutoff. If
sudden changes in the number of k-points are not desired, then the
Monkhorst-Pack data block should be used instead. In this case there
will be an implicit change in the quality of the sampling as the cell
changes. Both methods should be equivalent for a well-converged
sampling.

{\it Default value:} {\tt 0.0 Bohr}


\item[{\bf kgrid\_Monkhorst\_Pack}] ({\it data block}):
\index{kgrid\_Monkhorst\_Pack@{\bf kgrid\_Monkhorst\_Pack}}
Real-space supercell, whose reciprocal unit cell is that of the
k-sampling grid, and grid displacement for each grid coordinate.
Specified as an integer matrix and a real vector:

\begin{verbatim}
     %block kgrid_Monkhorst_Pack
        Mk(1,1)  Mk(2,1)  Mk(3,1)   dk(1)
        Mk(1,2)  Mk(2,2)  Mk(3,2)   dk(2)
        Mk(1,3)  Mk(2,3)  Mk(3,3)   dk(3)
     %endblock kgrid_Monkhorst_Pack
\end{verbatim}

where {\tt Mk(j,i)} are integers and {\tt dk(i)} are usually
either 0.0 or 0.5 (the program will warn the user if the displacements
chosen are not optimal).
The k-grid supercell is defined from {\tt Mk}
as in block {\bf SuperCell} above, i.e.:
$KgridSuperCell(ix,i) = \sum_j CELL(ix,j)*Mk(j,i)$.
Note again that the matrix indexes are inverted: each input line
gives the decomposition of a supercell vector in terms of the unit
cell vectors.


{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}.
The k-grid supercell is compatible and unrelated
(except for the default value, see below)
with the {\bf SuperCell} specifier. Both supercells are given in
terms of the CELL specified by the {\bf LatticeVectors} block.
If {\tt Mk} is the identity matrix and {\tt dk}
is zero, only the $\Gamma$ point of the {\bf unit} cell is used.
Overrides {\bf kgrid\_cutoff}

{\it Default value:} $\Gamma$ point of the (super)cell.
(Default used only when {\bf kgrid\_cutoff} is not defined).

\item[{\bf ChangeKgridInMD}] ({\it boolean}):
\index{ChangeKgridInMD@{\bf ChangeKgridInMD}}

If {\tt .true.}, the k-point grid is
recomputed at every iteration during MD runs that potentially
change the unit cell: Parrinello-Rahman, Nose-Parrinello-Rahman, and
Anneal. Regardless of the setting of this flag, the k-point grid
is always updated at every iteration of a variable-cell optimization
and after each step in a ``siesta-as-server'' run.

{\it Default value:} {\tt .false.} for historical reasons. The
rationale was to avoid sudden jumps in some properties when the
sampling changes, but if the calculation is well-converged there
should be no problems if the update is enabled.

\item[{\bf TimeReversalSymmetryForKpoints}] ({\it boolean}):
\index{TimeReversalSymmetryForKpoints@{\bf TimeReversalSymmetryForKpoints}}

If {\tt .true.}, the k-points in the BZ generated by the methods above
are paired as (k,-k) and only one member of the pair is retained. This
symmetry is valid in the absence of external magnetic fields or
spin-orbit interaction.

{\it Default value:} {\tt .true.} unless the option {\bf SpinSpiral} 
is used. In this case time-reversal-symmetry is broken explicitly.

\end{description}

\subsubsection{Output of k-point information}

\index{output!grid $\vec k$ points}
The coordinates of the $\vec k$ points used in the sampling
are always stored in the file SystemLabel.KP.

\begin{description}
\itemsep 10pt
\parsep 0pt
\item[{\bf WriteKpoints}] ({\it logical}):
\index{WriteKpoints@{\bf WriteKpoints}}\index{output!grid $\vec k$ points}
If {\tt .true.} it writes the coordinates of the $\vec k$ vectors
used in the grid for $k$-sampling, into the main output file.

{\it Default value:} {\tt .false.} (see {\bf LongOutput})

\end{description}

\vspace{5pt}
\subsection{Exchange-correlation functionals}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf XC.functional}] ({\it string}):
\index{XC.functional@{\bf XC.functional}}
Exchange-correlation functional type. May be {\tt LDA}
(local density approximation, equivalent to {\tt LSD}) or
{\tt GGA} (Generalized Gradient Approximation).

{\it Use:} Spin polarization is defined by SpinPolarized label for
both {\tt LDA} and {\tt GGA}. There is no difference between {\tt LDA}
and {\tt LSD}.

{\it Default value:} {\tt LDA}


\item[{\bf XC.authors}] ({\it string}):
\index{XC.authors@{\bf XC.authors}}
Particular parametrization of the
exchange-correlation functional. Options are:
\begin{itemize}
\item {\tt CA} (Ceperley-Alder) \index{CA}
equivalent to {\tt PZ} (Perdew-Zunger). \index{PZ}
Local density approximation.
Ref: Perdew and Zunger, PRB 23, 5075 (1981)
\item {\tt PW92} (Perdew-Wang-92). \index{PW92}
Local density approximation.\index{LDA}\index{LSD}
Ref: Perdew and Wang, PRB, 45, 13244 (1992)
\item {\tt PBE} (Perdew-Burke-Ernzerhof). Generalized gradients
approximation.  Ref: Perdew, Burke and Ernzerhof, PRL 77, 3865
(1996)\index{GGA} \index{PBE}
\item {\tt revPBE} (Revised Perdew-Burke-Ernzerhof). Generalized gradients
approximation.  Ref: Y. Zhang and W. Yang, PRL 80, 890
(1998)\index{GGA} \index{revPBE}
\item {\tt RPBE} (Revised Perdew-Burke-Ernzerhof). Generalized gradients
approximation.  Ref: Hammer, Hansen and Norskov PRB 59, 7413
(1999)\index{GGA} \index{RPBE}
\item {\tt WC} (Wu-Cohen modification of PBE functional). Generalized gradients
approximation.  Ref: Z. Wu and R.E. Cohen, PRB 73, 235116 (2006)
\index{GGA} \index{WC}
\item {\tt PBEsol} (Perdew-Burke-Ernzerhof for solids). Generalized gradients
approximation.  Ref: Perdew et al, PRL 100, 136406
(2008)\index{GGA} \index{PBEsol}
\item {\tt LYP} Generalized gradients approximation \index{BLYP}
that implements Becke gradient exchange functional (A. D.
Becke, Phys. Rev. A {\bf 38}, 3098 (1988)) and Lee, Yang, Parr
correlation functional (C. Lee, W. Yang, R. G. Parr, Phys. Rev. B
{\bf 37}, 785 (1988)), as modified by Miehlich, Savin, Stoll and Preuss,
Chem. Phys. Lett. {\bf 157}, 200 (1989). See also Johnson, Gill and Pople,
J. Chem. Phys. {\bf 98}, 5612 (1993). (Some errors were detected in this
last paper, so not all of their expressions correspond exactly to those
implemented in {\sc Siesta}).

\end{itemize}

{\it Use:} {\bf XC.functional} and {\bf XC.authors} must be compatible.

{\it Default value:} {\tt PZ}

\item[{\bf XC.hybrid}] ({\it data block}):
\index{XC.hybrid@{\bf XC.hybrid}}
This data block allows the user to create a ``cocktail'' functional by
mixing the desired amounts of exchange and correlation from each of
the functionals described under XC.authors. Note that these ``mixed''
functionals do {\em not} have the exact Hartree-Fock exchange which
is a key ingredient of the true ``hybrid'' functionals. The use of
the word ``hybrid'' in the label is unfortunate in this regard, and
might be deprecated in a future version.

The first line of the block must contain the number of functionals to
be mixed. On the subsequent lines the values of XC.functl and
XC.authors must be given and then the weights for the exchange and
correlation, in that order. If only one number is given then the same
weight is applied to both exchange and correlation.

The following is an example in which a 75:25 mixture of Ceperley-Alder
and PBE correlation is made, with an equal split of the exchange
energy:

\begin{verbatim}
     %block XC.hybrid
        2
        LDA CA  0.5 0.75
        GGA PBE 0.5 0.25
     %endblock XC.hybrid
\end{verbatim}

{\it Default value:} {\tt not hybrid}


\end{description}

\vspace{5pt}
\subsection{Spin polarization}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf SpinPolarized}] ({\it logical}):
\index{SpinPolarized@{\bf SpinPolarized}}
Logical variable to choose between spin unpolarized ({\tt .false.})
or spin polarized ({\tt .true.}) calculation.

{\it Default value:} {\tt .false.}


\item[{\bf NonCollinearSpin}] ({\it logical}):
  \index{NonCollinearSpin@{\bf NonCollinearSpin}}\index{spin}
  \index{spin!non-collinear}\index{LSD} If {\tt .true.}, non-collinear
  spin is described using spinor wavefunctions and $(2 \times 2)$ spin
  density matrices at every grid point.  Refs: T. Oda et al, PRL, {\bf
    80}, 3622 (1998); 
V. M. Garc\'{\i}a-Su\'arez et al, Eur. Phys. Jour. B {\bf 40}, 371 (2004);
V. M. Garc\'{\i}a-Su\'arez et al, Journal of
  Phys: Cond. Matt {\bf 16}, 5453 (2004). 
Not compatible with the {\tt  Diag.ParallelOverK} option 
{\it Default value:} {\tt .false.}


\item[{\bf FixSpin}] ({\it logical}):
\index{FixSpin@{\bf FixSpin}}\index{spin}
\index{fixed spin state}\index{LSD}
If {\tt .true.}, the calculation is done with a fixed value of the
spin of the system, defined by variable  {\bf TotalSpin}.
This option can only be used for collinear spin polarized
calculations.

{\it Default value:} {\tt .false.}

\item[{\bf TotalSpin}] ({\it real}):
\index{TotalSpin@{\bf TotalSpin}}
\index{spin}
\index{fixed spin state}\index{LSD}
Value of the imposed total spin polarization of the system (in units of the
electron spin, 1/2). It is only used
if {\bf FixSpin} = {\tt .true.}

{\it Default value:} 0.0

\item[{\bf SingleExcitation}] ({\it logical}):
\index{SingleExcitation@{\bf SingleExcitation}}
If true, {\sc Siesta} calculates a very rough approximation to
the lowest excited state by swapping the populations of the HOMO
and the LUMO. If there is no spin polarisation, it is half swap only.
It is done for the first spin component (up) and first k vector.

{\it Default value:} {\tt .false.}


\end{description}

\vspace{5pt}
\subsection{The self-consistent-field loop}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf Harris\_functional}] ({\it logical}):
\index{Harris\_functional@{\bf Harris\_functional}}
Logical variable to choose between self-consistent Kohn-Sham functional or
 non self-consistent Harris functional to calculate energies and forces.
\begin{itemize}
\item {\tt .false.} : Fully self-consistent Kohn-Sham functional.
\item {\tt .true.} : Non self consistent Harris functional. Cheap but
pretty crude for some systems. The forces are computed within the
Harris functional in the first SCF step. Only implemented for LDA in
the Perdew-Zunger parametrization.

When this option is choosen, the values of DM.UseSaveDM,
MaxSCFIterations, SCFMustConverge and DM.MixSCF1 are automatically set
up to False, 1, False and False respectively, no matter whatever other
specification are in the INPUT file.
\end{itemize}

{\it Default value:} {\tt .false.}


\item[{\bf MaxSCFIterations}] ({\it integer}):
\index{MaxSCFIterations@{\bf MaxSCFIterations}}
Maximum number of SCF\index{SCF} iterations per time step.

{\it Default value:} {\tt 50}

\item[{\bf SCFMustConverge}] ({\it logical}):
\index{SCFMustConverge@{\bf SCFMustConverge}}
Defines the behaviour if convergence is not reached in the maximum
number of SCF iterations. The default is to update the forces, perform
an MD or geometry optimisation step and carry on. When set to true
the calculation will stop on the first SCF convergence failure.

{\it Default value:} {\tt .false.}

\end{description}

\subsubsection{Mixing options}

\begin{description}

\item[{\bf DM.MixingWeight}] ({\it real}):\index{SCF!mixing}
\index{DM.MixingWeight@{\bf DM.MixingWeight}}\index{SCF!mixing!linear}
Proportion $\alpha$ of
output Density Matrix to be used for the input Density Matrix of
next SCF cycle (linear mixing):
$\rho^{n+1}_{in} = \alpha \rho^{n}_{out}
+(1 - \alpha) \rho^{n}_{in}$.

{\it Default value:} {\tt 0.25}

\item[{\bf DM.NumberPulay}] ({\it integer}):\index{Pulay mixing}
\index{DM.NumberPulay@{\bf DM.NumberPulay}}\index{SCF!mixing!Pulay}
It controls the Pulay convergence accelerator. Pulay mixing generally
accelerates convergence quite significantly, and can
reach convergence in cases where linear mixing cannot.
%One Pulay mixing will be performed every {\bf DM.NumberPulay} SCF
%iterations, the other iterations using linear mixing. If
%it is less than 2, only linear mixing is used.
The guess for the $n+1$ iteration is constructed using the
input and output matrices of the {\bf DM.NumberPulay} former
SCF cycles, in the following way:
$\rho^{n+1}_{in} = \alpha \bar{\rho}^{n}_{out}
+(1 - \alpha) \bar{\rho}^{n}_{in}$, where $\bar{\rho}^{n}_{out}$
and $\bar{\rho}^{n}_{in}$ are constructed from the previous
$N=${\bf DM.NumberPulay} cycles:
%
\begin{equation}
\bar{\rho}^{n}_{out} = \sum_{i=1}^N
\beta_i \rho_{out}^{(n-N+i)} \hspace{0.5truecm}; \hspace{0.5truecm}
\bar{\rho}^{n}_{in} = \sum_{i=1}^N
\beta_i \rho_{in}^{(n-N+i)}.
\nonumber
\end{equation}
%
The values of $\beta_i$ are obtained by minimizing the distance
between $\bar{\rho}^{n}_{out}$ and $\bar{\rho}^{n}_{in}$.
The value of $\alpha$ is given by variable {\bf DM.MixingWeight}.

If {\bf DM.NumberPulay} is 0 or 1, simple linear mixing is
performed.

{\it Default value:} {\tt 0}

\item[{\bf DM.Pulay.Avoid.First.After.Kick}] ({\it
  logical}):\index{SCF!mixing}
  \index{DM.Pulay.Avoid.First.After.Kick@{\bf
      DM.Pulay.Avoid.First.After.Kick}}\index{SCF!mixing} Controls
  whether the first density-matrix residual of the SCF cycle and the
  first residual after a kick are included in the Pulay history. It
  can be argued that in these cases the ``output'' DM might be
  significantly different from the ``input'' DM. To preserve backwards
  compatibility, these residuals are kept in the Pulay history unless
  this variable is activated.

{\it Default value:} {\tt .false.}


\item[{\bf DM.PulayOnFile}] ({\it logical}):
\index{DM.PulayOnFile@{\bf DM.PulayOnFile}}

{\bf NOTE:} This feature is temporarily disabled pending a proper
implementation that works well in parallel.

Store intermediate information of Pulay mixing in files
({\tt .true.}) or in memory ({\tt .false.}).
Memory storage can increase considerably the
memory requirements for large systems.
If files are used, the filenames will be
{\tt SystemLabel}.P1 and
{\tt SystemLabel}.P2,
where SystemLabel is the name associated
to parameter {\tt SystemLabel}.

{\it Default value:} {\tt .false.}

\item[{\bf DM.NumberBroyden}] ({\it integer}):\index{Broyden mixing}
\index{DM.NumberBroyden@{\bf DM.NumberBroyden}}\index{SCF!mixing!Broyden}
It controls the Broyden-Vanderbilt-Louie-Johnson
convergence accelerator, which is based on the use of past information
(up to {\bf DM.NumberBroyden} steps) to construct the input density
matrix for the next iteration.

See D.D. Johnson, Phys. Rev. B{\bf 38}, 12807 (1988), and references therein;
Kresse and Furthmuller, Comp. Mat. Sci {\bf 6}, 15 (1996).

If {\bf DM.NumberBroyden} is 0, the program performs linear mixings,
or, if requested, Pulay mixings.

Broyden mixing takes precedence over Pulay mixing if both are
specified in the input file.

{\bf Note:} The Broyden mixing algorithm is still in development,
notably with regard to the effect of its various modes of operation, and
the assigment of weights. In its default mode, its effectiveness is
very similar to Pulay mixing. As memory usage is not yet optimized,
casual users might want to stick with Pulay mixing for now.

{\it Default value:} {\tt 0}

\item[{\bf DM.Broyden.Cycle.On.Maxit}] ({\it logical}):
\index{DM.Broyden.Cycle.On.Maxit@{\bf DM.Broyden.Cycle.On.Maxit}}
\index{SCF!mixing!Broyden}
Upon reaching the maximum number of historical data sets which are
kept for Broyden mixing (see description of variable {\bf
  DM.NumberBroyden}), throw away the oldest and shift the rest to make
room for a new data set. This procedure tends, heuristically, to
perform better than the alternative, which is to re-start the Broyden
mixing algorithm from a first step of linear mixing.

{\it Default value:} {\tt .true.}

\item[{\bf DM.Broyden.Variable.Weight}] ({\it logical}):
\index{DM.Broyden.Variable.Weight@{\bf DM.Broyden.Variable.Weight}}
\index{SCF!mixing!Broyden}
If {\tt .true.}, the different historical data sets used in
the Broyden mixing (see description of variable {\bf
  DM.NumberBroyden}) are assigned a weight depending on the
norm of their residual ${\rho}^{n}_{out}-{\rho}^{n}_{in}$.

{\it Default value:} {\tt .true.}

\item[{\bf DM.NumberKick}] ({\it integer}):\index{Linear mixing kick}
\index{DM.NumberKick@{\bf DM.NumberKick}}
%\index{SCF!mixing!linear!Pulay!Broyden}
\index{SCF!mixing!linear}
Option to skip the Pulay (or Broyden) mixing earch certain number of iterations,
and use a linear mixing instead. Linear mixing is done
every {\bf DM.NumberKick} iterations, using a mixing coefficient
$\alpha$ given by variable {\bf DM.KickMixingWeight}
(instead of the usual mixing {\bf DM.MixingWeight}).
This allows in some difficult cases to bring the SCF out of
loops in which the selfconsistency is stuck.
If {\bf DM.MixingWeight}=0, no linear mix is used.

{\it Default value:} {\tt 0}

\item[{\bf DM.KickMixingWeight}] ({\it real}):\index{SCF!mixing!Pulay!Broyden}
\index{DM.KickMixingWeight@{\bf DM.KickMixingWeight}}
%\index{SCF!mixing!linear!Pulay!Broyden}
\index{SCF!mixing!linear}
Proportion $\alpha$ of
output Density Matrix to be used for the input Density Matrix of
next SCF cycle (linear mixing):
$\rho^{n+1}_{in} = \alpha \rho^{n}_{out}
+(1 - \alpha) \rho^{n}_{in}$, for linear mixing kicks within the
Pulay or Broyden mixing schemes.
This mixing is done every {\bf DM.NumberKick} cycles.

{\it Default value:} {\tt 0.50}


\item[{\bf DM.MixSCF1}] ({\it logical}):\index{SCF!mixing}
\index{DM.MixSCF1@{\bf DM.MixSCF1}}\index{SCF!mixing}
Logical variable to indicate whether mixing is done in the
first SCF cycle or not. Usually, mixing should not be done in
the first cycle, to avoid non-idempotency in density matrix
from Harris or previous steps. It can be useful, though,
for restarts of selfconsistency runs.

{\it Default value:} {\tt .false.}

\end{description}

\subsubsection{Initialization of the density-matrix}

The Density matrix can be:

\begin{verbatim}
    1. Synthesized directly from atomic occupations.
       (See the options below for spin considerations)
    2. Read from a .DM file (if the appropriate options are set)
    3. Extrapolated from (two) previous geometry steps
    3.a The DM of the previous geometry iteration

    In cases 2 and 3, a check is done to guarantee that the structure
    of the read or extrapolated DM conforms to the current sparsity.
    If it does not, the information is re-arranged.

    Special cases:
           Harris functional: The matrix is always initialized
           Force calculation: The DM should be written to disk
                              at the time of the "no displacement"
                              calculation and read from file at
                              every subsequent step.
           Variable-cell calculation:
             If the auxiliary cell changes, the DM is forced to be
             initialized (conceivably one could rescue some important
             information from an old DM, but it is too much trouble
             for now). NOTE that this is a change in policy with respect
             to previous versions of the program, in which a (blind?)
             re-use was allowed, except if 'ReInitialiseDM' was 'true'.
             Now 'ReInitialiseDM' is 'true' by default. Setting it to
             'false' is not recommended.

             In all other cases (including "server operation"), the
             default is to allow DM re-use (with possible extrapolation)
             from previous geometry steps.

             There is no re-use of the DM for "Forces", and "Phonon"
             dynamics types (i.e., the DM is re-initialized)

             For "CG" calculations, the default is not to extrapolate the
             DM (unless requested by setting 'DM.AllowExtrapolation' to
             "true"). The previous step's DM is reused.

             The fdf variables 'DM.AllowReuse' and 'DM.AllowExtrapolation'
             can be used to turn off DM re-use and extrapolation.

\end{verbatim}


\begin{description}

\item[{\bf DM.UseSaveDM}] ({\it logical}):
\index{DM.UseSaveDM@{\bf DM.UseSaveDM}}
\index{reading saved data!density matrix}
Instructs to read the density matrix stored in file
{\tt SystemLabel}.DM by a previous run.

{\it Use:} If the required file does not exist, a warning is
printed but the program does not stop. Overrides {\bf UseSaveData}.

{\it Default value:} {\tt .false.}


\item[{\bf DM.FormattedFiles}] ({\it logical}):
\index{DM.FormattedFiles@{\bf DM.FormattedFiles}}
\index{reading saved data!density matrix}
Instructs to use formatted files for reading and writing
the density matrix. In this case, the files are labelled
{\tt SystemLabel}.DMF.

{\it Use:} This makes for much larger files, and slower i/o. However, the
files are transferable between different computers, which is
not the case normally.

{\it Default value:} {\tt .false.}


\item[{\bf DM.FormattedInput}] ({\it logical}):
\index{DM.FormattedInput@{\bf DM.FormattedInput}}
\index{reading saved data!density matrix}
Instructs to use formatted files for reading the density
matrix.

{\it Use:} Overrides the value of {\bf DM.FormattedFiles}.

{\it Default value:} {\tt .false.}


\item[{\bf DM.FormattedOutput}] ({\it logical}):
\index{DM.FormattedInput@{\bf DM.FormattedOutput}}
\index{reading saved data!density matrix}
Instructs to use formatted files for writing the density
matrix.

{\it Use:} Overrides the value of {\bf DM.FormattedFiles}.

{\it Default value:} {\tt .false.}


\item[{\bf DM.InitSpinAF}] ({\it logical}):\index{spin}
\index{spin!initialization}\index{ferromagnetic initial DM}
\index{antiferromagnetic initial DM}
\index{DM.InitSpinAF@{\bf DM.InitSpinAF}}
It defines the initial spin density for a spin polarized calculation.
The spin density is initially constructed with the maximum possible
spin polarization for each atom in its atomic configuration.
This variable defines the relative orientation of the atomic
spins:

\begin{itemize}
\item {\tt .false.} gives ferromagnetic order (all spins up).
\item {\tt .true.} gives antiferromagnetic order. Up and down are
assigned according to order in the block
{\bf AtomicCoordinatesAndAtomicSpecies}: up for the odd atoms, down for even.
\end{itemize}

{\it Default value:} {\tt .false.}


\item[{\bf DM.InitSpin}] ({\it data block}):
\index{DM.InitSpin@{\bf DM.InitSpin}} It defines the
initial spin density for a spin polarized calculation atom by atom.
In the block there is one line per atom to be spin-polarized,
containing the atom index (integer, ordinal in the block
{\bf AtomicCoordinatesAndAtomicSpecies}) and the desired
initial spin-polarization (real, positive for spin up, negative for
spin down). A value larger than possible will be reduced
to the maximum possible polarization, keeping its sign.
Maximum polarization can also be given by introducing the
symbol {\tt +} or {\tt -} instead of the polarization value.
There is no need to include a line for every atom, only for
those to be polarized. The atoms not contemplated in the block will
be given non-polarized initialization.
For non-collinear spin, the spin direction may be specified for
each atom by the polar angles theta and phi, given as the last
two arguments in degrees. If not specified, theta=0 is assumed.
{\bf NonCollinearSpin} must be {\tt .true.} to use the spin direction.

Example:

\begin{verbatim}
     %block DM.InitSpin
        5  -1.   90.   0.   # Atom index, spin, theta, phi (deg)
        3   +    45. -90.
        7   -
     %endblock DM.InitSpin
\end{verbatim}

{\it Default value:} If present but empty, all atoms are not polarized.
If absent, {\bf DM.InitSpinAF} defines the polarization.

\item[{\bf DM.AllowReuse}] ({\it logical}):
\index{DM.AllowReuse@{\bf DM.AllowReuse}}
Controls whether density matrix information from previous geometry
iterations is re-used to start the new geometry's SCF cycle.

{\it Default value:} {\tt .true.}

\item[{\bf DM.AllowExtrapolation}] ({\it logical}):
\index{DM.AllowExtrapolation@{\bf DM.AllowExtrapolation}}
Controls whether density matrix information from two previous geometry
iterations is (linearly) extrapolated to start the new geometry's SCF cycle.

{\it Default value:} {\tt .true.}

Further information regarding the density-matrix re-use can be found
in the header of routine {\tt Src/new\_dm.F}.

\end{description}

\subsubsection{Initialization of the SCF cycle with charge densities}

\begin{description}
\item[{\bf SCF.Read.Charge.NetCDF}] ({\it logical}):
  \index{SCF.Read.Charge.NetCDF@{\bf SCF.Read.Charge.NetCDF}}
  \index{reading saved data!charge density} Instructs Siesta to read
  the charge density stored in the netCDF file {\tt
    Rho.IN.grid.nc}. This feature allows the easier re-use of
  electronic-structure information from a previous run. It is not
  necessary that the basis sets are ``similar'' (a requirement if
  density-matrices are to be read in).

{\it Use:} This is an experimental feature.  Until robust checks are
implemented, care must be taken to make sure that the FFT grids in the
.grid.nc file and in Siesta are the same.

{\it Default value:} {\tt .false.}

\item[{\bf SCF.Read.Deformation.Charge.NetCDF}] ({\it logical}):
  \index{SCF.Read.Deformation.Charge.NetCDF@{\bf
      SCF.Read.Deformation.Charge.NetCDF}} \index{reading saved
    data!deformation charge density} Instructs Siesta to read the
  deformation charge density stored in the netCDF file {\tt
    DeltaRho.IN.grid.nc}. This feature allows the easier re-use of
  electronic-structure information from a previous run. It is not
  necessary that the basis sets are ``similar'' (a requirement if
  density-matrices are to be read in). The deformation charge is
  particularly useful to give a good starting point for slightly
  different geometries.

{\it Use:} This is an experimental feature.  Until robust checks are
implemented, care must be taken to make sure that the FFT grids in the
.grid.nc file and in Siesta are the same.

{\it Default value:} {\tt .false.}

\end{description}



\subsubsection{Output of density matrix}
\index{output!density matrix}

\begin{description}
\item[{\bf WriteDM}] ({\it logical}): \index{WriteDM@{\bf WriteDM}}
\index{output!density matrix} It determines whether the density matrix
is output as a binary {\it Systemlabel}.DM file or not.

{\it Default value:} {\tt .true.}

\item[{\bf WriteDM.NetCDF}] ({\it logical}): \index{WriteDM.NetCDF@{\bf WriteDM.NetCDF}}
\index{output!density matrix} It determines whether the density matrix
(after the mixing step) is output as a DM.nc netCDF file or not.

The file is overwritten at every SCF step. Use the {\bf
WriteDM.History.NetCDF} option if a complete history is desired.

The DM.nc and standard DM file formats can be converted at will with
the programs in {\tt Util/DensityMatrix} directory. Note that the
DM values in the DM.nc file are in single precision.

{\it Default value:} {\tt .true.} if netCDF support is enabled (see Appendix).

\item[{\bf WriteDMHS.NetCDF}] ({\it logical}): \index{WriteDMHS.NetCDF@{\bf WriteDMHS.NetCDF}}
\index{output!density
  matrix}\index{output!Hamiltonian}\index{output!overlap matrix}
If true, the input density matrix, Hamiltonian, and output density matrix, are stored in a netCDF file
named {\tt DMHS.nc}. The file also contains the overlap matrix S.

The file is overwritten at every SCF step. Use the {\bf
  WriteDMHS.History.NetCDF} option if a complete history is desired.

{\it Default value:} {\tt .true.} if netCDF support is enabled (see Appendix).

\item[{\bf WriteDM.History.NetCDF}] ({\it logical}):
\index{WriteDM.History.NetCDF@{\bf WriteDM.History.NetCDF}}
\index{output!density matrix}\index{output!density matrix history} If
true, a series of netCDF files with names of the form {\tt DM-NNNN.nc}
is created to hold the complete history of the density matrix (after
mixing).  (See also {\bf WriteDM.NetCDF}). Each file corresponds to a
geometry step.

{\it Default value:} {\tt .false.}

\item[{\bf WriteDMHS.History.NetCDF}] ({\it logical}):
\index{WriteDMHS.History.NetCDF@{\bf WriteDMHS.History.NetCDF}}
\index{output!density matrix history}\index{output!Hamiltonian
history}\index{output!overlap matrix} If true, a series of netCDF
files with names of the form {\tt DMHS-NNNN.nc} is created to hold the
complete history of the input and output density matrix, and the
Hamiltonian.  (See also {\bf WriteDMHS.NetCDF}). Each file corresponds
to a geometry step. The overlap matrix is stored only once per SCF
cycle.

{\it Default value:} {\tt .false.}

\end{description}
\subsubsection{Convergence criteria}
\index{SCF convergence criteria}

\begin{description}
\item[{\bf DM.Tolerance}] ({\it real}):
\index{DM.Tolerance@{\bf DM.Tolerance}}
Tolerance of Density Matrix.
When the maximum difference between the output and the
input on each element of the DM
in a SCF cycle is smaller than DM.Tolerance,
the selfconsistency has been achieved.

{\it Default value:} {${\tt 10^{-4}}$}



\item[{\bf DM.Require.Energy.Convergence}] ({\it logical}):
\index{SCF!mixing!energy convergence}
\index{DM.Require.Energy.Convergence@{\bf DM.Require.Energy.Convergence}}
Logical variable to request an additional requirement for
self-consistency: it is considered achieved when the change in the total energy between cycles
of the SCF procedure is below {\bf DM.EnergyTolerance} and the
density matrix change criterion is also satisfied.

{\it Default value:} {\tt .false.}

\item[{\bf DM.Energy.Tolerance}] ({\it real energy}):
\index{DM.EnergyTolerance@{\bf DM.EnergyTolerance}}
If {\bf DM.Require.Energy.Convergence} is {\tt .true.}, then
self-consistency is achieved when the change in the total energy between cycles
of the SCF procedure is below this value and the
density matrix change criterion is also satisfied.

{\it Default value:} {${\tt 10^{-4}}$ eV}

\item[{\bf DM.Require.Harris.Convergence}] ({\it logical}):
\index{SCF!mixing!harris energy convergence}
\index{DM.Require.Harris.Convergence@{\bf DM.Require.Harris.Convergence}}
Logical variable to use the Harris energy as monitor of
self-consistency: this is considered achieved when the change in the Harris energy between cycles
of the SCF procedure is below {\bf DM.Harris.Tolerance}. No density
matrix change criterion is used.
This is useful if only energies are needed, as the Harris energy tends
to converge faster than the Kohn-Sham energy.
The user is responsible for using the correct energies in further
processing, e.g., the Harris energy if the Harris criterion is used.

To help in basis-optimization tasks, a new file BASIS\_HARRIS\_ENTHALPY
is provided, holding the same information as BASIS\_ENTHALPY but using
the Harris energy instead of the Kohn-Sham energy.

{\it Default value:} {\tt .false.}


\item[{\bf DM.Harris.Tolerance}] ({\it real energy}):
\index{DM.Harris.Tolerance@{\bf DM.Harris.Tolerance}}
If {\bf DM.Require.Harris.Convergence} is {\tt .true.}, then
self-consistency is achieved when the change in the Harris energy between cycles
of the SCF procedure is below this value.
This is useful if only energies are needed, as the Harris energy tends
to converge faster than the Kohn-Sham energy.

{\it Default value:} {${\tt 10^{-4}}$ eV}

\end{description}

\vspace{5pt}
\subsection{The real-space grid and the eggbox-effect}

{\sc Siesta} uses a finite 3D grid for the calculation of some
integrals and the representation of charge densities and potentials.
Its fineness is determined by its plane-wave cutoff, as
given by the {\bf MeshCutoff} option. It means that all periodic
plane waves with kinetic energy lower than this cutoff 
can be represented in the grid without aliasing. In turn,
this implies that if a function (e.g. the density or the 
effective potential) is an expansion of
only these plane waves, it can be Fourier transformed
back and forth without any approximation.

The existence of the grid causes the breaking of translational
symmetry (the egg-box effect, due to the fact that the density
and potential {\it do have} plane wave components above
the mesh cutoff).  This symmetry breaking is clear when
moving one single atom in an otherwise empty simulation cell. The
total energy and the forces oscillate with the grid periodicity when
the atom is moved, as if the atom were moving on an eggbox. In the
limit of infinitely fine grid (infinite mesh cutoff) this effect
disappears.

For reasonable values of the mesh cutoff, the effect of the eggbox
on the total energy or on the relaxed structure is normally unimportant.
However, it can affect substantially the process of relaxation, by
increasing the number of steps considerably, and can also spoil the
calculation of vibrations, usually much more demanding than relaxations.

The Util/Scripting/eggbox\_checker.py script can be used to diagnose
the eggbox effect to be expected for a particular
pseudopotential/basis-set combination.

Apart from increasing the mesh cutoff (see the {\bf MeshCutoff} option),
the following options might help in lessening a given eggbox problem. But
note also that a filtering of the orbitals and the relevant parts of
the pseudopotential and the pseudocore charge might be enough to solve
the issue (see Sect.~\ref{sec:filtering}).

\begin{description}

\item[{\bf MeshCutoff}] ({\it real energy}):
\index{MeshCutoff@{\bf MeshCutoff}}\index{grid}\index{mesh}
Defines the plane wave cutoff for the grid.

{\it Default value:} {\tt 100 Ry}

\item[{\bf MeshSubDivisions}] ({\it integer}):
  \index{MeshSubDivisions@{\bf
      MeshSubDivisions}}\index{grid}\index{mesh} Defines the number of
  sub-mesh points in each direction used to save index storage on the
  mesh. It affects the memory requirements and in some cases the CPU
  time, but should not affect the results.

{\it Default value:} {\tt 2}

NOTE: The default value might be a bit conservative. Users might
experiment with higher values (4, 6) to lower the memory and cputime
usage.

\item[{\bf GridCellSampling}] ({\it data block}):\index{egg-box effect}
\index{GridCellSampling@{\bf GridCellSampling}}\index{rippling}

It specifies points within the grid cell for a symmetrization sampling.

For a given grid the grid-cutoff convergence can be improved (and the
eggbox lessened) by recovering the lost symmetry: by symmetrizing the
sensitive quantities. The full symmetrization implies an integration
(averaging) over the grid cell. Instead, a finite sampling can be
performed.

It is a sampling of rigid displacements of the system with respect
to the grid. The original grid-system setup (one point of the grid
at the origin) is always calculated. It is the (0,0,0) displacement.
The block {\bf GridCellSampling} gives the additional displacements
wanted for the sampling. They are given relative to the grid-cell
vectors, i.e., (1,1,1) would displace to the next grid point across
the body diagonal, giving an equivalent grid-system situation
(a useless displacement for a sampling).

Examples: Assume a cubic cell, and therefore a (smaller) cubic grid cell.
If there is no block or the block is empty, then the original (0,0,0)
will be used only. The block:

\begin{verbatim}
     %block GridCellSampling
        0.5    0.5    0.5
     %endblock GridCellSampling
\end{verbatim}

would use the body center as a second point in the sampling. Or:


\begin{verbatim}
     %block GridCellSampling
        0.5    0.5    0.0
        0.5    0.0    0.5
        0.0    0.5    0.5
     %endblock GridCellSampling
\end{verbatim}

gives an fcc kind of sampling, and

\begin{verbatim}
     %block GridCellSampling
        0.5    0.0    0.0
        0.0    0.5    0.0
        0.0    0.0    0.5
        0.0    0.5    0.5
        0.5    0.0    0.5
        0.5    0.5    0.0
        0.5    0.5    0.5
     %endblock GridCellSampling
\end{verbatim}

gives again a cubic sampling with half the original side length.
It is not trivial to choose a right set of displacements so as
to maximize the new 'effective' cutoff. It depends on the
kind of cell. It may be automatized in the future, but it
is now left to the user, who introduces the displacements
manually through this block.

The quantities which are symmetrized are: ($i$) energy terms
that depend on the grid, ($ii$) forces, ($iii$) stress
tensor, and ($iv$) electric dipole.

The symmetrization is performed at the end of every SCF cycle. The
whole cycle is done for the (0,0,0) displacement, and, when the
density matrix is converged, the same (now fixed)
density matrix is used to obtain the desired quantities at the
other displacements (the density matrix itself is {\it not}
symmetrized as it gives a much smaller egg-box effect).
The CPU time needed for each displacement
in the {\bf GridCellSampling} block
is of the order of one extra SCF iteration.

{\it Default value:} Empty.


\item[{\bf EggboxRemove}] ({\it data block}):\index{egg-box effect}
\index{EggboxRemove@{\bf EggboxRemove}}\index{rippling}

For recovering translational invariance in an approximate way.

It works by substracting from Kohn-Sham's total energy (and forces) an
approximation to the eggbox energy, sum of atomic contributions.
Each atom has a predefined eggbox energy depending on where it sits on
the cell. This atomic contribution is species dependent and is
obviously invariant under grid-cell translations. Each species
contribution is thus expanded in the appropriate Fourier series.
It is important to have a smooth eggbox, for it to
be represented by a few Fourier components. A jagged egg-box (unless
very small, which is then unimportant) is often an
indication of a problem with the pseudo.

In the block there is one line per Fourier component. The first integer
is for the atomic species it is associated with. The other three
represent the reciprocal lattice vector of the grid cell (in units
of the basis vectors of the reciprocal cell). The real number is
the Fourier coefficient in units of the energy scale given in
{\bf EggboxScale} (see below), normally 1 eV.

The number and choice of Fourier components is free, as well as their
order in the block. One can choose to correct only some species and not
others if, for instance, there is a substantial difference in hardness
of the cores. The 0 0 0 components will add a species-dependent
constant energy per atom. It is thus irrelevant except if comparing
total energies of different calculations, in which case they
have to be considered with care (for instance by putting them all to zero,
i.e. by not introducing them in the list).
The other components average to zero representing no bias in the
total energy comparisons.

If the total
energies of the free atoms are put as 0 0 0 coefficients (with
spin polarisation if adequate etc.) the corrected total energy
will be the cohesive energy of the system (per unit cell).

{\it Example:} For a two species system, this example would give a quite
sufficent set in many instances (the actual values of the Fourier
coefficients are not realistic).

\begin{verbatim}
     %block EggBoxRemove
       1   0   0   0 -143.86904
       1   0   0   1    0.00031
       1   0   1   0    0.00016
       1   0   1   1   -0.00015
       1   1   0   0    0.00035
       1   1   0   1   -0.00017
       2   0   0   0 -270.81903
       2   0   0   1    0.00015
       2   0   1   0    0.00024
       2   1   0   0    0.00035
       2   1   0   1   -0.00077
       2   1   1   0   -0.00075
       2   1   1   1   -0.00002
     %endblock EggBoxRemove
\end{verbatim}

It represents an alternative to grid-cell sampling (above).
It is only approximate, but once the Fourier components for each
species are given, it does not represent any computational
effort (neither memory nor time), while the grid-cell sampling
requires CPU time (roughly one extra SCF step per point every
MD step).

It will be particularly helpful in atoms with substantial partial
core or semicore electrons.

{\it Use:} This technique as it stands should only be used for fixed cell
calculations.

For the time being, it is up to the user to obtain the Fourier
components to be introduced. They can be obtained by moving one
isolated atom through the cell to be used in the calculation
(for a give cell size, shape and mesh), once for each species.
The Util/Scripting/eggbox\_checker.py script can be used as a starting
point for this.

{\it Default value:} Empty.


\item[{\bf EggboxScale}] ({\it real energy}):\index{egg-box effect}
\index{EggboxScale@{\bf EggboxScale}}\index{rippling}

Defines the scale in which the Fourier components of the
egg-box energy are given in the {\bf EggboxRemove} block.

{\it Default value:} 1 eV.

\end{description}

\subsection{Matrix elements of the Hamiltonian and overlap}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf NeglNonOverlapInt}] ({\it logical}):
\index{NeglNonOverlapInt@{\bf NeglNonOverlapInt}}
Logical variable to neglect or compute interactions between orbitals
which do not overlap. These come from the KB projectors.
Neglecting them makes the Hamiltonian more sparse, and
the calculation faster.  {\bf Use with care}

{\it Default value:} {\tt .false.}

\item[{\bf SaveHS}] ({\it logical}):
\index{SaveHS@{\bf SaveHS}}\index{output!Hamiltonian \& overlap}
Instructs to write the Hamiltonian and overlap matrices, as well
as other data required to generate bands and density of states,
in file {\tt SystemLabel}.HSX. The HSX format is more
compact than the traditional HS, and the Hamiltonian,
overlap matrix, and relative-positions array (which is always output,
even for gamma-point only calculations) are in single precision.

The program {\tt hsx2hs} in {\tt Util/HSX} can be used to generate
an old-style HS file if needed.

{\sc Siesta} produces also an HSX file if the {\bf COOP.Write} option
is active.
\index{output!HSX file}

{\it Use:} File {\tt SystemLabel}.HS is only written, not read, by siesta.

{\it Default value:} {\tt .false.}

See also the {\bf WriteDMHS.NetCDF} and {\bf WriteDMHS.History.NetCDF}
options.
\end{description}

\subsubsection{The auxiliary supercell}

When using k-points, this auxiliary supercell is needed to compute properly
the matrix elements involving orbitals in different unit cells.
It is computed automatically by the program at every geometry step.

\begin{description}

\item[{\bf FixAuxiliaryCell}] ({\it logical}):
\index{FixAuxiliaryCell@{\bf FixAuxiliaryCell}}

Logical variable to control whether the auxiliary cell is changed
during a variable cell optimization.

\item[{\bf NaiveAuxiliaryCell}] ({\it logical}):
\index{NaiveAuxiliaryCell@{\bf NaiveAuxiliaryCell}}

If true, the program does not check whether the auxiliary cell
constructed with a naive algorithm is appropriate. This variable is
only useful if one wishes to reproduce calculations done with previous
versions of the program in which the auxiliary cell was not large
enough, as indicated by warnings such as:

\texttt{WARNING: orbital pair 1 341 is multiply connected}

Only small numerical differences in the results are to be expected.

Note that for gamma-point-only calculations there is an implicit
``folding'' of matrix elements corresponding to the images of orbitals
outside the unit cell. If information about the specific values of
these matrix elements is needed (as for COOP/COHP analysis), one has
to make sure that the unit cell is large enough.  
\index{COOP/COHP curves!Folding in Gamma-point calculations}

{\it Default value:} {\tt .false.}

\end{description}


\subsection{Calculation of the electronic structure}

{\sc Siesta} can use two methods to determine the electronic structure
of the system. One is standard diagonalization, which works for all
systems and has a cubic scaling with the size. The other is based on
the direct minimization of a special functional over a set of
localized functions. The latter scales in principle linearly with the
size of the system (only if the size is larger than the radial cutoff
for the local solution wave-functions), but is quite fragile and
substantially more difficult to use, and only works for systems with
clearly separated occupied and empty states.  The default is to use
diagonalization.

The calculation of the H and S matrix elements is always done with an
O(N) method. The actual scaling is not linear for small systems, but
it becomes O(N) when the system dimensions are larger than the scale
of orbital r$_c$'s.

The relative importance of both parts of the computation (matrix
elements and solution) depends on the size and quality of the
calculation. The mesh cutoff affects only the matrix-element
calculation; orbital cutoff radii affect the matrix elements and the
linear-scaling solver, but not the diagonalization; the need for {\bf
  k}-point sampling affects the solvers only, and the number of basis
orbitals affects them all.

In practice, the vast majority of users employ diagonalization for the
calculation of the electronic structure. This is so because the vast
majority of calculations would not benefit from the O(N) solver (most
of the calculations done are for intermediate system sizes, for varied
reasons e.g.  the long time scales needed in MD simulations for
growing system sizes).

Since it is used less often, bugs creeping into the O(N) solver have
been more resilient than in more popular bits of the code.  Work is
ongoing to clean and automate the O(N) process, to make the solver
more user-friendly and robust.


\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf SolutionMethod}] ({\it string}):
\index{SolutionMethod@{\bf SolutionMethod}}
Character string to chose between
diagonalization ({\tt diagon}) or Order-N ({\tt OrderN}) solution
of the LDA Hamiltonian.

{\it Default value:} {\tt diagon}



\end{description}

\subsubsection{Diagonalization options}
\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf NumberOfEigenStates}] ({\it integer}):
\index{NumberOfEigenStates@{\bf NumberOfEigenStates}}
This parameter allows the user to reduce the number of eigenstates
that are calculated from the maximum possible. The benefit is that,
for a gamma point calculation, the cost of the diagonalisation is
reduced by finding fewer eigenvectors. For example, during a geometry
optimisation, only the occupied states are required rather than the
full set of virtual orbitals. Note, that if the electronic temperature
is greater than zero then the number of partially occupied states
increases, depending on the band gap.
The value specified must greater than the number of occupied states
and less than the number of basis functions.

{\it Default value:} {\tt all orbitals}

\item[{\bf Use.New.Diagk}] ({\it logical}):
\index{Use.New.Diagk@{\bf Use.New.Diagk}}
Selects whether a more efficient diagonalization routine (with
intermediate storage of eigenvectors in netCDF format) is
used for the case of k-point sampling.

In order to use the new routine, netCDF support should be compiled in.
Specifying a number of eigenvectors to store is possible through
the symbol NumberOfEigenstates (see above). Note that for now, for safety, all
eigenvectors for a given k-point and spin are computed by the
diagonalization routine, but only that number specified by the user
are stored. If they are insufficient, the program stops.  A rule of
thumb to select the number of eigenvectors to store is to count the
number of electrons and divide by two, and then apply a "safety
factor" of around 1.1-1.2 to take into account fractional occupations
and band overlaps.

A new file {\tt OCCS} is produced with information about the number of
states occupied.

This is an experimental feature. Note: It is not compatible with the
{\tt Diag.Parallel.Over.K} option.

{\it Default value:} {\tt .false.}


\item[{\bf Diag.DivideAndConquer}] ({\it logical}):
\index{Diag.DivideAndConquer@{\bf Diag.DivideAndConquer}}
Logical to select whether the normal or Divide and Conquer algorithms are
used within the Lapack diagonalisation routines.

(Note: Some system library implementations of the D\&C algorithm are
buggy. It is advisable to use Siesta's own (fixed) version -- configure will
try to do that.)

{\it Default value:} {\tt true}

\item[{\bf Diag.AllInOne}] ({\it logical}):
\index{Diag.AllInOne@{\bf Diag.AllInOne}}
Logical to select whether a single call to lapack/scalapack is made to
perform the diagonalisation or whether the individual steps are controlled
by {\sc Siesta}. Normally this option should not need to be used.

{\it Default value:} {\tt false}

\item[{\bf Diag.NoExpert}] ({\it logical}):
\index{Diag.NoExpert@{\bf Diag.NoExpert}}
Logical to select whether the simple or expert versions of the lapack/
scalapack routines are used. Usually the expert routines are faster, but
may require slightly more memory.

{\it Default value:} {\tt false}

\item[{\bf Diag.PreRotate}] ({\it logical}):
\index{Diag.PreRotate@{\bf Diag.PreRotate}}
Logical to select whether the eigensystem is transformed according to
previously saved eigenvectors to create a near diagonal matrix and then
back transformed afterwards. This is included for future options, but
currently should not make any difference except to increase the
computational work!

{\it Default value:} {\tt false}

\item[{\bf Diag.Use2D}] ({\it logical}):
\index{Diag.Use2D@{\bf Diag.Use2D}}
Logical to select whether a 1-D or 2-D data decomposition should be used
when calling scalapack. The use of 2-D leads to superior scaling to
large numbers of processors and is therefore the default. This option
only influences the parallel performance.

{\it Default value:} {\tt true}

\end{description}

\subsubsection{Output of eigenvalues and wavefunctions}

This section focuses on the output of eigenvalues and wavefunctions
produced during the (last) iteration of the self-consistent cycle,
and associated to the appropriate k-point sampling.

For band-structure calculations (which typically use a different set
of k-points) and specific requests for wavefunctions, see
Secs.~\ref{sec:band-structure} and~\ref{sec:wf-output-user}, respectively.

The complete set of wavefunctions obtained during the last
iteration of the SCF loop will be written to a NetCDF file
{\tt WFS.nc} if the {\bf Diag.UseNewDiagk} option is in effect.

The complete set of wavefunctions obtained during the last
iteration of the SCF loop will be written to SystemLabel.fullBZ.WFSX
\index{WFSX file!fullBZ.WFSX@\texttt{fullBZ.WFSX}} 
if the {\bf COOP.write} option is in effect.

\begin{description}
\item[{\bf WriteEigenvalues}] ({\it logical}):
\index{WriteEigenvalues@{\bf WriteEigenvalues}}\index{output!eigenvalues}
If {\tt .true.} it writes the Hamiltonian eigenvalues for the sampling
$\vec k$ points, in the main output file.
If {\tt .false.}, it writes them in the file {\it Systemlabel}.EIG,
which can be used by the {\sc Eig2DOS}\index{Eig2DOS@{\sc Eig2DOS}} postprocessing
utility (in the Util/Eig2DOS directory) for obtaining the density of
states.\index{density of states}

{\it Use:} Only if {\bf SolutionMethod} is {\tt diagon}.

{\it Default value:} {\tt .false.} (see {\bf LongOutput})

\end{description}

\subsubsection{Occupation of electronic states and Fermi level}
\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf OccupationFunction}]({\it string}):
\index{OccupationFunction@{\bf OccupationFunction}}
\index{ElectronicTemperature@{\bf ElectronicTemperature}}
String variable to select the function that determines the occupation
of the electronic states. Two options are available:
\begin{itemize}
\item {\tt FD}: The usual Fermi-Dirac occupation function is used.
\item {\tt MP}: The occupation function proposed by Methfessel and
Paxton (Phys. Rev. B, {\bf 40}, 3616 (1989)), is used.
\end{itemize}
The smearing of the electronic occupations is done, in both cases,
using an energy width defined by the {\bf ElectronicTemperature}
variable. Note that, while in the case of Fermi-Dirac, the occupations
correspond to the physical ones if the electronic temperature is
set to the physical temperature of the system, this is not the case
in the Methfessel-Paxton function. In this case, the tempeature
is just a mathematical artifact to obtain a more accurate
integration of the physical quantities at a lower cost. In
particular, the Methfessel-Paxton scheme has the advantage
that, even for quite large smearing temperatures, the
obtained energy is very close to the physical energy at T=0.
Also, it allows a much faster convergence with respect to
k-points, specially for metals. Finally, the convergence to
selfconsistency is very much improved (allowing the use
of larger mixing coefficients).

For the Methfessel-Paxton case, one can use relatively large
values for the {\bf ElectronicTemperature} parameter. How large
depends on the specific system. A guide can be found in the
article by J. Kresse and J. Furthm\"uller, Comp. Mat. Sci.
{\bf 6}, 15 (1996).

If Methfessel-Paxton smearing is used, the order of
the corresponding Hermite polynomial expansion must also be chosen
(see description of variable {\bf OccupationMPOrder}).

We finally note that, in both cases (FD and MP), once a finite
temperature has been chosen, the relevant energy is not the Kohn-Sham
energy, but the Free energy. In particular, the
atomic forces are derivatives of the Free energy, not the KS
energy. See R. Wentzcovitch {\it et al.}, Phys. Rev. B {\bf 45},
11372 (1992); S. de Gironcoli, Phys. Rev. B {\bf 51}, 6773 (1995);
J. Kresse and J. Furthm\"uller, Comp. Mat. Sci.
{\bf 6}, 15 (1996),
for details.


{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}

{\it Default value:} {\tt FD}

\item[{\bf OccupationMPOrder}]({\it integer}):
\index{OccupationMPOrder@{\bf OccupationMPOrder}}
\index{OccupationFunction@{\bf OccupationFunction}}
Order of the Hermite-Gauss polynomial expansion for the
electronic occupation functions in the Methfessel-Paxton
scheme (see Phys. Rev. B  {\bf 40}, 3616 (1989)).
Specially for metals, higher order expansions provide better convergence
to the ground state result, even with larger smearing
temperatures, and provide also better convergence with k-points.


{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}
and {\bf OccupationFunction} =  {\tt MP}

{\it Default value:} {\tt 1}



\item[{\bf ElectronicTemperature}] ({\it real temperature or energy}):
\index{ElectronicTemperature@{\bf ElectronicTemperature}}
\index{OccupationFunction@{\bf OccupationFunction}}
Temperature for Fermi-Dirac or Methfessel-Paxton
distribution. Useful specially for
metals, and to accelerate selfconsistency in some cases.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}

{\it Default value:} {\tt 300.0 K}
pp

\end{description}

\subsubsection{Order(N) calculations}

The Ordern(N) subsystem is quite fragile and only works for systems
with clearly separated occupied and empty states. Note also that the
option to compute the chemical potential automatically does not yet
work in parallel.

\begin{description}
\itemsep 10pt
\parsep 0pt
\item[{\bf ON.functional}] ({\it string}):
\index{ON.functional@{\bf ON.functional}}
Choice of order-N minimization functionals:
\begin{itemize}
\item {\tt Kim}:\index{Kim@{\tt Kim}}
Functional of Kim, Mauri and Galli, PRB 52, 1640 (1995).
\item {\tt Ordejon-Mauri}:\index{Ordejon-Mauri@{\tt Ordejon-Mauri}}
Functional of Ordej\'on et al, or Mauri et al, see PRB 51, 1456 (1995).
The number of localized wave functions (LWFs) used must coincide with
$N_{el}/2$ (unless spin polarized).
For the initial assignment of LWF centers to atoms, atoms
with even number of electrons, n, get n/2 LWFs. Odd atoms
get (n+1)/2 and (n-1)/2 in an alternating sequence, ir order
of appearance (controlled by the input in the atomic coordinates block).

\item {\tt files}:\index{files (ON.functional)@{\tt files} (ON.functional)}
Reads localized-function information from a file and
chooses automatically the functional to be used.
\end{itemize}

{\it Use:} Used only if {\bf SolutionMethod} = {\tt ordern}

{\it Default value:} {\tt Kim}

\item[{\bf ON.MaxNumIter}] ({\it integer}):
\index{ON.MaxNumIter@{\bf ON.MaxNumIter}}
Maximum number of iterations
in the conjugate minimization of the electronic
energy, in each SCF cycle.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} {\tt 1000}

\item[{\bf ON.etol}] ({\it real}):
\index{ON.etol@{\bf ON.etol}}
Relative-energy tolerance in the conjugate minimization of the electronic
energy. The minimization finishes if
\hspace{0.2truecm} $2 (E_n - E_{n-1}) / (E_n + E_{n-1}) \leq $ ON.etol.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} ${\tt 10^{-8}}$

\item[{\bf ON.eta}] ({\it real energy}):
\index{ON.eta@{\bf ON.eta}}
Fermi level parameter of Kim
{\it et al.}. This should be in the energy gap, and tuned to obtain
the correct number of electrons. If the calculation is spin polarised,
then separate Fermi levels for each spin can be specified.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} {\tt 0.0 eV}

\item[{\bf ON.eta\_alpha}] ({\it real energy}):
\index{ON.eta\_alpha@{\bf ON.eta\_alpha}}
Fermi level parameter of Kim {\it et al.} for alpha spin electrons.
This should be in the energy gap, and tuned to obtain
the correct number of electrons. Note that if the Fermi
level is not specified individually for each spin then the
same global eta will be used.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} {\tt 0.0 eV}

\item[{\bf ON.eta\_beta}] ({\it real energy}):
\index{ON.eta\_beta@{\bf ON.eta\_beta}}
Fermi level parameter of Kim {\it et al.} for beta spin electrons.
This should be in the energy gap, and tuned to obtain
the correct number of electrons. Note that if the Fermi
level is not specified individually for each spin then the
same global eta will be used.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} {\tt 0.0 eV}

\item[{\bf ON.RcLWF}] ({\it real legth}):
\index{ON.RcLWF@{\bf ON.RcLWF}}\index{Localized Wave Functions}
Localization redius for the Localized Wave Functions (LWF's).

{\it Use:} Used only if  {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} {\tt 9.5 Bohr}

\item[{\bf ON.ChemicalPotential}] ({\it logical}):
\index{ON.ChemicalPotential@{\bf ON.ChemicalPotential}}
\index{Chemical Potential}
Specifies whether to calculate an order-{\it N} estimate of the
Chemical Potential, by the projection method
(Goedecker and Teter, PRB {\bf 51}, 9455 (1995);
Stephan, Drabold and Martin, PRB {\bf 58}, 13472
(1998)). This is
done by expanding the Fermi function (or density matrix)
at a given temperature, by means of Chebyshev
polynomials\index{Chebyshev Polynomials}, and imposing a
real space truncation on the density matrix.
To obtain a realistic estimate, the temperature
should be small enough (typically, smaller than
the energy gap), the localization range large enough
(of the order of the one you would use for the Localized Wannier
Functions), and the order of the polynomial expansion
sufficiently large (how large depends on the temperature;
typically, 50-100).

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}.

{\it Default value:} {\tt .false.}

{\bf Note:} This option does not work in parallel. An alternative
is to obtain the approximate value of the chemical potential using
an initial diagonalization.


\item[{\bf ON.ChemicalPotentialUse}] ({\it logical}):
\index{ON.ChemicalPotentialUse@{\bf ON.ChemicalPotentialUse}}
\index{Chemical Potential}
Specifies whether to use the calculated estimate of the
Chemical Potential, instead of the parameter
{\bf ON.eta}\index{ON.eta@{\bf ON.eta}}
for the order-{\it N} energy functional minimization.
This is useful if you do not know the position
of the Fermi level, typically in the beginning
of an order-{\em N} run.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}.
Overrides the value of {\bf ON.eta}.
Overrides the value of {\bf ON.ChemicalPotential}, setting
it to {\tt .true.}.

{\it Default value:} {\tt .false.}

{\bf Note:} This option does not work in parallel. An alternative
is to obtain the approximate value of the chemical potential using
an initial diagonalization.

\item[{\bf ON.ChemicalPotentialRc}]  ({\it real length}):
\index{ON.ChemicalPotentialRc@{\bf ON.ChemicalPotentialRc}}
\index{Chemical Potential}
Defines the cutoff radius for the density matrix or Fermi
operator in the calculation of the estimate of the
Chemical Potential.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN}
and {\bf ON.ChemicalPotential} or  {\bf ON.ChemicalPotentialUse}
= {\tt .true.}

{\it Default value:} {\tt 9.5 Bohr}.

\item[{\bf ON.ChemicalPotentialTemperature}]  ({\it real temperature
or energy}):
\index{ON.ChemicalPotentialTemperature@{\bf ON.ChemicalPotentialTemperature}}
\index{Chemical Potential}
Defines the temperature to be used in the Fermi function expansion
in the calculation of the estimate of the Chemical Potential.
To have an accurate results, this temperature should be smaller
than the gap of the system.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN},
and {\bf ON.ChemicalPotential} or  {\bf ON.ChemicalPotentialUse} =
{\tt .true.}

{\it Default value:} {\tt 0.05 Ry}.

\item[{\bf ON.ChemicalPotentialOrder}] ({\it integer}):
\index{ON.ChemicalPotentialOrder@{\bf ON.ChemicalPotentialOrder}}
\index{Chemical Potential}
Order of the Chebishev expansion to calculate the estimate
of the Chemical Potential.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt OrderN},
and {\bf ON.ChemicalPotential} or  {\bf ON.ChemicalPotentialUse} =
{\tt .true.}

{\it Default value:} {\tt 100}

\item[{\bf ON.LowerMemory}] ({\it logical}):
\index{ON.LowerMemory@{\bf ON.LowerMemory}}\index{Lower order N memory}
If .true., then a slightly reduced memory algorithm is used in the
3-point line search during the order N minimisation. Only affects
parallel runs.

{\it Use:} Used only if  {\bf SolutionMethod} = {\tt OrderN}

{\it Default value:} {\tt .false.}


\end{description}

{\bf Output of localized wavefunctions}

\index{Localized Wave Functions}
At the end of each conjugate gradient minimization of the energy
functional, the LWF's are stored on disk. These can be used as an
input for the same system in a restart, or in case something goes
wrong.  The LWF's are stored in sparse form in file SystemLabel.LWF

It is important to keep very good care of this file, since the first
minimizations can take MANY steps. Loosing them will mean performing
the whole minimization again. It is also a good practice to save it
periodically during the simulation, in case a mid-run restart is
necessary.

\begin{description}

\item[{\bf ON.UseSaveLWF}] ({\it logical}):
\index{ON.UseSaveLWF@{\bf ON.UseSaveLWF}}
\index{reading saved data!localized wave functions (order-$N$)}
\index{Restart of O(N) calculations}
Instructs to read the localized wave functions stored in file
{\tt SystemLabel}.LWF by a previous run.

{\it Use:} Used only if {\bf SolutionMethod} is {\tt OrderN}.
If the required file does not exist, a warning is
printed but the program does not stop. Overrides {\bf UseSaveData}.

{\it Default value:} {\tt .false.}

\end{description}

\subsection{Band-structure analysis}
\label{sec:band-structure}

This calculation of the band structure is performed optionally after
the geometry loop finishes, and the output information written
to the SystemLabel.bands file (see below for the format).

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf BandLinesScale}] ({\it string}):
\index{BandLinesScale@{\bf BandLinesScale}}
Specifies the scale of the k vectors given in {\bf BandLines}
and {\bf BandPoints} below.
The options are:
\begin{itemize}
\item {\tt pi/a} (k-vector coordinates are given in Cartesian
coordinates, in units of $\pi/a$, where $a$ is the lattice constant)
\item {\tt ReciprocalLatticeVectors} (k vectors are given in
reciprocal-lattice-vector coordinates)
\end{itemize}

{\it Default value:} {\tt pi/a}

{\bf Note:} You might need to define explicitly a LatticeConstant tag
in your fdf file if you do not already have one, and make it
consistent
with the scale of the k-points and any unit-cell vectors you might
have already defined.

\item[{\bf BandLines}] ({\it data block}):
\index{BandLines@{\bf BandLines}}
Specifies the lines along which band energies are calculated
(usually along high-symmetry directions).
An example for an FCC lattice is:

\begin{verbatim}
     %block BandLines
       1  1.000  1.000  1.000  L        # Begin at L
      20  0.000  0.000  0.000  \Gamma   # 20 points from L to gamma
      25  2.000  0.000  0.000  X        # 25 points from gamma to X
      30  2.000  2.000  2.000  \Gamma   # 30 points from X to gamma
     %endblock BandLines
\end{verbatim}

where the last column is an optional LaTeX label for use in the band plot.
If only given points (not lines) are required, simply specify 1 in the
first column of each line. The first column of the first line must be
always 1.

{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}.
The band k points are unrelated and compatible with any k-grid used
to calculate the total energy and charge density.
This block is overriden by {\bf BandPoints} if both are present.

{\it Default value:} No band energies calculated.

\item[{\bf BandPoints}] ({\it data block}):
\index{BandPoints@{\bf BandPoints}}
Band energies are calculated for the list of arbitrary $k$ points
given in the block. Units defined by {\bf BandLinesScale} as
for {\bf BandLines}. The generated {\it Systemlabel}.{\tt bands} file
will contain the $k$ point coordinates (in a.u.) and the corresponding
band energies (in eV). Example:

\begin{verbatim}
     %block BandPoints
        0.000  0.000  0.000   # This is a comment. eg this is gamma
        1.000  0.000  0.000
        0.500  0.500  0.500
     %endblock BandPoints
\end{verbatim}

{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}.
The band $k$ points are unrelated and compatible with any k-grid used
to calculate the total energy and charge density. If both are present, this
block supersedes {\bf BandLines}.

{\it Default value:} No band energies calculated.

\item[{\bf WriteKbands}] ({\it logical}):
\index{WriteKbands@{\bf WriteKbands}}\index{output!band $\vec k$ points}
If {\tt .true.} it writes the coordinates of the $\vec k$ vectors
defined for band plotting, to the main output file.

{\it Use:} Only if {\bf SolutionMethod} is {\tt diagon}.

{\it Default value:} {\tt .false.} (see {\bf LongOutput})


\item[{\bf WriteBands}] ({\it logical}): \index{WriteBands@{\bf
    WriteBands}}\index{output!band structure} If {\tt .true.} it
  writes the Hamiltonian eigenvalues corresponding to the $\vec k$
  vectors defined for band plotting, in the main output file.
  \index{band structure}

{\it Use:} Only if {\bf SolutionMethod} is {\tt diagon}.

{\it Default value:} {\tt .false.} (see {\bf LongOutput})


\end{description}


\subsubsection{Format of the .bands file}

\begin{verbatim}

FermiEnergy (all energies in eV) \\
kmin, kmax (along the k-lines path, i.e. range of k in the band plot) \\
Emin, Emax (range of all eigenvalues) \\
NumberOfBands, NumberOfSpins (1 or 2), NumberOfkPoints \\
k1, ((ek(iband,ispin,1),iband=1,NumberOfBands),ispin=1,NumberOfSpins) \\
k2, ek \\
 . \\
 . \\
 . \\
klast, ek \\
NumberOfkLines \\
kAtBegOfLine1, kPointLabel \\
kAtEndOfLine1, kPointLabel \\
  . \\
  . \\
  . \\
kAtEndOfLastLine, kPointLabel \\
\end{verbatim}

\noindent
The {\sc gnubands}\index{gnubands@{\tt gnubands}} postprocessing
utility program (found in the Util/Bands directory) reads the {\it
  Systemlabel}.bands for plotting.  See the {\bf BandLines} data
descriptor above for more information.

\subsubsection{Output of wavefunctions associated to bands}
\label{sec:wf-bands}

The user can optionally request that the wavefunctions corresponding
to the computed bands be written to file. 
They are written to the {\it SystemLabel}.bands.WFSX file
\index{WFSX file!bands.WFSX@\texttt{bands.WFSX}} 
(see section below for the
format). The relevant options are:

\begin{description}

\item[{\bf WFS.Write.For.Bands}] ({\it logical}):
\index{WFS.Write.For.Bands@{\bf WFS.Write.For.Bands}}
\index{output of wave functions for bands}
Instructs the program to compute and write the wave functions
associated to the bands specified (by a {\bf BandLines} or a {\bf
  BandPoints} block) to the file {\tt SystemLabel.bands}.WFSX.

The information in this file might be useful, among other things, to
generate ``fatbands'' plots, in which both  band eigenvalues and
information about orbital projections is presented.
\index{fatbands}
 See the
\texttt{fat} program in the \texttt{Util/COOP} directory for details.

{\it Default value:} {\tt .false.}

\item[{\bf WFS.Band.Min}] ({\it integer}):
\index{WFS.Band.Min@{\bf WFS.Band.Min}}
\index{output of wave functions for bands}
Specifies the lowest band index of the wave-functions to be written to 
the file {\tt SystemLabel.bands}.WFSX for each k-point (all k-points
in the band set are affected). 

{\it Default value:} {\tt 1}

\item[{\bf WFS.Band.Max}] ({\it integer}):
\index{WFS.Band.Max@{\bf WFS.Band.Max}}
\index{output of wave functions for bands}
Specifies the highest band index of the wave-functions to be written to 
the file {\tt SystemLabel.bands}.WFSX for each k-point (all k-points
in the band set are affected).

{\it Default value:} {\tt (the number of orbitals)}

\end{description}


\subsection{Output of selected wavefunctions}
\label{sec:wf-output-user}

The user can optionally request that specific wavefunctions are
written to file. These wavefunctions are re-computed after the
geometry loop (if any) finishes, using the last (presumably converged)
density matrix produced during the last self-consistent field loop
(after a final mixing). They are written to the
SystemLabel.selected.WFSX file (see below for the format).
\index{WFSX file!selected.WFSX@\texttt{selected.WFSX}} 

Note that the complete set of wavefunctions obtained during the last
iteration of the SCF loop will be written to SystemLabel.fullBZ.WFSX
if the {\bf COOP.write} option is in effect.

Note that the complete set of wavefunctions obtained during the last
iteration of the SCF loop will be written to a NetCDF file
{\tt WFS.nc} if the {\bf Diag.UseNewDiagk} option is in effect.

\begin{description}

\item[{\bf WaveFuncKPointsScale}] ({\it string}):
\index{WaveFuncKPointsScale@{\bf WaveFuncKPointsScale}}
Specifies the scale of the k vectors given in
{\bf WaveFuncKPoints} below.
The options are:
\begin{itemize}
\item {\tt pi/a} (k-vector coordinates are given in Cartesian
coordinates, in units of $\pi/a$, where $a$ is the lattice constant)
\item {\tt ReciprocalLatticeVectors} (k vectors are given in
reciprocal-lattice-vector coordinates)
\end{itemize}

{\it Default value:} {\tt pi/a}


\item[{\bf WaveFuncKPoints}] ({\it data block}):
\index{WaveFuncKPoints@{\bf WaveFuncKPoints}}
Specifies the k-points at which the electronic wavefunction
coefficients are written.
An example for an FCC lattice is:

\begin{verbatim}
     %block WaveFuncKPoints
     0.000  0.000  0.000  from 1 to 10   # Gamma wavefuncs 1 to 10
     2.000  0.000  0.000  1 3 5          # X wavefuncs 1,3 and 5
     1.500  1.500  1.500                 # K wavefuncs, all
     %endblock WaveFuncKPoints
\end{verbatim}

The index of a wavefunction is defined by its energy, so that the
first one has lowest energy.

The user can also narrow the energy-range used with the {\bf
  WFS.Energy.Min} and {\bf WFS.Energy.Max} options (both take an
energy (with units) as extra argument -- see
section~\ref{sec:coop}). Care should be taken to make sure that the
actual values of the options make sense.

The output of the wavefunctions in described in Section \ref{subsec:wf}

{\it Use:} Used only if {\bf SolutionMethod} = {\tt diagon}.
These k points are unrelated and compatible with any k-grid used
to calculate the total energy,  charge density and band structure.

{\it Default value:} No wavefunctions are written.

\item[{\bf WriteWaveFunctions}] ({\it logical}):
  \index{WriteWaveFunctions@{\bf WriteWaveFunctions}}
  \index{output!wave functions} If {\tt .true.} it writes to the
  output file a list of the wavefunctions actually written to the
{\it Systemlabel}.selected.WFSX file, which is always produced.

{\it Use:} Only if {\bf SolutionMethod} is {\tt diagon}.

{\it Default value:} {\tt .false.} (see {\bf LongOutput})


\end{description}

The unformatted WFSX file contains the information of the
k-points for which wavefunctions coefficients are written, and the
energies and coefficients of each wavefunction which was specified in
the input file (see {\bf WaveFuncKPoints}\index{WaveFuncKPoints@{\bf
    WaveFuncKPoints}} descriptor above). It also contains information
on the atomic species and the orbitals for postprocessing purposes.

\index{WFSX file}
{\bf NOTE:} The WFSX file is in a more compact form than the old WFS,
and the wavefunctions are output in single precision. The {\tt
  Util/WFS/wfsx2wfs} program can be used to convert to the old format.

\noindent
The readwf\index{readwf} and readwfsx\index{readwfsx} postprocessing
utilities programs (found in the Util/WFS directory) read the WFS or WFSX
files, respectively, and generate a readable file.


\vspace{5pt}
\subsection{Densities of states}

\subsubsection{Total density of states}
There are several options to obtain the
total density of states:
\begin{itemize}
\index{output!eigenvalues}
\item The Hamiltonian eigenvalues for the SCF sampling $\vec k$ points can be
dumped into SystemLabel.EIG in a format analogous to SystemLabel.bands,
but without the kmin, kmax, emin, emax information, and without
the abscissa. The {\sc Eig2DOS}\index{Eig2DOS@{\sc Eig2DOS}}
postprocessing utility can be then used to obtain the density of
states.\index{density of states}
See the {\bf WriteEigenvalues} descriptor.
%
\item As a side-product of a partial-density-of-states calculation
  (see below)
\item As one of the files produced by the {\tt Util/COOP/mprop} during
  the off-line analysis of the electronic structure. This method
  allows the flexibility of specifying energy ranges and resolutions
  at will, without re-running {\sc Siesta} See Sec.~\ref{sec:coop}.
\end{itemize}

\subsubsection{Partial (projected) density of states}

There are two options to obtain the partial density of states
\begin{itemize}
\item Using the options below
\item Using the {\tt Util/COOP/mprop} program the off-line analysis of
  the electronic structure in PDOS mode. This method allows the
  flexibility of specifying energy ranges, orbitals, and resolutions
  at will, without re-running {\sc Siesta}. See Sec.~\ref{sec:coop}.
\end{itemize}

\begin{description}
\itemsep 10pt
\parsep 0pt
\item[{\bf ProjectedDensityOfStates}] ({\it block}):
\index{ProjectedDensityOfStates@{\bf ProjectedDensityOfStates}}
\index{output!projected density of states}

Instructs to write the Total Density Of States (Total DOS) and the
Projected Density Of States (PDOS) on the basis orbitals,
between two given energies,
in files {\tt SystemLabel}.DOS and
{\tt SystemLabel}.PDOS, respectively.
The block must be a single line with the energies of the range for
PDOS projection,
(relative to the program's zero, i.e. the same as the eigenvalues
printed by the program), the peak width (an energy) for broadening
the eigenvalues, the number of points in the energy window,
and the energy units.
An example is:

\begin{verbatim}
     %block ProjectedDensityOfStates
        -20.00  10.00  0.200  500  eV
     %endblock ProjectedDensityOfStates
\end{verbatim}

By default the projected density of states is generated for the same
grid of points in reciprocal space as used for the SCF calculation.
However, a separate set of K-points, usually on a finer grid, can
be generated using one of the options \textbf{PDOS.kgrid\_cutoff} or
\textbf{PDOS.kgrid\_Monkhorst\_Pack}. The format of these options is
exactly the same as for \textbf{kgrid\_cutoff} and
\textbf{kgrid\_Monkhorst\_Pack}, respectively. Note that if a gamma
point calculation is being used in the SCF part, especially as part
of a geometry optimisation, and this is then to
be run with a grid of K-points for the PDOS calculation it is more
efficient to run the SCF phase first and then restart to perform the
PDOS evaluation using the density matrix saved from the SCF phase.

{\it Use:} The two energies of the range must be ordered, with lowest
first.

{\it Output:} The Total DOS is dumped into a file
called {\tt SystemLabel}.DOS. The format of this file is:

Energy value, Total DOS (spin up), Total DOS (spin down)

The Projected Density Of States for all the orbitals in the unit cell
is dumped sequentially into a file called {\tt SystemLabel}.PDOS. This
file is structured using spacing and xml tags. A machine-readable (but
not very human readable) xml file {\tt pdos.xml} is also
produced. Both can be processed by the program in {\tt
  Util/pdosxml}. The .PDOS file can be processed by utilites in {\tt
  Util/Contrib/APostnikov}.

In all cases, the units for the DOS are (number of states/eV), and the
Total DOS, $g \left(\epsilon\right)$, is normalized as follows:

\begin{eqnarray}
   \int_{-\infty}^{+\infty} g \left(\epsilon\right) d\epsilon =
   number \;\; of \;\; basis \;\; orbitals \;\; in \;\;  unit \;\; cell \;\;
   \nonumber \\
\end{eqnarray}


{\it Default value:} PDOS not calculated nor written.
\end{description}


\subsubsection{Local density of states}

The LDOS is formally the DOS weighted by the amplitude of the
corresponding wavefunctions at different points in space, and is then
a function of energy and position. {\sc Siesta} can output the LDOS
integrated over a range of energies.  This information can be used to
obtain simple STM images in the Tersoff-Hamann approximation (See {\tt
  Util/STM/simple-stm}).

\begin{description}
\item[{\bf LocalDensityOfStates}] ({\it block}):
\index{LocalDensityOfStates@{\bf LocalDensityOfStates}}
\index{output!local density of states}
Instructs to write the LDOS, integrated between two given energies,
at the mesh used by DHSCF,
in file {\tt SystemLabel}.LDOS. This file can be read by routine IORHO,
which may be used by an application program in later versions.
The block must be a single line with the energies of the range for
LDOS integration
(relative to the program's zero, i.e. the same as the eigenvalues
printed by the program) and their units.
An example is:

\begin{verbatim}
     %block LocalDensityOfStates
        -3.50  0.00   eV
     %endblock LocalDensityOfStates
\end{verbatim}

{\it Use:} The two energies of the range must be ordered,
with lowest first.
File {\tt SystemLabel}.LDOS is only written, not read, by siesta.

{\it Default value:} LDOS not calculated nor written.

\end{description}


\subsection{Options for chemical analysis}

\subsubsection{Mulliken charges and overlap populations}
\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf WriteMullikenPop}] ({\it integer}):
\index{WriteMullikenPop@{\bf WriteMullikenPop}}\index{Mulliken population
analysis}\index{output!Mulliken analysis}
It determines the level of Mulliken population analysis printed:
\begin{itemize}
\item 0 = None
\item 1 = atomic and orbital charges
\item 2 = 1 + atomic overlap pop.
\item 3 = 2 + orbital overlap pop.
\end{itemize}
The order of the orbitals in the population lists is defined
by the order of atoms. For each atom, populations for PAO orbitals and
double-$z$, triple-$z$, etc... derived from them are displayed first for
all the angular momenta. Then, populations for perturbative polarization
orbitals are written.
Within a $l$-shell be aware that the order is not
conventional, being $y$, $z$, $x$ for $p$ orbitals, and
$xy$, $yz$, $z^2$, $xz$, and $x^2-y^2$ for $d$ orbitals.

{\it Default value:} {\tt 0} (see {\bf LongOutput})


\item[{\bf MullikenInSCF}] ({\it logical}):
\index{MullikenInSCF@{\bf MullikenInSCF}}
If true, the Mulliken populations will be written for every SCF step
at the level of detail specified in {\bf WriteMullikenPop}. Useful
when dealing with SCF problems, otherwise too verbose.

{\it Default value:} {\tt .false.}

\end{description}

\subsubsection{Voronoi and Hirshfeld atomic population analysis}
\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf WriteHirshfeldPop}] ({\it logical}): 
\index{WriteHirshfeldPop@{\bf WriteHirshfeldPop}}\index{Hirshfeld population
analysis}\index{output!Hirshfeld analysis} 
%
If {\tt .true.}, the program calculates and prints the Hirshfeld {\bf
  net} atomic populations on each atom in the system. For a definition
of the Hirshfeld charges, see Hirshfeld, Theo Chem Acta {\bf 44}, 129
(1977) and Fonseca et al, J. Comp. Chem. {\bf 25}, 189 (2003).
Hirshfeld charges are more reliable than Mulliken charges, specially
for large basis sets.  The number printed is the total net charge of
the atom: the variation from the neutral charge, in units of $|e|$:
positive (negative) values indicate deficiency (excess) of electrons
in the atom.

{\it Default value:} {\tt .false.} 


\item[{\bf WriteVoronoiPop}] ({\it logical}): 
\index{WriteVoronoiPop@{\bf WriteVoronoiPop}}\index{Voronoi population
analysis}\index{output!Voronoi analysis} 
%
If {\tt .true.}, the program calculates and prints the Voronoi {\bf
  net} atomic populations on each atom in the system. For a definition
of the Voronoi charges, see Bickelhaupt et al, Organometallics {\bf
  15}, 2923 (1996) and Fonseca et al, J. Comp. Chem. {\bf 25}, 189
(2003).  Voronoi charges are more reliable than Mulliken charges,
specially for large basis sets.  The number printed is the total net
charge of the atom: the variation from the neutral charge, in units of
$|e|$: positive (negative) values indicate deficiency (excess) of
electrons in the atom.

{\it Default value:} {\tt .false.}

\end{description}

The Hirshfeld and Voronoi populations (partial charges) are computed
by default only at the end of the program (i.e., for the final
geometry, after self-consistency). The following options allow more control:

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf PartialChargesAtEveryGeometry}] ({\it logical}):
  \index{PartialChargesAtEveryGeometry@{\bf
      PartialChargesAtEveryGeometry}}\index{Voronoi population
      analysis}\index{output!Voronoi analysis}\index{Hirshfeld
      population analysis}\index{output!Hirshfeld analysis}

The Hirshfeld and Voronoi populations are computed after
self-consistency is achieved, for all the geometry steps.

{\it Default value:} {\tt .false.}

\item[{\bf PartialChargesAtEveryScfStep}] ({\it logical}):
  \index{PartialChargesAtEveryScfStep@{\bf
      PartialChargesAtEveryScfStep}}\index{Voronoi population
    analysis}\index{output!Voronoi analysis}\index{Hirshfeld
    population analysis}\index{output!Hirshfeld analysis}

The Hirshfeld and Voronoi populations are computed for every
step of the self-consistency process.

{\it Default value:} {\tt .false.}

\end{description}

{\bf Performance note:}
The default behavior (computing at the end of the program) involves
an extra calculation of the charge density.
%

\subsubsection{Crystal-Orbital overlap and hamilton populations (COOP/COHP)}
\label{sec:coop}
\index{COOP/COHP curves}

These curves are quite useful to analyze the electronic structure to
get insight about bonding characteristics. See the {\tt Util/COOP}
directory for more details. The {\bf COOP.Write} option must be
activated to get the information needed.

References:

\begin{itemize}
\item Original COOP reference:
Hughbanks, T.; Hoffmann, R., J. Am. Chem. Soc., 1983, 105, 3528.
\item Original COHP reference: Dronskowski, R.; Blöchl, P. E., J. Phys. Chem., 1993, 97, 8617.
\item A tutorial introduction: Dronskowski, R. Computational Chemistry of Solid State
Materials; Wiley-VCH: Weinheim, 2005.
\item Online material maintained by R. Dronskowski's group: {\tt http://www.cohp.de/}
\end{itemize}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf COOP.Write}] ({\it logical}):
\index{COOP.Write@{\bf COOP.Write}}
\index{output!Information for COOP/COHP curves}
Instructs the program to generate  {\tt SystemLabel.fullBZ}.WFSX (packed
wavefunction file) and  {\tt SystemLabel}.HSX (H, S and X\_~{ij} file),
to be processed by {\tt Util/COOP/mprop} to generate COOP/COHP curves,
(projected) densities of states, etc.

The WFSX file is in a more compact form than the usual WFS, and the
wavefunctions are output in single precision. The {\tt Util/wfsx2wfs}
program can be used to convert to the old format.
The HSX file is in a more compact form than the usual HS, and the
Hamiltonian, overlap matrix, and relative-positions array (which is
always output, even for gamma-point only calculations) are in
single precision.

{\it Default value:} {\tt .false.}

The user can narrow the energy-range used (and save some file space)
by using the {\bf WFS.Energy.Min} and {\bf WFS.Energy.Max} options (both take an
energy (with units) as extra argument), and/or the {\bf WFS.Band.Min} and
{\bf WFS.Band.Max} options. Care should be taken to make sure that the 
actual values of the options make sense.

Note that the band range options could also affect the output of
wave-functions associated to bands (see section~\ref{sec:wf-bands}),
and that the energy range options could also affect the output of
user-selected wave-functions with the {\bf WaveFuncKpoints} block (see
section~\ref{sec:wf-output-user}).

\item[{\bf WFS.Energy.Min}] ({\it physical energy}):
\index{WFS.Energy.Min@{\bf WFS.Energy.Min}}
Specifies the lowest value of the energy (eigenvalue) of the wave-functions to be written to 
the file {\tt SystemLabel.fullBZ}.WFSX for each k-point (all k-points
in the BZ sampling are affected). 

{\it Default value:} $-\infty$

\item[{\bf WFS.Energy.Max}] ({\it physical energy}):
\index{WFS.Energy.Max@{\bf WFS.Energy.Max}}
Specifies the highest value of the energy (eigenvalue) of the wave-functions to be written to 
the file {\tt SystemLabel.fullBZ}.WFSX for each k-point (all k-points
in the BZ sampling are affected).

{\it Default value:} $+\infty$

\item[{\bf WFS.Band.Min}] ({\it integer}):
\index{WFS.Band.Min@{\bf WFS.Band.Min}}
Specifies the lowest band index of the wave-functions to be written to 
the file (in this context) {\tt SystemLabel.fullBZ}.WFSX for each k-point (all k-points
in the BZ sampling are affected). 

{\it Default value:} {\tt 1}

\item[{\bf WFS.Band.Max}] ({\it integer}):
\index{WFS.Band.Max@{\bf WFS.Band.Max}}
Specifies the highest band index of the wave-functions to be written to 
the file (in this context) {\tt SystemLabel.fullBZ}.WFSX for each k-point (all k-points
in the BZ sampling are affected).

{\it Default value:} {\tt (the number of orbitals)}

\end{description}


\vspace{5pt}
\subsection{Optical properties}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf OpticalCalculation}] ({\it logical}):\index{Dielectric function,
optical absorption}
If specified, the imaginary part of the dielectric function
will be calculated and stored in a file called {\it Systemlabel}.{\bf EPSIMG}.
The calculation is performed using the simplest approach based on the
dipolar transition matrix elements between different eigenfunctions
of the self-consistent Hamiltonian. For molecules the calculation
is performed using the position operator matrix elements, while
for solids the calculation is carried out in the momentum space
formulation.
Corrections due to the non-locality of the pseudopotentials
are introduced in the usual way.

{\it Default value:} {\tt false}

\item[{\bf Optical.EnergyMinimum}] ({\it real energy}):
\index{Optical.EnergyMinimum@{\bf Optical.EnergyMinimum}}
This specifies the minimum of the energy range in which
the frequency spectrum will be calculated.

{\it Default value:} 0 Ry.

\item[{\bf Optical.EnergyMaximum}] ({\it real energy}):
\index{Optical.EnergyMaximum@{\bf Optical.EnergyMaximum}}
This specifies the maximum of the energy range in which
the frequency spectrum will be calculated.

{\it Default value:} 10 Ry.

\item[{\bf Optical.Broaden}] ({\it real energy}):
\index{Optical.Broaden@{\bf Optical.Broaden}}
If this is value is set then a Gaussian broadening will be
applied to the frequency values.

{\it Default value:} 0 Ry.

\item[{\bf Optical.Scissor}] ({\it real energy}):
\index{Optical.Scissor@{\bf Optical.Scissor}}
Because of the tendency of DFT calculations to under estimate
the band gap, a rigid shift of the unoccupied states, known as
the scissor operator, can be added to correct the gap and
thereby improve the calculated results. This shift is only
applied to the optical calculation and no where else within
the calculation.

{\it Default value:} 0 Ry.

\item[{\bf Optical.NumberOfBands}] ({\it integer}):
\index{Optical.NumberOfBands@{\bf Optical.NumberOfBands}}
This option controls the number of bands that are included in
the optical property calculation. Clearly this number must be
larger than the number of occupied bands and less than or
equal to the number of basis functions (which determines the
number of unoccupied bands available). Note, while including
all the bands may be the most accurate choice this will also
be the most expensive!

{\it Default value:} All bands.

\item[{\bf Optical.Mesh}] ({\it data block}):
\index{Optical.Mesh@{\bf Optical.Mesh}}
This block contains 3 numbers that determine the mesh size
used for the integration across the Brillouin zone. For
example:

\begin{verbatim}
        %block  Optical.Mesh
          5 5 5
        %endblock  Optical.Mesh
\end{verbatim}

The three values represent the number of mesh points in
the direction of each reciprocal lattice vector.

{\it Default value:} Empty in general. For atoms
or molecules a k-sampling of only one point is assumed.

\item[{\bf Optical.OffsetMesh}] ({\it logical}):
\index{Optical.OffsetMesh@{\bf Optical.OffsetMesh}}
If set to true, then the mesh is offset away from the
gamma point for odd numbers of points.

{\it Default value:} {\tt false}

\item[{\bf Optical.PolarizationType}] ({\it string}):
\index{Optical.PolarizationType@{\bf Optical.PolarizationType}}
This option has three possible values that represent the
type of polarization to be used in the calculation. The options
are {\bf polarized}, which implies the application of an electric
field in a given direction, {\bf unpolarized}, which implies the
propagation of light in a given direction, and {\bf polycrystal}.
In the case of the first two options a direction in space must
be specified for the electric field or propagation using the
{\it Optical.Vector} data block.

{\it Default value:} {\tt polycrystal}

\item[{\bf Optical.Vector}] ({\it data block}):
\index{Optical.Vector@{\bf Optical.Vector}}
This block contains 3 numbers that specify the vector direction
for either the electric field or light propagation, for a polarized
or unpolarized calculation, respectively. A typical block might look
like:

\begin{verbatim}
        %block  Optical.Vector
          1.0 0.0 0.5
        %endblock  Optical.Vector
\end{verbatim}

{\it Default value:} Empty.

\end{description}

\vspace{5pt}
\subsection{Macroscopic polarization}

\begin{description}

\item[{\bf PolarizationGrids}] ({\it data block}):
\index{PolarizationGrids@{\bf PolarizationGrids}}
\index{bulk polarization}\index{Berry phase}
If specified, the macroscopic polarization will be calculated using the
geometric Berry phase approach (R.D. King-Smith, and D. Vanderbilt,
PRB {\bf 47}, 1651 (1993)). In this method the electronic
contribution to the macroscopic polarization, along a given direction,
is calculated using
a discretized version of the formula
\begin{equation}
\label{pol_formula}
    P_{e,\parallel}={ifq_e \over 8\pi^3} \int_A d{\bf k}_\perp
    \sum_{n=1}^M \int_0^{|G_\parallel|} dk_{\parallel}
     \langle u_{{\bf k} n} |{\delta \over \delta k_{\parallel}} |
      u_{{\bf k} n} \rangle
\end{equation}
where $f$ is the occupation (2 for a non-magnetic system),
$q_e$ the electron charge, $M$ is the number of occupied bands (the
system {\bf must} be an insulator), and $u_{{\bf k} n}$ are
the periodic Bloch functions. ${\bf G}_\parallel$ is the shortest
reciprocal vector along the chosen direction.

As it can be seen in formula (\ref{pol_formula}), to compute each
component of the polarization we must perform a surface integration
of the result of a 1-D integral in the selected direction.
The grids for the calculation along the direction of each of the
three lattice vectors are specified in the block
{\bf PolarizationGrids}.
\begin{verbatim}
     %block PolarizationGrids
        10   3  4      yes
         2  20  2       no
         4   4 15
     %endblock PolarizationGrids
\end{verbatim}

All three grids must be specified, therefore a 3$\times$3 matrix of
integer numbers must be given: the first row specifies the grid that
will be used to calculate the polarization along the direction of the
first lattice vector, the second row will be used for the calculation
along the the direction of the second lattice vector, and the third
row for the third lattice vector.  The numbers in the diagonal of the
matrix specifie the number of points to be used in the one dimensional
line integrals along the different directions. The other numbers
specifie the mesh used in the surface integrals.  The last column
specifies if the bidimensional grids are going to be diplaced from the
origin or not, as in the Monkhorst-Pack algorithm (PRB {\bf 13}, 5188
(1976)).  This last column is optional.  If the number of points in
one of the grids is zero, the calculation will not be performed for
this particular direction.

For example, in the given example, for the computation in the
direction of the first lattice vector, 15 points will be used for the
line integrals, while a 3$\times$4 mesh will be used for the surface
integration. This last grid will be displaced from the origin, so
$\Gamma$ will not be included in the bidimensional integral. For the
directions of the second and third lattice vectors, the number of
points will be 20 and 2$\times$2, and 15 and 4$\times$4, respectively.

It has to be stressed that the macroscopic polarization can only be
meaningfully calculated using this approach for insulators.
Therefore, the presence of an energy gap is necessary, and no band can
cross the Fermi level. The program performs a simple check of this
condition, just by counting the electrons in the unit cell ( the
number must be even for a non-magnetic system, and the total spin
polarization must have an integer value for spin polarized systems),
however is the responsability of the user to check that the system
under study is actually an insulator (for both spin components if spin
polarized).

The total macroscopic polarization, given in the output of the
program, is the sum of the electronic contribution (calculated as the
Berry phase of the valence bands), and the ionic contribution, which
is simply defined as the sum of the atomic positions within the unit
cell multiply by the ionic charges ($\sum_i^{N_a} Z_i {\bf r}_i$).  In
the case of the magnetic systems, the bulk polarization for each spin
component has been defined as
\begin{equation}
       {\bf P}^\sigma = {\bf P}_e^\sigma +
   {1 \over 2} \sum_i^{N_a}  Z_i {\bf r}_i
\end{equation}
$N_a$ is the number of atoms in the unit cell, and ${\bf r}_i$ and
$Z_i$
are the positions and charges of the ions.

It is also worth noting, that the macroscopic polarization given by
formula (\ref{pol_formula}) is only defined modulo a ``quantum" of
polarization (the bulk polarization per unit cell is only well defined
modulo $fq_e${\bf R}, being {\bf R} an arbitrary lattice
vector). However, the experimentally observable quantities are
associated to changes in the polarization induced by changes on the
atomic positions (dynamical charges), strains (piezoelectric tensor),
etc... The calculation of those changes, between different
configurations of the solid, will be well defined as long as they are
smaller than the ``quantum", i.e. the perturbations are small enough
to create small changes in the polarization.

{\it Use:} Only compatible with {\bf SolutionMethod} = diagon.\\
{\it Default value:} Empty. No calculation performed.

\item[{\bf BornCharge}] ({\it logical}):\index{Born effective charges}
\index{BornCharge@{\bf BornCharge}}
If true, the Born effective charge tensor is calculated for each atom
by finite differences, by calculating the change in electric polarization
(see {\bf PolarizationGrids}) induced by the small displacements generated
for the force constants calculation (see {\bf MD.TypeOfRun} = {\tt FC}):
\begin{equation}\label {eq:effective_charge}
Z^*_{i,\alpha,\beta}=\frac{\Omega_0}{e} \left. {\frac{\partial{P_\alpha}}
{\partial{u_{i,\beta}}}}\right|_{q=0}
\end{equation}
where e is the charge of an electron and $\Omega_0$ is the unit cell volume.

To calculate the Born charges it is necessary to specify both the Born
charge flag and the mesh used to calculate the polarization, for example:
\begin{verbatim}
%block PolarizationGrids
7  3  3
3  7  3
3  3  7
%endblock PolarizationGrids
BornCharge True
\end{verbatim}

The Born effective charge matrix is then written to the file
{\it SystemLabel}.{\tt BC}.

The method by which the polarization is calculated may introduce an arbitrary
phase (polarization quantum), which in general is far larger than the change
in polarization which results from the atomic displacement. It is removed
during the calculation of the Born effective charge tensor.

The Born effective charges allow the calculation of LO-TO splittings and
infrared activities. The version of the Vibra utility code in which these
magnitudes are calculated is not yet distributed with {\sc Siesta}, but can be
obtained form Tom Archer (archert@tcd.ie).

{\it Use:} Only used if {\bf MD.TypeOfRun} is {\tt FC}.

{\it Default value:} {\tt false}

\end{description}

\vspace{5pt}
\subsection{Systems with net charge or dipole, and electric fields}

\begin{description}

\item[{\bf NetCharge}] ({\it real}):
\index{NetCharge@{\bf NetCharge}}\index{Charge of the system}
Specify the net charge of the system (in units of $|e|$).
For charged systems, the energy converges very slowly
versus cell size. For molecules or atoms, a Madelung
correction term is applied to the energy to make it converge
much faster with cell size (this is done only if
the cell is SC, FCC or BCC). For other cells, or for
periodic systems (chains, slabs or bulk), this energy
correction term can not be applied, and the user is warned
by the program.   It is not advised to do charged systems
other than atoms and molecules in SC, FCC or BCC cells,
unless you know what you are doing.

{\it Use:}
For example, the F$^-$ ion would have {\bf NetCharge} = {\tt -1},
and the Na$^+$ ion would have {\bf NetCharge} = {\tt 1}.
Fractional charges can also be used.

{\it Default value:} {\tt 0.0}

\item[{\bf SimulateDoping}] ({\it boolean}):
\index{SimulateDoping@{\bf SimulateDoping}}\index{Slabs with net charge}

This option instructs the program to add a background charge density
to simulate doping.  The new ``doping'' routine calculates the net
charge of the system, and adds a compensating background charge that
makes the system neutral. This background charge is constant at points
of the mesh near the atoms, and zero at points far from the atoms.
This simulates situations like doped slabs, where the extra electrons
(holes) are compensated by oposite charges at the material (the
ionized dopant impurities), but not at the vacuum.  This serves to
simulate properly doped systems in which there are large portions of
vacuum, such as doped slabs.

(See {\tt Tests/sic-slab})

{\it Default value:} {\tt .false.}

\item[{\bf ExternalElectricField}] ({\it data block}):
\index{ExternalElectricField@{\bf ExternalElectricField}}
It specifies an external electric field for molecules, chains and slabs.
The electric field should be orthogonal to `bulk directions', like
those parallel to a slab (bulk electric fields, like in
dielectrics or ferroelectrics, are not allowed). If it is not, an
error message is issued and the components of the field in bulk
directions are suppressed automatically. The input is a
vector in Cartesian coordinates, in the specified units. Example:

\begin{verbatim}
     %block ExternalElectricField
        0.000  0.000  0.500  V/Ang
     %endblock ExternalElectricField
\end{verbatim}

{\it Default value:} zero field

\item[{\bf SlabDipoleCorrection}] ({\it boolean}):
\index{SlabDipoleCorrection@{\bf SlabDipoleCorrection}}

If {\tt true}, {\sc Siesta} calculates the electric field required to
compensate the dipole of the system at every iteration of the
self-consistent cycle. The potential added to the grid corresponds to
that of a dipole layer at the middle of the vacuum layer. For slabs,
this exactly compensates the electric field at the vacuum created by
the dipole moment of the system, thus allowing to treat asymmetric
slabs (including systems with an adsorbate on one surface) and compute
properties such as the work funcion of each of the surfaces.

NOTE: If the program is fed a starting density matrix from an
uncorrected calculation (i.e., with an exagerated dipole), the first
iteration might use a compensating field that is too big, with the
risk of taking the system out of the convergence basin. In that case,
it is advisable to use the {\tt DM.MixSCF1}\index{DM.MixSCF1@{\bf
    DM.MixSCF1}}\index{Slab dipole correction} option to request a mix of the
input and output density matrices after that first iteration.

(See {\tt Tests/sic-slab})

{\it Default value:} {\tt false}

\end{description}


\vspace{5pt}
\subsection{Output of charge densities and potentials on the grid}

{\sc Siesta} represents these magnitudes on the real-space grid. The
following options control the generation of the appropriate files,
which can be processed by the programs in the {\tt Util/Grid}
directory, and also by Andrei Postnikov's utilities in {\tt
  Util/Contrib/APostnikov}. See also {\tt /Util/Denchar} for an
alternative way to plot the charge density (and wavefunctions).

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf SaveRho}] ({\it logical}): \index{SaveRho@{\bf
    SaveRho}}\index{output!charge density} Instructs to write the
  valence pseudocharge density at the mesh used by DHSCF, in file {\tt
    SystemLabel}.RHO.

{\it Use:} File {\tt SystemLabel}.RHO is only written, not read, by siesta.
This file can be read by routine IORHO, which may be used by other
application programs.

If netCDF support is compiled in, the file {\tt Rho.grid.nc} is produced.

{\it Default value:} {\tt .false.}


\item[{\bf SaveDeltaRho}] ({\it logical}):
\index{SaveDeltaRho@{\bf SaveDeltaRho}}\index{output!$\delta \rho(\vec r)$}
Instructs to write $\delta \rho(\vec r) = \rho(\vec r) - \rho_{atm}(\vec r)$,
i.e., the valence pseudocharge density minus the sum of atomic valence
pseudocharge densities. It is done for the mesh points used by DHSCF and it
comes in file {\tt SystemLabel}.DRHO. This file can be read by routine IORHO,
which may be used by an application program in later versions.

{\it Use:} File {\tt SystemLabel}.DRHO is only written, not read, by siesta.

If netCDF support is compiled in, the file {\tt DeltaRho.grid.nc} is produced.

{\it Default value:} {\tt .false.}


\item[{\bf SaveElectrostaticPotential}] ({\it logical}):
\index{SaveElectrostaticPotential@{\bf SaveElectrostaticPotential}}
\index{output!electrostatic potential}
Instructs to write the total electrostatic potential, defined as the
sum of the hartree potential plus the local pseudopotential, at the
mesh used by DHSCF,
in file {\tt SystemLabel}.VH. This file can be read by routine IORHO,
which may be used by an application program in later versions.

{\it Use:} File {\tt SystemLabel}.VH is only written, not read, by siesta.

If netCDF support is compiled in, the file {\tt
ElectrostaticPotential.grid.nc} is produced.

{\it Default value:} {\tt .false.}

\item[{\bf SaveNeutralAtomPotential}] ({\it logical}):
\index{SaveNeutralAtomPotential@{\bf SaveNeutralAtomPotential}}
\index{output!electrostatic potential}
Instructs to write the neutral-atom potential, defined as the
sum of the hartree potential of a ``pseudo atomic valence charge''
plus the local pseudopotential, at the mesh used by DHSCF,
in file {\tt SystemLabel}.VNA. It is written at the start of the
self-consistency cycle, as this potential does not change.

{\it Use:} File {\tt SystemLabel}.VNA is only written, not read, by siesta.

If netCDF support is compiled in, the file {\tt Vna.grid.nc} is produced.

{\it Default value:} {\tt .false.}


\item[{\bf SaveTotalPotential}] ({\it logical}):
\index{SaveTotalPotential@{\bf SaveTotalPotential}}
\index{output!total potential}
Instructs to write the valence total effective local potential
(local pseudopotential + Hartree + Vxc), at the
mesh used by DHSCF,
in file {\tt SystemLabel}.VT. This file can be read by routine IORHO,
which may be used by an application program in later versions.

{\it Use:} File {\tt SystemLabel}.VT is only written, not read, by siesta.

If netCDF support is compiled in, the file {\tt TotalPotential.grid.nc} is produced.

{\it Default value:} {\tt .false.}


\item[{\bf SaveIonicCharge}] ({\it logical}):
\index{SaveIonicCharge@{\bf SaveIonicCharge}}
\index{output!ionic charge}
Instructs to write the soft diffuse ionic charge at the
mesh used by DHSCF,
in file {\tt SystemLabel}.IOCH. This file can be read by routine IORHO,
which may be used by an application program in later versions.
Remember that, within the {\sc Siesta} sign convention, the electron charge
density is positive and the ionic charge density is negative.


{\it Use:} File {\tt SystemLabel}.IOCH is only written, not read, by siesta.

If netCDF support is compiled in, the file {\tt Chlocal.grid.nc} is produced.

{\it Default value:} {\tt .false.}

\item[{\bf SaveTotalCharge}] ({\it logical}):
\index{SaveTotalCharge@{\bf SaveTotalCharge}}
\index{output!total charge}
Instructs to write the total charge density (ionic+electronic) at the
mesh used by DHSCF,
in file {\tt SystemLabel}.TOCH. This file can be read by routine IORHO,
which may be used by an application program in later versions.
Remember that, within the {\sc Siesta} sign convention, the electron charge
density is positive and the ionic charge density is negative.

{\it Use:} File {\tt SystemLabel}.TOCH is only written, not read, by siesta.

{\it Default value:} {\tt .false.}

\item[{\bf SaveBaderCharge}] ({\it logical}):
  \index{SaveBaderCharge@{\bf SaveBaderCharge}} \index{output!Bader
    charge} Instructs the program to save the charge density for
  further post-processing by a Bader-analysis program.  This ``Bader
  charge'' is the sum of the electronic valence charge density and a
  set of ``model core charges'' placed at the atomic sites. For a
  given atom, the model core charge has the same shape as the ``local
  pseudopotential charge'' used elsewhere by {\sc Siesta} (a
  generalized Gaussian), but confined to a radius of 1.0 Bohr, and
  integrating to the total core charge ($Z$-$Z_{\rm val}$). These core
  charges are needed to provide local maxima for the charge density at
  the atomic sites, which are not guaranteed in a pseudopotential
  calculation. For hydrogen, an artificial core of 1 electron is
  added, with a confinement radius of 0.4 Bohr.  The Bader charge is
  projected on the grid points of the mesh used by DHSCF, and saved in
  file {\tt SystemLabel}.BADER. This file can be post-processed by the
  program {\tt Util/grid2cube} to convert it to the ``cube'' format,
  accepted by several Bader-analysis programs (for example, see {\tt
    http://theory.cm.utexas.edu/bader/}).  Due to the need to
  represent a localized core charge, it is advisable to use a
  moderately high MeshCutoff when invoking this option (300-500
  Ry). The size of the ``basin of attraction'' around each atom in the
  Bader analysis should be monitored to check that the model core
  charge is contained in it.  

  The suggested way to run the Bader analysis with the Univ. of Texas
  code is to use both the RHO and BADER files (both in ``cube''
  format), with the BADER file providing the ``reference'' and the RHO
  file the actual significant valence charge data which is important
  in bonding. (See the notes for pseudopotential codes in the above
  web page.) For example, for the h2o-pop example:

  {\tt bader  h2o-pop.RHO.cube -ref h2o-pop.BADER.cube}


If netCDF support is compiled in, the file {\tt BaderCharge.grid.nc}
is produced.

{\it Default value:} {\tt .false.}


\item[{\bf SaveInitialChargeDensity}] ({\it logical}):
  \index{SaveInitialChargeDensity@{\bf
      SaveInitialChargeDensity}}\index{output!charge density}

  If ``true'', the program generates a {\tt SystemLabel}.RHOINIT file
  (and a {\tt RhoInit.grid.nc} file if netCDF support is compiled in)
  containing the charge density used to start the first
  self-consistency step, and it stops. Note that if an initial density
  matrix (DM file) is used, it is not normalized. This is useful to
  generate the charge density associated to ``partial'' DMs, as
  created by progras such as {\tt dm\_creator} and {\tt dm\_filter}.

{\it Default value:} {\tt .false.}


\end{description}

\vspace{5pt}
\subsection{Auxiliary Force field}

It is possible to supplement the DFT interactions with a limited
set of force-field options, typically useful to simulate dispersion
interactions. It is not yet possible to turn off DFT and base the
dynamics only on the force field. The {\tt GULP} program should be
used for that.

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf MM.Potentials}] ({\it data block}):
\index{MM.Potentials@{\bf MM.Potentials}} This block allows the input
of molecular mechanics potentials between species. The following
potentials are currently implemented:
\begin{itemize}
\item C6, C8, C10 powers of the Tang-Toennes damped dispersion
  potential.
\item A harmonic interaction.
\item A dispersion potential of the Grimme type (similar to the C6
  type but with a different damping function). (See S. Grimme,
  J. Comput. Chem. Vol 27, 1787-1799 (2006)). See also {\tt
  MM.Grimme.D} and {\tt MM.Grimme.S6} below.
\end{itemize}

The format of the input is the two species numbers that are to
interact, the potential name (C6, C8, C10, harm, or Grimme), followed
by the potential parameters. For the damped dispersion potentials the
first number is the coefficient and the second is the exponent of the
damping term (i.e., a reciprocal length). A value of zero for the
latter term implies no damping. For the harmonic potential the force
constant is given first, followed by r0. For the Grimme potential C6
is given first, followed by the (corrected) sum of the van der Waals
radii for the interacting species (a real length). Positive values of
the C6, C8, and C10 coefficients imply attractive potentials.

{\it Use:} Gives the input for the molecular mechanics potentials.

\begin{verbatim}

    %block MM.Potentials
       1 1 C6 32.0 2.0
       1 2 harm 3.0 1.4
       2 3 Grimme 6.0 3.2
    %endblock MM.Potentials

\end{verbatim}

{\it Default value:}  None.

\item[{\bf MM.Cutoff}] ({\it physical}): \index{MM.Cutoff@{\bf
MM.Cutoff}} Specifies the distance out to which molecular mechanics
potential will act before being treated as going to zero.

{\it Use:} Limits the real space range of the molecular mechanics
potentials.

{\it Default value:}  {\tt 30.0 Bohr}

\item[{\bf MM.UnitsEnergy}] ({\it units}): \index{MM.UnitsEnergy@{\bf
MM.UnitsEnergy}} Specifies the units to be used for energy in the
molecular mechanics potentials.

{\it Use:} Controls the units for energy in the molecular mechanics input.

{\it Default value:}  {\tt eV} (Note: Currently this the {\em only} option)

\item[{\bf MM.UnitsDistance}] ({\it units}): \index{MM.UnitsDistance@{\bf
MM.UnitsDistance}} Specifies the units to be used for distance in the
molecular mechanics potentials.

{\it Use:} Controls the units for distance in the molecular mechanics input.

{\it Default value:}  {\tt Ang} (Note: Currently this the {\em only} option)

\item[{\bf MM.Grimme.D}] : \index{MM.Grimme.D@{\bf
MM.Grimme.D}} Specifies the scale factor $d$ for the scaling function
in the Grimme dispersion potential (see above).

{\it Default value:}  { 20.0 }

\item[{\bf MM.Grimme.S6}] : \index{MM.Grimme.S6@{\bf
MM.Grimme.S6}} Specifies the overall fitting factor $s_6$ for the
Grimme dispersion potential (see above). This number depends on the
quality of the basis set, the exchange-correlation functional, and the
fitting set.

{\it Default value:}  { 1.66 } (for DZP basis sets).

\end{description}

\vspace{5pt}
\subsection{Parallel options}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf BlockSize}] ({\it integer}): \index{BlockSize@{\bf
BlockSize}} The orbitals are distributed over the processors when
running in parallel using a 1-D block-cyclic algorithm. {\bf
BlockSize} is the number of consecutive orbitals which are located on
a given processor before moving to the next one. Large values of this
parameter lead to poor load balancing, while small values can lead to
inefficient execution.  The performance of the parallel code can be
optimised by varying this parameter until a suitable value is found.

{\it Use:} Controls the blocksize used for distributing orbitals over
processors

{\it Default value:}  8

\item[{\bf ProcessorY}] ({\it integer}): \index{ProcessorY@{\bf
ProcessorY}} The mesh points are divided in the Y and Z directions
(more precisely, along the second and third lattice vectors)
over the processors in a 2-D grid. {\bf ProcessorY} specifies the
dimension of the processor grid in the Y-direction and must be a
factor of the total number of processors. Ideally the processors
should be divided so that the number of mesh points per processor
along each axis is as similar as possible.

{\it Use:} Controls the dimensions of the 2-D processor grid for mesh
distribution

{\it Default value:} Variable - chosen using multiples of factors of
  the total number of processors

\item[{\bf Diag.Memory}] ({\it real no units}):
\index{Diag.Memory@{\bf Diag.Memory}}
Whether the parallel diagonalisation of a matrix is successful or not can
depend on how much workspace is available to the routine when there are
clusters of eigenvalues. {\bf Diag.Memory} allows the user to increase
the memory available, when necessary, to achieve successful diagonalisation
and is a scale factor relative to the minimum amount of memory that
SCALAPACK might need.

{\it Use:} Controls the amount of workspace available to parallel
matrix diagonalisation

{\it Default value:}  1.0

\item[{\bf Diag.ParallelOverK}] ({\it logical}): \index{Diag.ParallelOverK@{\bf
Diag.ParallelOverK}} For the diagonalisation there is a choice in strategy
about whether to parallelise over the K points or over the orbitals. K
point diagonalisation is close to perfectly parallel but is only
useful where the number of K points is much larger than the number of
processors and therefore orbital parallelisation is generally
preferred. The exception is for metals where the unit cell is small,
but the number of K points to be sampled is very large. In this last
case it is recommend that this option be used.

NOTE: This scheme is not used for the diagonalizations involved in the
generation of the band-structure (as specified with {\bf BandLines} or
{\bf BandPoints}) or in the generation of wave-function information
(as specified with {\bf WaveFuncKpoints}). In these cases the program
falls back to using parallelization over orbitals.

{\it Use:} Controls whether the diagonalisation is parallelised with
respect to orbitals or K points - not allowed for non-co-linear spin
case.

{\it Default value:}  false

\end{description}

\subsubsection{Parallel decompositions for O(N)}
\label{parallel-on}

Apart from the default block-cyclic decomposition of the orbital data,
O(N) calculations can use other schemes which should be more
efficient: spatial decomposition (based on atom proximity), and domain
decomposition (based on the most efficient abstract partition of the
interaction graph of the Hamiltonian). 

\begin{description}

\item[{\bf UseDomainDecomposition}] ({\it logical}):
  \index{UseDomainDecomposition@{\bf UseDomainDecomposition}} This
  option instructs the program to employ a graph-partitioning
  algorithm (using the {\tt METIS} library (See {\tt
    www.cs.umn.edu/~metis}) to find an efficient distribution of the
  orbital data over processors.  To use this option (meaningful only
  in parallel) the program has to be compiled with the preprocessor
  option {\tt ON\_DOMAIN\_DECOMP} and the {\tt METIS} library has to
  be linked in.

{\it Default value:}  false

\item[{\bf UseSpatialDecomposition}] ({\it logical}):
  \index{UseSpatialDecomposition@{\bf UseSpatialDecomposition}} When
  performing a parallel order N calculation, this option instructs the
  program to execute a spatial decomposition algorithm in which the
  system is divided into cells, which are then assigned, together with
  the orbitals centered in them, to the different processors. The size
  of the cells is, by default, equal to the maximum distance at which
  there is a non-zero matrix element in the Hamiltonian between two
  orbitals, or the radius of the Localized Wannier function - which
  ever is the larger. If this is the case, then an orbital will only
  interact with other orbitals in the same or neighbouring
  cells. However, by decreasing the cell size and searching over more
  cells it is possible to achieve better load balance in some
  cases. This is controlled by the variable {\bf RcSpatial}.

NOTE: The distribution algorithm is quite fragile and a careful tuning
of {\bf RcSpatial} might be needed. This option is therefore not
enabled by default.

{\it Default value:}  false

\item[{\bf RcSpatial}] ({\it real distance}):
\index{RcSpatial@{\bf RcSpatial}}

Controls the cell size during the spatial decomposition.

{\it Default value:}  maximum of the matrix element range or the
Localized Wannier Function radius

\end{description}


\vspace{5pt}
\subsection{Efficiency options}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf DirectPhi}] ({\it logical}):
\index{DirectPhi@{\bf DirectPhi}}
The calculation of the matrix elements on the mesh requires the
value of the orbitals on the mesh points. This array represents one of
the largest uses of memory within the code. If set to true this option
allows the code to generate the orbital values when needed rather than
storing the values. This obviously costs more computer time but will
make it possible to run larger jobs where memory is the limiting factor.

{\it Use:} Controls whether the values of the orbitals at the mesh points
  are stored or calculated on the fly.

{\it Default value:}  false

\end{description}

\subsection{Memory accounting options}
\begin{description}

\item[{\bf AllocReportLevel}] ({\it integer}):
\index{AllocReportLevel@{\bf AllocReportLevel}}
Sets the level of the allocation report, printed in file
{\tt SystemLabel}.alloc. However, not all the allocated arrays are 
included in the report (this will be corrected in future versions).
The allowed values are:
\begin{itemize}
\item
  level 0 : no report at all (the default)
\item
  level 1 : only total memory peak and where it occurred
\item
  level 2 : detailed report printed only at
            normal program termination
\item
  level 3 : detailed report printed at every new memory peak
\item
  level 4 : print every individual (re)allocation or deallocation
\end{itemize}

{\it Default value:} {\tt 0}

\end{description}


\vspace{5pt}
\subsection{The catch-all option UseSaveData}
\index{reading saved data}

This is a dangerous feature, and is deprecated, but retained for
historical compatibility. Use the individual options instead.

\begin{description}
\itemsep 10pt
\parsep 0pt


\item[{\bf UseSaveData}] ({\it logical}): \index{UseSaveData@{\bf
    UseSaveData}} \index{reading saved data!all} Instructs to use as
  much information as possible stored from previous runs in files {\tt
    SystemLabel}.XV, {\tt SystemLabel}.DM and {\tt SystemLabel}.LWF,
  where SystemLabel is the name associated to parameter {\tt
    SystemLabel}.

{\it Use:} If the required files do not exist, warnings are
printed but the program does not stop.

{\it Default value:} {\tt .false.}

\end{description}

\vspace{5pt}
\subsection{Output of information for Denchar}
\index{denchar}

The program {\tt denchar} in {\tt Util/Denchar} can generate
charge-density and wavefunction contours.

\begin{description}

\item[{\bf WriteDenchar}] ({\it logical}): \index{WriteDenchar@{\bf
    WriteDenchar}} \index{output!charge density and/or wfs for DENCHAR code}
  Instructs to write information needed by the utility program DENCHAR
  (by J. Junquera and P. Ordej\'on) to plot the valence charge density
  contours (see {\tt Util/Denchar}). The information is written in
  file {\tt SystemLabel}.PLD.

{\it Use:} File {\tt SystemLabel}.PLD is only written, not read, by siesta.

Apart from the PLD file, you will need the Density-Matrix (DM) file
and/or a wavefunction (WFSX) file. 

{\it Default value:} {\tt .false.}

\end{description}


\vspace{5pt}
\section{STRUCTURAL RELAXATION, PHONONS, AND MOLECULAR DYNAMICS}

This functionality is not {\sc Siesta}-specific, but is implemented to
provide a more complete simulation package. The program has an outer
geometry loop: it computes the electronic structure (and
thus the forces and stresses) for a given geometry, updates the
atomic positions (and maybe the cell vectors) accordingly and moves on
to the next cycle.

Several options for MD and structural optimizations are
implemented, selected by
{\bf MD.TypeOfRun} ({\it string}):
\index{MD.TypeOfRun@{\bf MD.TypeOfRun}}

\begin{itemize}

\item {\tt CG} Coordinate optimization by conjugate
  gradients). Optionally (see variable MD.VariableCell below), the
  optimization can include the cell vectors.

\item {\tt Broyden} Coordinate optimization by a modified Broyden
  scheme). Optionally, (see variable MD.VariableCell below), the
  optimization can include the cell vectors.

\item {\tt FIRE} Coordinate optimization by Fast Inertial Relaxation
  Engine (FIRE) (E. Bitzek et al, PRL 97, 170201, (2006)).
  Optionally, (see variable MD.VariableCell below), the
  optimization can include the cell vectors.

\item {\tt Verlet} Standard Verlet algorithm MD

\item {\tt Nose}  MD with temperature controlled  by means of a Nos\'e
thermostat

\item {\tt ParrinelloRahman}  MD with pressure controlled by
the Parrinello-Rahman method

\item {\tt NoseParrinelloRahman}  MD with temperature controlled
by means of a Nos\'e thermostat and pressure controlled by
the Parrinello-Rahman method

\item {\tt Anneal}  MD with annealing to a desired
temperature and/or pressure (see variable MD.AnnealOption below)

\item {\tt FC} Compute force constants matrix\index{Force Constants
  Matrix} for phonon calculations.

\item {\tt Phonon} Compute forces for a specified set of atomic
  displacements chosen with the help of the {\sc Phonon}
  program. \footnote{{\sc Phonon} is \copyright\ copyright by
    Krzysztof Parlinski} \index{Phonon program} \index{Force Constants
    Matrix!using phonon@using {\sc Phonon}}.

\item {\tt Forces} (Receive coordinates from, and return forces to, an
  external driver program, using Unix pipes for communication.  The
  routines in module fsiesta.f90 allow the user's program to perform
  this communication transparently, as if siesta were a conventional
  force-field subroutine. See {\tt Util/SiestaSubroutine/README} for
  details. WARNING: if this option is specified without a driver
  program sending data, siesta may hang without any notice).

See directory Util/Scripting \index{Scripting} for other driving options.

\end{itemize}

{\it Default value:} {\tt Verlet} ({\tt CG} for one-atom systems)

Note that some options specified in later variables
(like quenching) modify the behavior of these MD options.
If the system contains just one atom, {\tt CG} is the only
available dynamics option.


\subsection{Structural relaxation}

In this mode of operation, the program moves the atoms (and optionally
the cell vectors) trying to minimize the forces (and stresses) on
them.

These are the options common to all relaxation methods. If the Zmatrix
input option is in effect (see Sec.~\ref{sec:Zmatrix}) the
Zmatrix-specific options take precedence.  The 'MD' prefix is
misleading but kept for historical reasons.

\begin{description}
\item[{\bf MD.VariableCell}] ({\it logical}):
  \index{MD.VariableCell@{\bf MD.VariableCell}} \index{cell
    relaxation} If true, the lattice is relaxed together with the
  atomic coordinates. It allows to target hydrostatic pressures or
  arbitrary stress tensors.  See {\bf MD.MaxStressTol}, {\bf
    MD.TargetPressure}, {\bf MD.TargetStress}, {\bf
    MD.ConstantVolume}, and {\bf MD.PreconditionVariableCell}.

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden} or
{\tt FIRE}

{\it Default value:} {\tt .false.}

\item[{\bf MD.ConstantVolume}] ({\it logical}):
  \index{MD.ConstantVolume@{\bf MD.ConstantVolume}}
  \index{constant-volume cell relaxation} If true, the cell volume is
  kept constant in a variable-cell relaxation: only the cell shape and
  the atomic coordinates are allowed to change.  Note that it does not
  make much sense to specify a target stress or pressure in this case,
  except for anisotropic (traceless) stresses.  See {\bf
    MD.VariableCell}, {\bf MD.TargetStress}.

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden} or
{\tt FIRE},  and  MD.VariableCell is {\tt .true.}.

{\it Default value:} {\tt .false.}

\item[{\bf MD.RelaxCellOnly}] ({\it logical}):
\index{MD.RelaxCellOnly@{\bf MD.RelaxCellOnly}} \index{relaxation of
cell parameters only}

If true, only the cell parameters are relaxed (by the Broyden or FIRE
method, not CG).  The atomic coordinates are re-scaled to the new
cell, keeping the fractional coordinates constant. For Zmatrix
calculations, the fractional position of the first atom in each
molecule is kept fixed, and no attempt is made to rescale the bond
distances or angles.

{\it Use:} Used only if MD.TypeOfRun is {\tt FIRE} or {\tt Broyden}  and
 MD.VariableCell is {\tt .true.}.

{\it Default value:} {\tt .false.}

\item[{\bf MD.MaxForceTol}] ({\it real force}):
\index{MD.MaxForceTol@{\bf MD.MaxForceTol}}
Force tolerance in coordinate optimization.
Run stops if the maximum atomic force is
smaller than {\bf MD.MaxForceTol} (see {\bf MD.MaxStressTol}
for variable cell).

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden} or
{\tt FIRE}

{\it Default value:} {\tt 0.04 eV/Ang}


\item[{\bf MD.MaxStressTol}] ({\it real pressure}):
\index{MD.MaxStressTol@{\bf MD.MaxStressTol}}
Stress tolerance in variable-cell CG optimization. Run stops
if the maximum atomic force is smaller than {\bf MD.MaxForceTol}
and the maximum stress component is smaller than {\bf MD.MaxStressTol}.

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden} or
{\tt FIRE}, and Md.VariableCell is {\tt .true.}

Special consideration is needed if used with Sankey-type basis sets, since
the combination of orbital kinks at the cutoff radii and the finite-grid
integration originate discontinuities in the
stress components, whose magnitude depends on the cutoff radii (or
energy shift) and the mesh cutoff. The tolerance has to be larger
than the discontinuities to avoid endless optimizations if the target
stress happens to be in a discontinuity.

{\it Default value:} {\tt 1.0 GPa}


\item[{\bf MD.NumCGsteps}] ({\it integer}):
\index{MD.NumCGsteps@{\bf MD.NumCGsteps}}
Maximum number of conjugate gradient (or Broyden) minimization
moves (the minimization will stop
if tolerance is reached before; see MD.MaxForceTol below).

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden}

{\it Default value:} {\tt 0}

\item[{\bf MD.MaxCGDispl}] ({\it real length}):
\index{MD.MaxCGDispl@{\bf MD.MaxCGDispl}}
Maximum atomic displacements in an optimization move.

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden} or
{\tt FIRE} (despite its name). For the Broyden optimization method, it is also
possible to limit indirectly the {\it initial\/} atomic displacements
using {\bf MD.Broyden.Initial.Inverse.Jacobian}. For the FIRE method,
the same result can be obtained by choosing a small time step.

Note that there are Zmatrix-specific options that override this option.

{\it Default value:} {\tt 0.2 Bohr}


\item[{\bf MD.PreconditionVariableCell}] ({\it real length}):
  \index{MD.PreconditionVariableCell@{\bf
      MD.PreconditionVariableCell}} A length to multiply to the strain
  components in a variable-cell optimization.  The strain components
  enter the minimization on the same footing as the coordinates. For
  good efficiency, this length should make the scale of energy
  variation with strain similar to the one due to atomic
  displacements. It is also used for the application of the {\bf
    MD.MaxCGDispl} value to the strain components.

{\it Use:} Used only if MD.TypeOfRun is {\tt CG} or {\tt Broyden} or
{\tt FIRE} and MD.VariableCell is {\tt .true.}

{\it Default value:} {\tt 5.0 Ang}

\item[{\bf ZM.ForceTolLength}] ({\it real force}):
  \index{ZM.ForceTolLength@{\bf ZM.ForceTolLength}} Parameter that
  controls the convergence with respect to forces on Z-matrix lengths

{\it Use:} This option sets the convergence criteria for the forces that
act on Z-matrix components with units of length.

{\it Default value:} {\tt $0.00155574$ Ry/Bohr}

\item[{\bf ZM.ForceTolAngle}] ({\it torque}):
  \index{ZM.ForceTolAngle@{\bf ZM.ForceTolAngle}} Parameter that
  controls the convergence with respect to forces on Z-matrix angles

{\it Use:} This option sets the convergence criteria for the forces that
act on Z-matrix components with units of angle.

{\it Default value:} {\tt $0.00356549$ Ry/rad}

\item[{\bf ZM.MaxDisplLength}] ({\it real length}):
  \index{ZM.MaxDisplLength@{\bf ZM.MaxDisplLength}} Parameter that
  controls the maximum change in a Z-matrix length during an
  optimisation step.

{\it Use:} This option sets the maximum displacement for a Z-matrix length

{\it Default value:} {\tt 0.2 Bohr}

\item[{\bf ZM.MaxDisplAngle}] ({\it real angle}):
  \index{ZM.MaxDisplAngle@{\bf ZM.MaxDisplAngle}} Parameter that
  controls the maximum change in a Z-matrix angle during an
  optimisation step.

{\it Use:} This option sets the maximum displacement for a Z-matrix angle

{\it Default value:} {\tt 0.003 rad }

\end{description}

\subsubsection{Conjugate-gradients optimization}

This was historically the default geometry-optimization method, and
all the above options were introduced specifically for it, hence their
names. The following pertains only to this method:

\index{Conjugate-gradient history information}
\begin{description}
\item[{\bf MD.UseSaveCG}] ({\it logical}):
\index{MD.UseSaveCG@{\bf MD.UseSaveCG}}
\index{reading saved data!CG}
Instructs to read the conjugate-gradient hystory information stored
in file {\tt SystemLabel}.CG by a previous run.

{\it Use:} To get actual continuation of iterrupted CG runs, use
together with {\bf MD.UseSaveXV} = {\tt .true.} with the XV
file generated in the same run as the CG file.
If the required file does not exist, a warning is
printed but the program does not stop. Overrides {\bf UseSaveData}.

{\it Default value:} {\tt .false.}

(No such feature exists yet for a Broyden-based relaxation.)

\end{description}

\subsubsection{Broyden optimization}

It uses the modified Broyden algorithm to
build up the Jacobian matrix. (See D.D. Johnson, PRB 38, 12807
(1988)). (Note: This is not BFGS.)

\begin{description}
\item [{\bf MD.Broyden.History.Steps}] ({\it integer}):
\index{MD.Broyden.History.Steps@{\bf MD.Broyden.History.Steps}}
\index{Broyden optimization}

Number of relaxation steps during which the modified Broyden algorithm
builds up the Jacobian matrix.

{\it Use:} Used only if MD.TypeOfRun is {\tt Broyden}.

{\it Default value:} {\tt 5}

\item [{\bf MD.Broyden.Cycle.On.Maxit}] ({\it logical}):
\index{MD.Broyden.Cycle.On.Maxit@{\bf MD.Broyden.Cycle.On.Maxit}}

Upon reaching the maximum number of history data sets which are kept
for Jacobian estimation, throw away the oldest and shift the rest to
make room for a new data set. The alternative is to re-start the
Broyden minimization algorithm from a first step of a diagonal inverse
Jacobian (which might be useful when the minimization is
stuck).

{\it Use:} Used only if MD.TypeOfRun is {\tt Broyden}.

{\it Default value:} {\tt .true.}

\item[{\bf MD.Broyden.Initial.Inverse.Jacobian}] ({\it real}):
\index{MD.Broyden.Initial.Inverse.Jacobian@
{\bf MD.Broyden.Initial.Inverse.Jacobian}}

Initial inverse Jacobian for the optimization procedure. (The units
are those implied by the internal Siesta usage (Bohr for lenghts and
Ry for energies). The default value seems to work well for most systems.

{\it Use:} Used only if MD.TypeOfRun is {\tt Broyden}.

{\it Default value:} {\tt 1.0}


\end{description}

\subsubsection{FIRE relaxation}

Implementation of the  Fast Inertial Relaxation
Engine (FIRE) method (E. Bitzek et al, PRL 97, 170201, (2006) in a
manner compatible with the CG and Broyden modes of relaxation. (An
older implementation activated by the {\bf MD.FireQuench} variable is
still available).

\begin{description}
\item[{\bf MD.FIRE.TimeStep}] ({\it real time}):
\index{MD.FIRE.TimeStep@{\bf MD.FIRE.TimeStep}}

The (fictitious) time-step for FIRE relaxation.
This is the main user-variable
when the option {\tt FIRE} for {\tt MD.TypeOfRun} is active.

{\it Default value:} The molecular-dynamics time-step, as
specified by {\tt MD.LengthTimeStep}, but this is misleading and
should be avoided.

There are other low-level options tunable by the user (see the
routines {\tt fire\_optim} and {\tt cell\_fire\_optim} for more details.

\end{description}

\subsubsection{Quenched MD}

These methods are really based on molecular dynamics, but are used for
structural relaxation.

Note that the Zmatrix input option (see
Sec.~\ref{sec:Zmatrix}) is not compatible with molecular dynamics. The
initial geometry can be specified using the Zmatrix format, but the
Zmatrix generalized coordinates will not be updated.

Note also that the force and stress tolerances have no effect on
the termination conditions of these methods. They run for the number
of MD steps requested (this is arguably a bug).

\begin{description}
\item[{\bf MD.Quench}] ({\it logical}):
\index{MD.Quench@{\bf MD.Quench}}
Logical option to perform a power quench during the molecular dynamics.
In the power quench, each velocity component is set to
zero if it is opposite to the corresponding force
of that component. This affects atomic velocities,
or unit-cell velocities (for cell shape optimizations).

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Verlet} or
{\tt ParrinelloRahman}.
It is incompatible with Nose thermostat options.
The quench option allows structural relaxations of
only atomic coordinates (with {\bf MD.TypeOfRun} = {\tt Verlet})
or atomic coordinates AND cell shape
(with {\bf MD.TypeOfRun} = {\tt ParrinelloRahman}).
{\bf MD.Quench} is superseded by {\bf MD.FireQuench} (see below).

{\it Default value:} {\tt .false.}

\item[{\bf MD.FireQuench}] ({\it logical}) (Deprecated)
\index{MD.FireQuench@{\bf MD.FireQuench}}

SEE the new option {\tt FIRE} for {\tt MD.TypeOfRun}

Logical option to perform a FIRE quench during a Verlet molecular dynamics
run, as described by Bitzek {\it et al.} in Phys. Rev. Lett. {\bf 97},
170201 (2006). It is a relaxation algorithm, and thus the dynamics
are of no interest per se: the initial time-step can be played with
(it uses {\bf MD.LengthTimeStep} as initial $\Delta t$),
as well as the initial temperature (recommended 0) and the atomic
masses (recommended equal). Preliminary tests seem to indicate that
the combination of $\Delta t = 5$ fs and a value of 20 for the atomic
masses works reasonably. The dynamics stops when the force
tolerance is reached ({\bf MD.MaxForceTol}). The other
parameters controlling the algorithm (initial damping,
increase and decrease thereof etc.) are hardwired in the code,
at the recommended values in the cited paper,
including $\Delta t_{max} = 10$ fs.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Verlet}.
It is incompatible with Nose thermostat options. No variable
cell option implemented for this at this stage.
{\bf MD.FireQuench} supersedes {\bf MD.Quench}. This option is
deprecated. The new option {\tt FIRE} for {\tt MD.TypeOfRun} should be
used instead.

{\it Default value:} {\tt .false.}

\end{description}

\subsection{Target stress options}

Useful for structural optimizations and constant-pressure molecular
dynamics.

\begin{description}


\item[{\bf MD.TargetPressure}] ({\it real pressure}):
\index{MD.TargetPressure@{\bf MD.TargetPressure}}
Target pressure for Parrinello-Rahman method, variable cell optimizations,
and annealing options.

{\it Use:} Used only if MD.TypeOfRun =
{\tt ParrinelloRahman}, {\tt NoseParrinelloRahman},
{\tt CG, Broyden, or FIRE} (variable cell), or {\tt Anneal}
(if MD.AnnealOption = {\tt Pressure} or {\tt TemperatureandPressure})

{\it Default value:} {\tt 0.0 GPa}


\item[{\bf MD.TargetStress}] ({\it data block}):
External or target stress tensor for variable cell optimizations.
Stress components are given in a line, in the order {\tt
xx, yy, zz, xy, xz, yz}. In units of {\bf MD.TargetPressure},
but with the opposite sign. For example, a uniaxial compressive stress
of 2 GPa along the 100 direction would be given by
\begin{verbatim}
       MD.TargetPressure  2. GPa
       %block MD.TargetStress
           -1.0  0.0  0.0  0.0  0.0  0.0
       %endblock MD.TargetStress
\end{verbatim}

{\it Use:} Used only if MD.TypeOfRun is {\tt CG, Broyden, or FIRE} and
MD.VariableCell is {\tt .true.}

{\it Default value:} Hydrostatic target pressure:
{\tt -1., -1., -1., 0., 0., 0.}

\item[{\bf MD.RemoveIntramolecularPressure}] ({\it logical}):
\index{MD.RemoveIntramolecularPressure@{\bf
MD.RemoveIntramolecularPressure}} \index{removal of intramolecular
pressure}

If {\tt .true.}, the contribution to the stress coming from the
internal degrees of freedom of the molecules will be subtracted from
the stress tensor used in variable-cell optimization or variable-cell
molecular-dynamics.  This is done in an approximate manner, using the
virial form of the stress, and assumming that the ``mean force'' over
the coordinates of the molecule represents the ``inter-molecular''
stress. The correction term was already computed in earlier versions
of {\sc Siesta} and used to report the ``molecule pressure''. The
correction is now computed molecule-by-molecule if the Zmatrix format
is used.

If the intra-molecular stress is removed, the corrected static and
total stresses are printed in addition to the uncorrected items.
The corrected Voigt form is also printed.

{\it Default value:} {\tt .false.}
\end{description}


\subsection{Molecular dynamics}

In this mode of operation, the program moves the atoms (and optionally
the cell vectors) in response to the forces (and stresses), using the
classical equations of motion.

Note that the Zmatrix input option (see Sec.~\ref{sec:Zmatrix}) is not
compatible with molecular dynamics. The initial geometry can be
specified using the Zmatrix format, but the Zmatrix generalized
coordinates will not be updated.

\begin{description}
\item[{\bf MD.InitialTimeStep}] ({\it integer}):
\index{MD.InitialTimeStep@{\bf MD.InitialTimeStep}}
Initial time step of the MD simulation.
In the current version of {\sc Siesta} it must be 1.

{\it Use:} Used only if MD.TypeOfRun is not {\tt CG} or {\tt Broyden}

{\it Default value:} {\tt 1}

\item[{\bf MD.FinalTimeStep}] ({\it integer}):
\index{MD.FinalTimeStep@{\bf MD.FinalTimeStep}}
Final time step of the MD simulation.

{\it Default value:} {\tt 1}

\item[{\bf MD.LengthTimeStep}] ({\it real time}):
\index{MD.LengthTimeStep@{\bf MD.LengthTimeStep}}
Length of the time step of the MD simulation.

{\it Default value:} {\tt 1.0 fs}

\item[{\bf MD.InitialTemperature}] ({\it real temperature or energy}):
\index{MD.InitialTemperature@{\bf MD.InitialTemperature}}
Initial temperature for the MD run. The atoms are assigned random
velocities drawn from the Maxwell-Bolzmann distribution with the
corresponding temperature. The constraint of zero center of
mass velocity is imposed.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Verlet, Nose,
ParrinelloRahman, NoseParrinelloRahman}
or {\tt Anneal}.

{\it Default value:} {\tt 0.0 K}


\item[{\bf MD.TargetTemperature}] ({\it real temperature or energy}):
\index{MD.TargetTemperature@{\bf MD.TargetTemperature}}
Target temperature for Nose thermostat and annealing options.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Nose, NoseParrinelloRahman}
or {\tt Anneal} (if {\bf MD.AnnealOption} = {\tt Temperature} or
{\tt TemperatureandPressure})

{\it Default value:} {\tt 0.0 K}



\item[{\bf MD.NoseMass}] ({\it real moment of inertia}):
\index{MD.NoseMass@{\bf MD.NoseMass}}
Generalized mass of Nose variable.
This determines the time scale of the Nose variable
dynamics, and the coupling of the thermal bath to
the physical system.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Nose} or
{\tt NoseParrinelloRahman}

{\it Default value:} {\tt 100.0 Ry*fs**2}

\item[{\bf MD.ParrinelloRahmanMass}] ({\it real moment of inertia}):
  \index{MD.ParrinelloRahmanMass@{\bf MD.ParrinelloRahmanMass}}
  Generalized mass of Parrinello-Rahman variable.  This determines the
  time scale of the Parrinello-Rahman variable dynamics, and its
  coupling to the physical system.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt ParrinelloRahman}
or {\tt NoseParrinelloRahman}

{\it Default value:} {\tt 100.0 Ry*fs**2}


{\it Default value:}  Same as {\bf NumberOfAtoms}

\item[{\bf MD.AnnealOption}] ({\it string}):
  \index{MD.AnnealOption@{\bf MD.AnnealOption}} Type of annealing MD
  to perform. The target temperature or pressure are achieved by
  velocity and unit cell rescaling, in a given time determined by the
  variable {\bf MD.TauRelax} below.
\begin{itemize}
\item {\tt Temperature} (Reach a target temperature by velocity
  rescaling)
\item {\tt Pressure} (Reach a target pressure by scaling of the unit
  cell size and shape)
\item {\tt TemperatureandPressure} (Reach a target temperature and
  pressure by velocity rescaling and by scaling of the unit cell size
  and shape)
\end{itemize}

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Anneal}

{\it Default value:} {\tt TemperatureAndPressure}

\item[{\bf MD.TauRelax}] ({\it real time}): \index{MD.TauRelax@{\bf
    MD.TauRelax}} Relaxation time to reach target temperature and/or
  pressure in annealing MD. Note that this is a ``relaxation time'',
  and as such it gives a rough estimate of the time needed to achieve
  the given targets. As a normal simulation also exhibits
  oscillations, the actual time needed to reach the {\it averaged}
  targets will be significantly longer.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Anneal}

{\it Default value:} {\tt 100.0 fs}

\item[{\bf MD.BulkModulus}] ({\it real pressure}):
  \index{MD.BulkModulus@{\bf MD.BulkModulus}} Estimate (may be rough)
  of the bulk modulus of the system.  This is needed to set the rate
  of change of cell shape to reach target pressure in annealing MD.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt Anneal}, when
{\bf MD.AnnealOption} = {\tt Pressure} or {\tt TemperatureAndPressure}

{\it Default value:}  {\tt 100.0 Ry/Bohr**3}


\end{description}

\subsection{Output options for dynamics}

Every time the atoms move, either during coordinate relaxation or
molecular dynamics, their positions {\bf predicted for next step} and
{\bf current} velocities are stored in file SystemLabel.XV. The shape
of the unit cell and its associated 'velocity' (in Parrinello-Rahman
dynamics) are also stored in this file.

Other options follow.

\begin{description}
\item[{\bf WriteCoorInitial}] ({\it logical}):
\index{WriteCoorInitial@{\bf WriteCoorInitial}}
\index{output!atomic coordinates!initial}
It determines whether the initial atomic coordinates of the simulation are
dumped into the main output file. These coordinates correspond to the
ones actually used in the first step (see the section on precedence
issues in structural input) and are output in Cartesian coordinates in
Bohr units.

It is not affected by the setting of {\bf LongOutput}.

{\it Default value:} {\tt .true.}


\item[{\bf WriteCoorStep}] ({\it logical}): \index{WriteCoorStep@{\bf
    WriteCoorStep}} \index{output!atomic coordinates!in a dynamics
  step} If {\tt .true.} it writes the atomic coordinates to standard
  output at every MD time step or relaxation step. The coordinates are
  always written in the {\it Systemlabel}.XV file, but overriden at
  every step. They can be also accumulated in the {\it Systemlabel}.MD
  or {\it Systemlabel}.MDX files depending on {\bf
    WriteMDhistory}.


{\it Default value:} {\tt .false.} (see {\bf LongOutput})


\item[{\bf WriteForces}] ({\it logical}): \index{WriteForces@{\bf
    WriteForces}}\index{output!forces} If {\tt .true.} it writes the
  atomic forces to the output file at every MD time step or relaxation
  step.  Note that the forces of the last step can be found in the
  file {\it Systemlabel}.FA .

{\it Default value:} {\tt .false.} (see {\bf LongOutput})

\item[{\bf WriteMDhistory}] ({\it logical}):
  \index{WriteMDhistory@{\bf WriteMDhistory}} \index{output!molecular
    dynamics!history} If {\tt .true.} {\sc Siesta} accumulates the
  molecular dynamics trajectory in the following files:
\begin{itemize}
\item
{\it Systemlabel}.MD : atomic coordinates and velocities (and lattice
vectors and their time derivatives, if the dynamics implies variable
cell). The information is stored unformatted for postprocessing with
utility programs to analyze the MD trajectory.
\item
{\it Systemlabel}.MDE : shorter description of the run, with energy,
temperature, etc., per time step.
\end{itemize}
These files are accumulative even for different runs.

{\it Default value:} {\tt .false.}

\index{output!molecular dynamics!history}

The trajectory of a molecular dynamics run (or a conjugate gradient
minimization) can be accumulated in different files: SystemLabel.MD,
SystemLabel.MDE, and SystemLabel.ANI. The first file keeps the whole
trajectory information, meaning positions and velocities at every time
step, including lattice vectors if the cell varies. NOTE that the
positions (and maybe the cell vectors) stored at each time step are
the {\bf predicted} values for the next step. Care should be taken if
joint position-velocity correlations need to be computed from this
file.  The second gives global information (energy, temperature, etc),
and the third has the coordinates in a form suited for XMol animation.
See the {\bf WriteMDhistory} and {\bf WriteMDXmol} data descriptors
above for information. {\sc Siesta} always appends new information on
these files, making them accumulative even for different runs.

The {\tt iomd} subroutine can generate both an unformatted file
SystemLabel.MD (default) or ASCII formatted files SystemLabel.MDX and
SystemLabel.MDC containing the atomic and lattice trajectories,
respectively. Edit the file to change the settings if desired.


\end{description}

\subsection{Restarting geometry optimizations and MD runs}

Every time the atoms move, either during coordinate relaxation or
molecular dynamics, their {\bf positions predicted for next step} and
{\bf current velocities} are stored in file SystemLabel.XV, where
SystemLabel is the value of that FDF descriptor (or 'siesta' by
default).  The shape of the unit cell and its associated 'velocity'
(in Parrinello-Rahman dynamics) are also stored in this file. For MD
runs of type Verlet, Parrinello-Rahman, Nose, or
Nose-Parrinello-Rahman, a file named SystemLabel.VERLET\_RESTART,
SystemLabel.PR\_RESTART, SystemLabel.NOSE\_RESTART, or
SystemLabel.NPR\_RESTART, respectively, is created to hold the values
of auxiliary variables needed for a completely seamless
continuation. 

If the restart file is not available, a simulation can still make use
of the XV information, and ``restart'' by basically repeating the
last-computed step (the positions are shifted backwards by using a
single Euler-like step with the current velocities as derivatives).
While this feature does not result in seamless continuations, it
allows cross-restarts (those in which a simulation of one kind (e.g.,
Anneal) is followed by another (e.g., Nose)), and permits 
to re-use dynamical information from old runs.

This restart fix is not satisfactory from a fundamental point of view,
so the MD subsystem in Siesta will have to be redesigned
eventually. In the meantime, users are reminded that the scripting
hooks being steadily introduced (see Util/Scripting) might be used to
create custom-made MD scripts.


\subsection{Use of general constraints}

{\bf Note:} The Zmatrix format (see Sec.~\ref{sec:Zmatrix}) provides
an alternative constraint formulation which can be useful for system
involving molecules.

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf GeometryConstraints}] ({\it data block})
\index{GeometryConstraints@{\bf GeometryConstraints}}
\index{constraints in relaxations}
Fixes constraints to the change of atomic coordinates during
geometry relaxation or molecular dynamics. Allowed constraints are:
\begin{itemize}
\item {\tt cellside}: fixes the unit-cell side lengths to
their initial values (not implemented yet).
\item {\tt cellangle}: fixes the unit-cell angles to
their initial values (not implemented yet).
\item {\tt stress}: fixes the specified stresses to
their initial values.
\item {\tt position}: fixes the positions of the specified atoms to
their initial values.
\item {\tt center}: fixes the center (mean position, not center of
mass) of a group of atoms to its initial value (not implemented yet).
\item {\tt rigid}: fixes the relative positions of a group of atoms,
without restricting their displacement or rotation as a rigid unit
(not implemented yet).
\item {\tt routine}: Additionally, the user may write a
problem-specific routine called {\bf constr} (with the same
interface as in the example below), which inputs the atomic
forces and stress tensor and outputs them orthogonalized to the
constraints. For example, to maintain the relative height of
atoms 1 and 2:

\begin{verbatim}
      subroutine constr( cell, na, isa, amass, xa, stress, fa )
c real*8  cell(3,3)    : input lattice vectors (Bohr)
c integer na           : input number of atoms
c integer isa(na)      : input species indexes
c real*8  amass(na)    : input atomic masses
c real*8  xa(3,na)     : input atomic Cartesian coordinates (Bohr)
c real*8  stress( 3,3) : input/output stress tensor (Ry/Bohr**3)
c real*8  fa(3,na)     : input/output atomic forces (Ry/Bohr)
c integer ntcon        : output total number of position constraints
c                        imposed in this routine
      integer na, isa(na), ntcon
      double precision amass(na), cell(3,3), fa(3,na),
     .                 stress(3,3), xa(3,na), fz
      fz = fa(3,1) + fa(3,2)
      fa(3,1) = fz * amass(1)/(amass(1)+amass(2))
      fa(3,2) = fz * amass(2)/(amass(1)+amass(2))
      ntcon=1
      end
\end{verbatim}

NOTE that the input of the routine {\bf constr} has changed
with respect to {\sc Siesta} versions prior to 1.3. Now, it includes the
argument {\it ntcon}, where the routine should
store the number of position constraints imposed in it,
as an output.  The user should update older {\bf constr} routines
accordingly. In the example above, the number of constraints is one,
since only the relative z position of two atoms is constrained
to be constant.

\end{itemize}

Example: consider a diatomic molecule (atoms 1 and 2) above a surface,
represented by a slab of 5 atomic layers, with 10 atoms per layer.
To fix the cell height, the slab's bottom layer (last 10 atoms),
the molecule's interatomic distance, its height above the surface and
the relative height of the two atoms
(but not its azimuthal orientation and lateral position):

\begin{verbatim}
     %block GeometryConstraints
        cellside   c
        cellangle  alpha  beta  gamma
        position  from -1 to -10
        rigid  1  2
        center 1  2   0.0  0.0  1.0
        stress 4 5 6
        routine constr
     %endblock GeometryConstraints
\end{verbatim}

The first line fixes the height of the unit cell, leaving the width
and depth free to change (with the appropriate type of dynamics).  The
second line fixes all three unit-cell angles.  The third line fixes
all three coordinates of atoms 1 to 10, counted backwards from the
last one (you may also specify a given direction, like in center).
The fourth line specifies that atoms 1 and 2 form a rigid unit.  The
fifth line fixes the center of the molecule (atoms 1 and 2), in the z
direction (0.,0.,1.). This vector is given in Cartesian coordinates
and, without it, all three coordinates will be fixed (to fix a center,
or a position, in the $x$ and $y$ directions, but not in the $z$
direction, two lines are required, one for each direction).  The sixth
line specifies that the stresses 4, 5 and 6 should be fixed.  The
convention used for numbering stresses is that 1=xx,2=yy,3=zz,
4=yz,5=xz,6=xy.  The list of atoms for a given constraint may contain
several atoms (as in lines 4 and 5) {\it or} a range (as in the third
line), but not both. But you may specify many constraints of the same
type, and a total of up to 10000 lines in the block.  Lines may be up
to 130 characters long. Ranges of atoms in a line may contain up to
1000 atoms. All names must be in lower case.

Notice that, if you only fix the position of one atom, the rest of the
system will move to reach the same relative position. In order to
fix the {\it relative} atomic position, you may fix the center of
the whole system by including a line specifying 'center'
without any list or range of atoms (though possibly with a direction).

Constraints are imposed by suppressing the forces in those directions,
before applying them to move the atoms. For nonlinear constraints
(like 'rigid'), this does not impose the exact conservation of the
constrained magnitude, unless the displacement steps are very small.

{\it Default value:} No constraints

\end{description}

\subsection{Phonon calculations}

If {\bf MD.TypeOfRun} = {\tt FC}, {\sc Siesta} sets up a special
outer geometry loop that displaces individual atoms along the
coordinate directions to build the force-constant matrix.
\index{output!molecular dynamics!Force Constants Matrix}

The output (see below) can be analyzed to extract phonon frequencies
and vectors with the VIBRA\index{VIBRA} package in the {\tt Util/Vibra}
directory. For computing the Born effective charges together with the
force constants, see {\bf BornCharge} \index{BornCharge@{\bf
    BornCharge}}).

\begin{description}
\item[{\bf MD.FCDispl}] ({\it real length}):
\index{MD.FCDispl@{\bf MD.FCDispl}}
Displacement to use for the computation of the force constant
matrix\index{Force Constants Matrix} for phonon calculations.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt FC}.

{\it Default value:}  {\tt 0.04 Bohr}

\item[{\bf MD.FCfirst}] ({\it integer}):
\index{MD.FCfirst@{\bf MD.FCfirst}}
Index of first atom to displace for the computation of the force constant
matrix\index{Force Constants Matrix} for phonon calculations.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt FC}.

{\it Default value:}  {\tt 1}

\item[{\bf MD.FClast}] ({\it integer}):
\index{MD.FClast@{\bf MD.FClast}}
Index of last atom to displace for the computation of the force constant
matrix\index{Force Constants Matrix} for phonon calculations.

{\it Use:} Used only if {\bf MD.TypeOfRun} = {\tt FC}.
\end{description}

The force-constants matrix is written in file {\it SystemLabel}.{\tt FC}.
The format is the following: for the displacement of
each atom in each direction, the forces on each of the other
atoms is writen (divided by the value of the displacement),
in units of eV/\AA$^2$. Each line has the forces in the $x$, $y$
and $z$ direction for one of the atoms.


\subsection{Interface to the {\sc PHONON} program}
\label{sec:phonon-interface}

The interface to the {\sc Phonon} program was prepared for an earlier
version of {\sc Siesta}, but it cannot be maintained properly by the
developers because we do not use the program. We would appreciate help
with testing and improving this interface. Alternatively, a script
driving Siesta can be written instead. See {\tt Util/Scripting}.

Here are the relevant options, active when {\bf MD.TypeOfRun}={\tt Phonon}.

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf PhononLabels}] ({\it data block}):
\index{PhononLabels@{\bf PhononLabels}}
It provides the mapping\index{Phonon program@{\sc Phonon program}}
between the species number and those used by the {\sc
Phonon} program. Note that chemically identical elements might be
assigned different labels if they are not related by symmetry.

\begin{verbatim}
         %block PhononLabels
            1   A   Mg
            2   B   O
         %endblock PhononLabels
\end{verbatim}

The species number is followed by the {\sc
Phonon} program label and by the chemical symbol.

{\it Use:} This block is mandatory if {\tt MD.TypeOfRun} is {\tt Phonon}.

{\it Default:} No default.

\item[{\bf MD.ATforPhonon}] ({\it data block}): List of ``symmetry
irreducible'' atomic displacements for which to compute forces. Each
line gives the fractional displacement for an atom, identified by its
number in the atom list, and by a one-character code generated by the
{\sc Phonon} program. These codes are put in correspondence with the
species labels in block \hbox{\it PhononLabels}).\index{Force
Constants Matrix!using phonon@using {\sc Phonon}}

\begin{verbatim}
    %block MD.ATforPhonon
      0.002358   0.000000   0.000000  L     1
      0.000000   0.000000   0.003488  L     1
      0.002358   0.000000   0.000000  A    33
      0.000000   0.000000   0.003488  A    33
     -0.002358   0.000000   0.000000  L     1
      0.000000   0.000000  -0.003488  L     1
     -0.002358   0.000000   0.000000  A    33
      0.000000   0.000000  -0.003488  A    33
    %endblock MD.ATforPhonon

\end{verbatim}

{\it Note:} The presence of this block
atomatically sets MD.TypeOfRun to {\tt Phonon}.

{\it Default value:} None.

\end{description}

\index{output!molecular dynamics!PHONON forces file}
If the dynamics option is set to the calculation of the forces for
selected displacements ({\bf MD.TypeOfRun}={\tt Phonon}, and/or the
block {\tt MD.ATforPhonon} exists), the forces
are written in file {\it SystemLabel}.{\tt PHONON}.  The format is the
following: Comment line, cell vectors in {\AA}, and for each
displacement: atom displaced and its coordinates plus fractional
displacement, Cartesian components of forces on all the atoms in units
of eV/\AA.

\section{TRANSIESTA}

The present {\sc Siesta} release includes the possibility of
performing calculations of electronic transport properties using the
{\sc TranSiesta} method. This Section describes how to compile the
code to be able to use these capabilities, and a reference guide to
the relevant FDF options. We describe here only the additional options
available for TranSiesta calculations, while the rest of the Siesta
functionalities and variables are described in the previous sections
of this User's Guide.

\subsection{Brief description}

The {\sc TranSiesta} method is a procedure to solve the electronic
structure of an open system formed by a finite structure sandwiched
between two semi-infinite metallic leads. A finite bias can be applied
between both leads, to drive a finite current. The method is described
in detail in Phys. Rev. B {\bf 65}, 165401 (2002). In practical terms,
calculations using {\sc TranSiesta} involve the solution of the
electronic density from the DFT Hamiltonian using Green's functions
techniques, instead of the usual diagonalization procedure. Therefore,
{\sc TranSiesta} calculations involve a {\sc Siesta} run, in which a
set of routines are invoked to solve the Green's functions and the
charge density for the open system. These routines are packed in a set
of modules, and we will refer to it as the '{\sc TranSIESTA} module'
in what follows.

{\sc TranSiesta} was originally developed by Mads Brandbyge,
Jos\'e-Luis Mozos, Pablo Ordej\'on, Jeremy Taylor and Kurt Stokbro
(see references). It consisted, mainly, in setting up an interface
between {\sc Siesta} and the (tight-binding) transport codes developed
by M. Brandbyge and K. Stokbro. Initially everything was written in
Fortran-77. As {\sc Siesta} started to be translated to Fortran-90, so
were the {\sc TranSiesta} parts of the code. This was accomplished by
Jos\'e-Luis Mozos, who also worked on the parallelization of {\sc
  TranSiesta}.  The present distribution has been adapted to the new
{\sc Siesta} code structure. With respect to the previous
implementations, it has the additional feature of allowing for the use
of a {\bf k}-point sampling other than the gamma point (for the 2D
Brillouin zone perpendicular to the transport direction).  These
modifications, among others, were done by Frederico D. Novaes.

\subsection{Source code structure}

In this implementation, the original {\sc TranSiesta} routines have
been grouped in a set of modules whose file names begin with {\tt
  m\_ts} (such as in e.g. {\tt m\_ts\_electrode.F90} ).  Several new
subroutines have been added.  These modules are located in the {\tt
  Src} directory.  The inclusion of {\sc TranSiesta} has also required
the modification of some of the {\sc Siesta} routines. Presently,
these modifications are controlled by pre-processor compilation
directives (such as in {\tt \#ifdef TRANSIESTA} ). See the next
section for compilation instructions.

\subsection{Compilation}

The standard {\sc Siesta} executable (obtained as described in Section
2) does not include the {\sc TranSiesta} modules. In order to use the
{\sc TranSiesta} capabilities, you must compile the {\sc Siesta}
package as indicated in this Section. In this way, the compilation is
done using the appropriate preprocessor flags needed to include the
{\sc TranSiesta} modules in the binary file. To generate a binary of
{\sc Siesta} which includes the {\sc TranSiesta} capabilities, just
type:

\begin{verbatim}
$ make transiesta
\end{verbatim}

using the appropriate arch.make file for your system (note that you do
not need to make any modification on your arch.make file: you can use
the same one that you have used to make a standard {\sc Siesta}
compilation in your system).  The Makefile takes care of defining the
appropriate preprocessor flag -DTRANSIESTA so that the {\sc
  TranSiesta} modules and modifications are compiled and incorporated
into the binary. Upon successful compilation, the binary file {\tt
  transiesta} will be generated, containing an executable version of
{\sc Siesta} with {\sc TranSiesta} capabilities.

\subsection{Running a fast example}

Before giving more detailed explanations about {\sc TranSiesta}, let
us start with an example to show the basic operations of a transport
calculation.  Starting from the top {\sc Siesta} directory:

\begin{verbatim}
$ cd Examples/TranSiesta
\end{verbatim}

First it is necessary to do the electrode calculation (see below for
details),

\begin{verbatim}
$ cd Elec
$ mkdir OUT_Test
$ cd OUT_Test
$ cp ../* .
$ transiesta < elec.fast.fdf > elec.fast.out
\end{verbatim}

Note that apart from the usual files generated by {\sc Siesta}, now you will 
find the {\tt elec.fast.TSHS} file (in general {\tt <SystemLabel>.TSHS}). 
This file contains the real-space Hamiltonian and Overlap matrices, together 
with some other information, that will be used, in the case of electrodes, to 
calculate the surface Green's functions. 

Once the electrode file has been generated, we can perform the {\sc
  TranSiesta} calculation (where the {\bf SolutionMethod} flag is set
to {\tt transiesta}).

\begin{verbatim}
$ cd ../../Scat
$ mkdir OUT_TS_Test
$ cd OUT_TS_Test
$ cp ../* .
$ cp ../../Elec/OUT_Test/elec.fast.TSHS .
$ transiesta < scat.fast.fdf > scat.fast.out
\end{verbatim}

Now the two following files should have been generated, {\tt scat.fast.TSHS} 
and {\tt scat.fast.TSDE}. The first one contains, as previously mentioned, 
essentially the Hamiltonian and Overlap matrices, and the {\tt .TSDE} file 
has the {\sc TranSiesta} density matrix, the equivalent to the {\tt .DM} 
file of {\sc Siesta}. The transmission function and the current are calculated 
using the {\tt tbtrans} postprocessing tool (below).

Other automated TranSiesta-TBTrans examples can be found in
{\tt Tests/TranSiesta-TBTrans}.

\subsection{Brief explanation}

\begin{itemize}
\item 
Transport calculations involve Electrodes (EL) calculations, and then
the Scattering Region (SR) calculation.  The Electrodes calculations
are usual {\sc Siesta} calculations, but where a file {\tt
  <SystemLabel>.TSHS} is generated.  These files contain the
information necessary for the SR calculation.  If both electrodes are
identical structures (see below) the same {\tt .TSHS} file can be used
to describe both.  In general, however, both Electrodes can be
different and therefore two different {\tt .TSHS} files must be
generated.  The location of these Electrode files must be specified in
the file FDF input file of the SR calculation (they are usually copied
to the same directory where the SR calculation is performed).

\item
For the SR, {\sc TranSiesta} starts with the usual {\sc Siesta}
procedure, converging a Density Matrix (DM) with the usual Kohn-Sham
scheme for periodic systems. It uses this solution as an initial input
for the Green's functions self consistent cycle. As it is known, {\sc
  Siesta} stores the DM in a file with extension {\tt .DM}. In the
case of {\sc TranSiesta}, this is done in a file named {\tt
  <SystemLabel>.TSDE}.  In a rerun of the same system (meaning the
same {\tt <SystemLabel>}), if the code finds a {\tt.TSDE} file in the
directory, it will take this DM as the initial input and this is then
considered a continuation run. In this case it does not perform an
initial {\sc Siesta} run. It must be clear that when starting a
calculation from scratch, in the end one will find both files, {\tt
  <SystemLabel>.DM} and {\tt <SystemLabel>.TSDE}.  The first one
stores the {\sc Siesta} density matrix (periodic boundary conditions
in all directions and no voltage), and the latter the {\sc TranSiesta}
solution. It is a good practice to, when increasing the bias, use as
an initial DM a {\tt .TSDE} that had been obtained for a lower
voltage. It is also usefull to point out here that the {\tt
  <SystemLabel>.TSDE} file has the same format as the {\tt
  <SystemLabel>.DM} file (with extra information appendend in the
end). Being so, one can for example use DENCHAR to analyse the non
equilibrium charge density.

\item
As in the case of {\sc Siesta} calculations, what {\sc TranSiesta}
does is to obtain a converged DM, but for open boundary conditions and
possibly a finite bias applied between the Electrodes. The
corresponding Hamiltonian matrix (once self consistency is achieved)
of the SR is also stored in a {\tt <SystemLabel>.TSHS} file. The
transport properties are obtained in a post-processing procedure using
the {\tt tbtrans} code (located in the {\tt Util/TBTrans}
directory). What {\tt tbtrans} does is, using the {\tt .TSHS} file of
the SR obtained with {\sc TranSiesta}, {\bf and} the Electrode's {\tt
  .TSHS} files, to calculate the transmission spectrum and the
electronic current. The {\tt tbtrans} input file is typically the same
as the one that was used for {\sc TranSiesta}, with the additional
{\tt tbtrans} options. It is to be noted that the {\tt .TSHS} files
contain all the needed structural information (atomic positions,
matrix elements, \ldots), and so this kind of parameters will not be
changed by input (fdf) flags once they are read a {\tt .TSHS} file.

\item
{\sc TranSiesta} defines the Left Electrode to be the first atoms
specified in the SR {\tt .fdf} file, and the Right Electrode to be the
last ones. The transport direction has to be considered to be the the
third cartesian axis, the {\tt z} axis. The Left Electrode atoms must
have smaller {\tt z} components than the Right Electrode atoms. It is
also crucial that the atomic positions specified at the left (right)
EL calculation must be equivalent to the left (right) electrode part
of the SR setup. Here, equivalent means that they can be made equal by
a simple translation in space. It is also possible to use buffer
atoms. This is mostly useful for simulations with different
Electrodes.  In this case, {\sc TranSiesta} will not consider these
atoms, and the buffer atoms are considered only for the initial {\sc
  Siesta} calculation, to get a better ``bulk-like'' environment at
the electrodes.

\item
An important parameter is: {\tt TS.ComplexContour.Emin} It specifies
the starting energy for the contour integration. It is a good
practice, to start with a {\sc Siesta} calculation for the SR and look
at the eigenvalues of the system. The value of {\tt
  TS.ComplexContour.Emin} must be (considerably) lower than the
smallest eigenvalue obtained with {\sc Siesta}. This ensures that all
the states are considered in the contour integration.

\item
{\sc TranSiesta} still assumes periodic boundary conditions in the
{\tt xy} directions.  For {\sc TranSiesta}, the specified k-point
sampling (of this 2-dimensional Brillouin zone) used in a SR
calculation must be the same as the one that was used for the
electrodes, if they are different the code will stop. In practice this
means that the first and the second lines of the {\bf
  kgrid\_Monkhorst\_Pack} block must be the same.  In the case of {\bf
  tbtrans}, the k-point sampling has to be specified also using a {\bf
  kgrid\_Monkhorst\_Pack} block, and can differ from the sampling that
was used in the {\sc TranSiesta} calculation. The convergence of the
transmission function with respect to the k sampling can be slower
than the one for the density matrix. This means that one may have to
increase the number of k-points used in {\bf tbtrans}.
\end{itemize}

\subsection{Electrodes}

In order to calculate the electronic structure of a system under
external bias, {\sc TranSiesta} attaches the system to semi-infinite
electrodes which extend to the left and right of the contact
region. Examples of electrodes would include surfaces, nanowires,
nanotubes or even atomic chains. The electrode must be oriented along
the z-axis and the unit cell along the z-direction must be large
enough so that orbitals within the unit cell only interact with a
single nearest neighbor cell (the size of the unit cell can thus be
derived from the range of support for the orbital basis
functions). The electrode description is also used in {\bf tbtrans}.
The electrodes are generated by a separate transiesta run on a bulk
system.  The results are saved in a file with extension {\tt .TSHS}
which contains a description of the electrode unit cell, the position
of the atoms within the unit cell, as well as the Hamiltonian and
overlap matrices that describe the electronic structure of the
lead. One can generate a variety of electrodes and the typical use of
transiesta would involve reusing the same electrode for several
setups.  In this version of {\sc TranSiesta}, one must manually
provide a valid description of the electrode and the atomic
coordinates input to must conform with this description.
%At runtime, the transiesta coordinates 
%are checked against the electrode coordinates and the program stops if 
%there is a mismatch.

\subsection{{\sc TranSiesta} Options}

The FDF options shown here are only to be used at the input file for
the scattering region.  When using {\tt transiesta} for electrode
calculations, only the usual {\sc Siesta} options are relevant.

\subsubsection{General options}

\begin{description}
    \itemsep 10pt
    \parsep 0pt

    \item[{\bf SolutionMethod}] ({\it string}):
      \index{SolutionMethod@{\bf SolutionMethod}} Must be set to {\tt
        transiesta} in order to perform a {\sc TranSiesta} calculation

        {\it Default value:} {\tt diagon}

\item[{\bf TS.SaveHS}] ({\it logical}): \index{TS.SaveHS@{\bf
    TS.SaveHS}} Save the Hamiltonian in the file with extension .TSHS.
  Must be {\tt true} when calculating the electrode Hamiltonian (it is
  by default).  The .TSHS file must also be generated in {\sc
    TranSiesta} calculations if tbtrans is to be used after the run.

{\it Default value:} {\tt true}

    \item[{\bf TS.Voltage}] ({\it physical }): The voltage applied
      along the z-direction of the unit cell between the two
      electrodes.

        {\it Default value:} {\tt 0.0 eV}

\item[{\bf TS.MixH}] ({\it logical}): \index{TS.MixH@{\bf TS.MixH}}
  During the self consisten cycle, usually the density matrix of
  previous steps are mixed to give the next density matrix. This flag
  represents the possibility of mixing the Hamiltonian instead. If
  used, it may result in faster convergence.

{\it Default value:} {\tt false}

\item[{\bf TS.UpdateDMCROnly}] ({\it logical}):
  \index{TS.UpdateDMCROnly@{\bf TS.UpdateDMCROnly}} During the {\sc
    TranSiesta} (Green's functions) self consistent cycle, it updates
  only the density matrix elements of the contact region, if set to
  {\tt true}. The electrodes and coupling terms are kept as the ones
  obtained in a first {\sc Siesta} run. If set as {\tt false}, the
  coupling terms are also updated by the Green's functions density
  matrix. If a larger number of electrode layers (metallic systems)
  are included in the contact region, the coupling terms may not need
  to be updated. If set to {\tt false}, however, may result in larger
  number of iterations to converge.

{\it Default value:} {\tt true}

\item[{\bf TS.CalcGF}] ({\it logical}): 
\index{TS.CalcGF@{\bf TS.CalcGF}}
The generated surface Green's functions of the electrodes depend on the atomic structure,
but also on the energy points of the contour (that will dependend on the voltage). 
It is possible to use previously generated .GF files, but care must be taken.
If it is just a rerun of the same system, this flag can safely be set as {\tt false}. 
This will save computing time.

{\it Default value:} {\tt true}

\item[{\bf TS.TriDiag}] ({\it logical}): \index{TS.TriDiag@{\bf
    TS.TriDiag}} If represented in terms of the left electrode, the
  contact region and the right electrode, the Hamiltonian is
  tridiagonal (no interactions between the electrodes). To obtain the
  Green's function used to compute the density matrix, the essential
  operation is an inversion of a tridiagonal matrix. This matrix can
  be inverted directly or by using smaller matrices (due to the
  tridiagonality). If set to {\tt true}, it is done in this way.
  Different memory uses and times for the inversion operation can be
  obtained when using one or the other.

{\it Default value:} {\tt false}

\end{description}

\subsubsection{Electrode description options}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\bf TS.HSFileLeft }] ({\it string}): 
\index{TS.HSFileLeft@{\bf TS.HSFileLeft}}
Name of the .TSHS file output from the initial electrode run. 
N.B.: The program will stop if this file is not found.

{\it Default value:} {\tt \_NONE\_} 

\item[{\bf TS.GFFileLeft }] ({\it string}): 
\index{TS.GFFileLeft@{\bf TS.GFFileLeft}}
Name of the .GF file of the left electrode. 
N.B.: The program will generate a new one if not found.

{\it Default value:} {\tt Left.GF} 

\item[{\bf TS.HSFileRight }] ({\it string}): 
\index{TS.HSFileRight@{\bf TS.HSFileRight}}
Name of .TSHS file describing right electrode. See TS.HSFileLeft. 

{\it Default value:} {\tt \_NONE\_} 

\item[{\bf TS.GFFileRight }] ({\it string}): 
\index{TS.GFFileRight@{\bf TS.GFFileRight}}
Name of the .GF file of the left electrode. 
N.B.: The program will generate a new one if not found.

{\it Default value:} {\tt Right.GF}

\item[{\bf TS.NumUsedAtomsLeft}] ({\it integer}):
  \index{TS.NumUsedAtomsLeft@{\bf TS.NumUsedAtomsLeft}} The number of
  electrode atoms to include in the left lead (for example it could be
  2 if only the Greens function of the first two layers of a fcc(111)
  surface is needed and in which case you need 3 atoms in the bulk
  unit cell to represent the A,B,C,A,.. stacking). Must be less than
  or equal to the number of atoms in the simple unit cell of the left
  electrode.  If it is less than the number of atoms in the simple
  unit cell, the last {\bf TS.NumUsedAtomsLeft} atoms are taken. If it
  is less than the number of atoms in the simple unit cell, the atoms
  in the left electrode must be ordered according to their coordinate
  along the z-direction, from smallest to largest.

{\it Default value:} {\tt Number of atoms in the simple unit cell of
  the Left electrode}

\item[{\bf TS.NumUsedAtomsRight}] ({\it integer}):
  \index{TS.NumUsedAtomsRight@{\bf TS.NumUsedAtomsRight}} The number
  of electrode atoms to include in the right lead. Must be less than
  or equal to the number of atoms in the simple unit cell of the right
  electrode. If it is less than the number of atoms in the simple unit
  cell, the first {\bf TS.NumUsedAtomsRight} atoms are taken. If it is
  less than the number of atoms in the simple unit cell, the atoms in
  the right electrode must be ordered according to their coordinate
  along the z-direction, from smallest to largest.

{\it Default value:} {\tt Number of atoms in the simple unit cell of
  the Right electrode}

\item[{\bf TS.BufferAtomsLeft}] ({\it integer}): 
\index{TS.BufferAtomsLeft@{\bf TS.BufferAtomsLeft}}
Number of atoms starting from the first atom to neglect in the  
{\sc TranSiesta} run. %(their density matrix will be fixed).

{\it Default value:} {\tt 0} 

\item[{\bf TS.BufferAtomsRight}] ({\it integer}): 
\index{TS.BufferAtomsRight@{\bf TS.BufferAtomsRight}}
Number of atoms starting from the last atom to neglect in the  
{\sc TranSiesta} run.%(their density matrix will be fixed).

{\it Default value:} {\tt 0} 

\end{description}


\subsubsection{Complex contour integration options}

\begin{description}
    \itemsep 10pt
    \parsep 0pt

    \item[{\bf TS.ComplexContour.Emin}] ({\it physical}):
      \index{TS.ComplexContour.Emin@{\bf TS.ComplexContour.Emin}} The
      starting point of the complex energy contour. In a {\sc
        TranSiesta} run this value should be below the lowest energy
      in the energy spectrum otherwise some charge will be missing in
      the integration.

        {\it Default value:} {\tt -3.0 Ry}

    \item[{\bf TS.ComplexContour.NumCircle}] ({\it integer}): 
        \index{TS.ComplexContour.NumCircle@{\bf TS.ComplexContour.NumCircle}}
        Number of points along the arc part of the contour (starting at 
        {\bf TS.ComplexContour.Emin} and ending at E$_F$ = 0).

        {\it Default value:} {\tt 24}
        
    \item[{\bf TS.ComplexContour.NumLine}] ({\it integer}): 
        \index{TS.ComplexContour.NumLine@{\bf TS.ComplexContour.NumLine}}
        Number of points on the line part of the contour.

        {\it Default value:} {\tt 6}
 
    \item[{\bf TS.ComplexContour.NumPoles}] ({\it integer}): 
        \index{TS.ComplexContour.NumPoles@{\bf TS.ComplexContour.NumPoles}}
        Number of Fermi poles that the complex contour should include.

        {\it Default value:} {\tt 6} 
 
\end{description}

\subsubsection{Bias contour integration options}

\begin{description}
    \itemsep 10pt
    \parsep 0pt
    
    \item[{\bf TS.BiasContour.Eta}] ({\it physical}): 
        \index{TS.BiasContour.Eta@{\bf TS.BiasContour.Eta}}
        Small finite complex part of the real energy contour.

        {\it Default value:} {\tt 10$^{-6}$ Ry}
        
    \item[{\bf TS.BiasContour.Method}] ({\it string}):
      \index{TS.BiasContour.Method@{\bf TS.BiasContour.Method}} This
      describes how the points on the real axis contour are chosen.
      Options are: \begin{itemize}
                       \item {\tt Sommerfeld}: equally spaced points
                         with Sommerfeld expansion for including the
                         electron temperature.
                       \item {\tt GaussFermi}: Gaussian quadrature
                         weighted with the Fermi distribution
                         function.
                    \end{itemize}
                    
        {\it Default value:} {\tt GaussFermi}
        
    \item[{\bf TS.BiasContour.NumPoints}] ({\it integer}):
      \index{TS.BiasContour.NumPoints@{\bf TS.BiasContour.NumPoints}}
      Number of contour points on the close-to-real axis part of the
      contour in the voltage bias window.

        {\it Default value:} {\tt 5}
        
\end{description}    

\subsection{  Matching   {\sc TranSiesta} coordinates: basic rules}
Having discussed the possible input options of {\sc TranSiesta} here
we just list a set of rules to construct the appropriate coordinates
of the scattering region.  The order of atoms be such that:
\begin{itemize}
\item
The first {\bf TS.BufferAtomsLeft} atoms will be considered buffer
atoms that will not be used in the {\sc TranSiesta} calculation, but
which are used in the {\sc Siesta} calculation. This number can, of
course, be zero.
\item The next {\bf TS.NumUsedAtomsLeft} correspond to the left
  electrode atoms.

\item  The next atoms correspond to the contact region.
\item  The next {\bf TS.NumUsedAtomsRight} are the right electrode atoms.
\item The next {\bf TS.BufferAtomsRight} correspond to atoms that are
  neglected in the transiesta part of the calculation, only take part
  in the first {\sc Siesta} run (only occurs if it is not a
  continuation run)
\end{itemize}

The order shown here must also correspond to increasing values of the
{\tt z} coordinates of the atoms, in the sense that the left buffer
atoms must all have smaller {\tt z} components than the left electrode
atoms, and so on. But, within each {\it ``block''}(buffer atoms, or
electrode atoms, etc \ldots), the coordinates do not have to be
ordered in any special way (except when using for the electrodes a
number smaller than what was used in the electrode's unit cell).

\subsection{Output}

{\sc TranSiesta} generates several output files.  The output files are
named {\tt <SystemLabel>.ext}, defined using the SystemLabel FDF
command , and .ext depends on the type of the output.  Below we list
the .ext files which are specific to transiesta.  For a description of
the other output files, we refer the user to the {\sc Siesta} manual.


\begin{description}
    \itemsep 10pt
    \parsep 0pt
    
    \item[{\bf .DM }]: \index{.DM@{\bf .DM}} The {\sc Siesta} density
      matrix. {\sc Siesta} initially performs a calculation at zero
      bias assuming periodic boundary conditions in all directions,
      and no voltage, which is used as a starting point for the
      transiesta calculation.

    \item[{\bf .TSDE }]: \index{.TSDE@{\bf .TSDE}} The {\sc
      TranSiesta} density matrix and energy density matrix. During a
      transiesta run, the .DM values are used for the density matrix
      in the buffer (if used) and electrode regions. The coupling
      terms may o may no be updated in a {\sc TranSiesta} run (see
      {\bf TS.UpdateDMCROnly}).

    \item[{\bf .TSHS }]: \index{.TSHS@{\bf .TSHS}} The Hamiltonian
      corresponding to .TSDE, and other information needed by {\sc
        TranSiesta} and {\tt tbtrans}.

\end{description} 

\subsection{Utilities for analysis: {\tt tbtrans}.}
\index{tbtrans@{\bf tbtrans}}

The {\tt tbtrans} code can be found in the directory {\tt
  Util/TBTrans}.  It is used in order to obtain, in a post-processing
way, the transport properties after a {\sc TranSiesta} run. It was
developed by M. Brandbyge, and the present version contains
modifications made by Frederico D. Novaes.

In order to run it, it requires the electrode's .TSHS files (may be
just one file if the left and right electrodes are equal), and the
scattering region's .TSHS file.  These are generated as explained
above.  The location of these files are specified by the (already
discussed) {\bf TS.HSFileLeft}, {\bf TS.HSFileRight} input options,
and by:
\begin{description}
    \itemsep 10pt
    \parsep 0pt

\item [{\bf TS.TBT.HSFile}]({\it string}): Scattering region .TSHS file.
\index{TS.HSFileLeft@{\bf TS.HSFileLeft}}

{\it Default value:} {\tt {\it SystemLabel}.TSHS}
\end{description}
respectively for the left and right electrodes and the scattering
region .TSHS file.

The energy scale in {\tt tbtrans} is shifted so that the Fermi level
of the system, if no voltage were applied, is zero. When computing the
transmission function of a zero bias calculation, the transmission at
the Fermi level is then given by T(E=0). When there is a finite bias,
the Fermi energy of the left electrode is placed at V/2, and that of
the right electrode at -V/2.

The voltage is specified by {\bf TS.Voltage}. The energy window and
number of points for the computation of the transmission function is
specified by
\begin{description}
    \itemsep 10pt
    \parsep 0pt

\item [{\bf TS.TBT.Emin}]({\it physical}): Lowest energy value of the
  computed transmission function.  \index{TS.TBT.Emin@{\bf
      TS.TBT.Emin}}

{\it Default value:} {\tt -2.0 eV}

\item [{\bf TS.TBT.Emax}]({\it physical}): Highest energy value of the
  computed transmission function.  \index{TS.TBT.Emax@{\bf
      TS.TBT.Emax}}

{\it Default value:} {\tt 2.0 eV}

\item [{\bf TS.TBT.NPoints}]({\it integer}): Number of energy points
  of the transmission function between {\bf TS.TBT.Emin} and {\bf
    TS.TBT.Emax}.  \index{TS.TBT.NPoints@{\bf TS.TBT.NPoints}}

{\it Default value:} {\tt 100}
\end{description}
Note that it is important to specify the voltage, since this
information is not stored in the .TSHS files. The current will be
computed using the resulting transmission function, so be sure to make
it suited for the integration in the bias window (the energy window
defined by {\bf TS.TBT.Emin} and {\bf TS.TBT.Emax} being bigger than
or equal to the applied bias).

The k-point sampling is defined by the {\bf kgrid\_Monkhorst\_Pack}
block. The averaged (over k-points) transmission function is printed
in the file {\tt <SystemLabel>.AVTRANS}.

The present version of the code is only parallelized over 
k-points, so the number of nodes should not be bigger than 
the number of k-points.

An additional options is:
\begin{description}
 \item [{\bf TS.TBT.NEigen}]({\it integer}): Number of eigenvalues of
   the transmission matrix to be computed.  \index{TS.TBT.NEigen@{\bf
       TS.TBT.NEigen}}

{\it Default value:} {\tt 0}
\end{description}


To summarize, here we give a list of the parameters read by {\tt
  tbtrans} from the input file (the fdf flags):
\begin{itemize}
 \item {\bf TS.Voltage}
 \item {\bf kgrid\_Monkhorst\_Pack} (block)
 \item {\bf TS.HSFileLeft}
 \item {\bf TS.HSFileRight}
 \item {\bf TS.TBT.HSFile}
 \item {\bf TS.TBT.Emin} 
 \item {\bf TS.TBT.Emax} 
 \item {\bf TS.TBT.NPoints}
 \item {\bf TS.TBT.NEigen}
 \item {\bf TS.BufferAtomsLeft}
 \item {\bf TS.BufferAtomsRight}
 \item {\bf TS.NumUsedAtomsLeft}
 \item {\bf TS.NumUsedAtomsRight}
 \item {\bf SpinPolarized}
\end{itemize}

\subsubsection{Compiling TBTtrans}

In the {\tt Util/TBTrans} directory, simply type {\tt make} if your
main {\sc Siesta} compilation directory is the top {\tt Obj}
directory. If you have used another object directory {\tt MyObjDir},
type {\tt make OBJDIR=MyObjDir}.

\section{ANALYSIS TOOLS}

There are a number of analysis tools and programs in the {\tt Util}
directory. Some of them have been directly or indirectly mentioned in
this manual. Their documentation is the appropriate sub-directory of
{\tt Util}. See {\tt Util/README}.

\section{SCRIPTING}

In the {\tt Util/Scripting} directory we provide an experimental
python scripting framework built on top of the 'Atomic Simulation
Environment' (see {\tt https://wiki.fysik.dtu.dk/ase2}) by the Campos
group at DTU, Denmark.

(NOTE: "ASE version 2", not the new version 3, is needed)

There are objects implementing the "Siesta as server/subroutine" feature, and
also hooks for file-oriented-communication usage. This interface is
different from the {\sc Siesta}-specific functionality already
contained in the ASE framework.

Users can create their own scripts to customize the "outer geometry loop"
in Siesta, or to perform various repetitive calculations in compact form.

Note that the interfaces in this framework are still evolving and are
subject to change.

Suggestions for improvements can be sent to Alberto Garcia
(albertog@icmab.es)

\section{PROBLEM HANDLING}

\subsection{Error and warning messages}

\begin{description}
\itemsep 10pt
\parsep 0pt

\item[{\tt chkdim: ERROR: In {\it routine} dimension {\it parameter} =
{\it value}. It must be  ...}]

And other similar messages.

{\it Description:} Some array dimensions which change infrequently,
and do not lead to much memory use, are fixed to oversized
values. This message means that one of this parameters is too small
and neads to be increased.  However, if this occurs and your system is
not very large, or unusual in some sense, you should suspect first of
a mistake in the data file (incorrect atomic positions or cell
dimensions, too large cutoff radii, etc).

{\it Fix:} Check again the data file.  Look for previous warnings or
suspicious values in the output.  If you find nothing unusual, edit
the specified routine and change the corresponding parameter.  

\end{description}



\subsection{Known but unsolved problems and bugs}

\begin{itemize}

\item
Input (fdf) files with CRLF line endings (the DOS standard) are not
correctly read by {\sc Siesta} on Unix machines.

{\it Solution:} Please convert to the normal LF-terminated form. This
is easy, running for example: {\tt \$ dos2unix} {\it yourinput.}{\tt
fdf}

\item
$k$-points are not properly generated ({\tt kgrid}) if using a
{\bf SuperCell} block with a non-diagonal matrix.

{\it Solution:} Make an empty run with {\bf SuperCell} first to generate
the whole geometry, and then run for the large unit cell (without the
{\bf SuperCell}) with $k$-points at will.

\item
For some systems the program stops with the error message

{\tt "Failure to converge standard eigenproblem
Stopping Program from Node:    0}

It is related to the use of the Divide \& Conquer algorithm for
diagonalisation.

{\it Solution:} If it happens, disable Diag.DivideAndConquer and run again.

\end{itemize}

\section{REPORTING BUGS}
\index{bug reports} Your assistance is essential to help improve the
program. If you find any problem, or would like to offer a suggestion
for improvement, please follow the instructions in the file {\tt
  Docs/REPORTING\_BUGS}


\section{ACKNOWLEDGMENTS}

We want to acknowledge the use of a small number of routines,
written by other authors, in developing the siesta code.
In most cases, these routines were acquired by now-forgotten
routes, and the reported authorships are based on their headings.
If you detect any incorrect or incomplete attribution, or suspect
that other routines may be due to different authors, please
let us know.

\begin{itemize}
\item
The main nonpublic contribution, that we thank thoroughly, are
modified versions of a number of routines, originally written by {\bf
  A. R.\ Williams} around 1985, for the solution of the radial
Schr\"odinger and Poisson equations in the APW code of Soler and
Williams (PRB {\bf 42}, 9728 (1990)).  Within {\sc Siesta}, they are
kept in files arw.f and periodic\_table.f, and they are used for the
generation of the basis orbitals and the screened pseudopotentials.

\item
Routine pulayx, used for the SCF mixing, was originally written by
{\bf In-Ho Lee} in 1997.

\item
The exchange-correlation routines contained in file xc.f were written
by J.M.Soler in 1996 and 1997, in collaboration with {\bf
  C.\ Balb\'as} and {\bf J. L.\ Martins}.  Routine pzxc (in the same
file), which implements the Perdew-Zunger LDA parametrization of xc,
is based on routine velect, written by {\bf S.\ Froyen}.

\item
A small number of routines are modified versions of those from {\em
  Numerical Recipes. The Art of Scientific Computing} by {\bf
  W. H.\ Press, S. A.\ Teukolsky, W. T.\ Veterling and
  B. P.\ Flannery} (Cambridge U.P. 1987-1992), and are kept in file
recipes.f

\item
Some standard linear-algebra routines from the {\bf EISPACK}, {\bf
  BLAS}, and {\bf LAPACK}  packages are in files eispack.F, and in
several files in Libs.

\item
The serial version of the multivariate fast fourier transform used to
solve Poisson's equation was written by {\bf R. C. Singleton} in 1968.

\item
Subroutine iomd.f for writing MD history in files was originally
written by {\bf J. Kohanoff}.
\end{itemize}

We want to thank very specially {\bf O. F.\ Sankey, D. J.\ Niklewski}
and {\bf D. A.\ Drabold} for making the FIREBALL code available to
P.\ Ordej\'on.  Although we no longer use the routines in that code,
it was essential in the initial development of the {\sc Siesta}
project, which still uses many of the algorithms developed by them.

We thank {\bf V. Heine} for his supporting and encouraging us in this
project.

The {\sc Siesta} project is supported by the Spanish DGES through
several contracts. We also acknowledge past support by the Fundaci\'on
Ram\'on Areces.



\section{APPENDIX: Physical unit names recognized by FDF}

\begin{center}
\begin{tabular}{llr}
Magnitude & Unit name & MKS value \\
\hline
mass     & Kg         & 1.E0 \\
mass     & g          & 1.E-3 \\
mass     & amu        & 1.66054E-27 \\
length   & m          & 1.E0 \\
length   & cm         & 1.E-2 \\
length   & nm         & 1.E-9 \\
length   & Ang        & 1.E-10 \\
length   & Bohr       & 0.529177E-10 \\
time     & s          & 1.E0 \\
time     & fs         & 1.E-15 \\
time     & ps         & 1.E-12 \\
time     & ns         & 1.E-9 \\
time     & mins       & 60.E0 \\
time     & hours      & 3.6E3 \\
time     & days       & 8.64E4 \\
energy   & J          & 1.E0 \\
energy   & erg        & 1.E-7 \\
energy   & eV         & 1.60219E-19 \\
energy   & meV        & 1.60219E-22 \\
energy   & Ry         & 2.17991E-18 \\
energy   & mRy        & 2.17991E-21 \\
energy   & Hartree    & 4.35982E-18 \\
energy   & K          & 1.38066E-23 \\
energy   & kcal/mol   & 6.94780E-21 \\
energy   & mHartree   & 4.35982E-21 \\
energy   & kJ/mol     & 1.6606E-21 \\
energy   & Hz         & 6.6262E-34 \\
energy   & THz        & 6.6262E-22 \\
energy   & cm-1       & 1.986E-23 \\
energy   & cm**-1     & 1.986E-23 \\
energy   & cm\^~-1      & 1.986E-23 \\
force    & N          & 1.E0 \\
force    & eV/Ang     & 1.60219E-9 \\
force    & Ry/Bohr    & 4.11943E-8 \\
\hline
\end{tabular}

\begin{tabular}{llr}
Magnitude & Unit name & MKS value \\
\hline
pressure & Pa         & 1.E0 \\
pressure & MPa        & 1.E6 \\
pressure & GPa        & 1.E9 \\
pressure & atm        & 1.01325E5 \\
pressure & bar        & 1.E5 \\
pressure & Kbar       & 1.E8 \\
pressure & Mbar       & 1.E11 \\
pressure & Ry/Bohr**3 & 1.47108E13 \\
pressure & eV/Ang**3  & 1.60219E11 \\
charge   & C          & 1.E0 \\
charge   & e          & 1.602177E-19 \\
dipole   & C*m        & 1.E0 \\
dipole   & D          & 3.33564E-30 \\
dipole   & debye      & 3.33564E-30 \\
dipole   & e*Bohr     & 8.47835E-30 \\
dipole   & e*Ang      & 1.602177E-29 \\
MomInert & Kg*m**2    & 1.E0 \\
MomInert & Ry*fs**2   & 2.17991E-48 \\
Efield   & V/m        & 1.E0 \\
Efield   & V/nm       & 1.E9  \\
Efield   & V/Ang      & 1.E10 \\
Efield   & V/Bohr     & 1.8897268E10 \\
Efield   & Ry/Bohr/e  & 2.5711273E11 \\
Efield   & Har/Bohr/e & 5.1422546E11 \\
angle    & deg        & 1.d0 \\
angle    & rad        & 5.72957795E1 \\
torque   & eV/deg     & 1.E0 \\
torque   & eV/rad     & 1.745533E-2 \\
torque   & Ry/deg     & 13.6058E0 \\
torque   & Ry/rad     & 0.237466E0 \\
torque   & meV/deg    & 1.E-3 \\
torque   & meV/rad    & 1.745533E-5 \\
torque   & mRy/deg    & 13.6058E-3 \\
torque   & mRy/rad    & 0.237466E-3 \\
\hline
\end{tabular}
\end{center}

\newpage
\section{APPENDIX: NetCDF}
\index{NetCDF format}
>From the NetCDF User's Guide:

\begin{quotation}
   The purpose of the Network Common Data Form (netCDF) interface is to
   allow you to create, access, and share array-oriented data in a form
   that is self-describing and portable. "Self-describing" means that a
   dataset includes information defining the data it contains. "Portable"
   means that the data in a dataset is represented in a form that can be
   accessed by computers with different ways of storing integers,
   characters, and floating-point numbers. Using the netCDF interface for
   creating new datasets makes the data portable. Using the netCDF
   interface in software for data access, management, analysis, and
   display can make the software more generally useful.

   [...]

   NetCDF is an abstraction that supports a view of data as a collection
   of self-describing, portable objects that can be accessed through a
   simple interface. Array values may be accessed directly, without
   knowing details of how the data are stored. Auxiliary information
   about the data, such as what units are used, may be stored with the
   data. Generic utilities and application programs can access netCDF
   datasets and transform, combine, analyze, or display specified fields
   of the data. The development of such applications may lead to improved
   accessibility of data and improved reusability of software for
   array-oriented data management, analysis, and display.

\end{quotation}

In the context of electronic structure calculations, such an interface
is useful to share pseudopotential, wavefunction, and other
files among different computers, regardless of their native floating
point format or their endian-ness. At present, some degree of
transportability can be achieved by using ascii-binary converters.
However, the other major advantage of the
NetCDF format, the self-description of the data and the ease of
accessibility is of great interest also.

\begin{quotation}
   A netCDF dataset contains dimensions, variables, and attributes, which
   all have both a name and an ID number by which they are identified.
   These components can be used together to capture the meaning of data
   and relations among data fields in an array-oriented dataset. The
   netCDF library allows simultaneous access to multiple netCDF datasets
   which are identified by dataset ID numbers, in addition to ordinary
   file names.
\end{quotation}

\index{NetCDF library}
To be able to generate NetCDF files in {\sc Siesta}, the public domain
NetCDF library (V. 3.6.12 or higher recommended) must be installed. It can be
downloaded from

{\tt http://www.unidata.ucar.edu/software/netcdf/}.

In the {\tt arch.make} file, the following information must exist:
\begin{verbatim}
NETCDF_LIBS=-L/path/to/netcdf/library/directory -lnetcdf
NETCDF_INCLUDE=-I/path/to/netcdf/include/directory
DEFS_CDF=-DCDF
\end{verbatim}
{\tt \$(NETCDF\_LIBS)} must be added to the {\tt LIBS} list and
{\tt \$(NETCDF\_INCLUDE)} must be added to the {\tt INCFLAGS} list (or
{\tt INCFLAGS} may be set directly). See examples in the Src/Sys
directory, and {\tt Src/Sys/DOCUMENTED-TEMPLATE.make}.


({\sc Siesta} used to include an old f90 interface to NetCDF in the
Src/NetCDF directory. Current versions of NetCDF now come with their
own, so that directory has dissappeared.

While it might seem a hassle to install the library, the added
functionality is significant: speedup in diagonalization with k-points
by storing the eigenvectors, optional restarts with charge density
information instead of a density-matrix,  new analysis tools, etc.


\newpage
\section{APPENDIX: Parallel {\sc Siesta}}
\index{Parallel {\sc Siesta}}
\label{sec:parallel}

At present, {\sc Siesta} has been parallelised with moderate system sizes
in mind and is suitable for comensurately moderate parallel computing
systems of the type most widely available. A version suitable for
massively parallel systems in order to tackle grand challenge problems
will hopefully be available in the future.

Apart from the possibility of faster real time performance, there is
another major driving force for the use of the parallel version. All
significant parts of the code have been written using a distributed
data strategy over the Nodes. This means that the use of a parallel
machine can allow access to a larger amount of physical memory.

Given the targets for the present version, the strategy for parallelism
does not employ spatial decomposition since this is only beneficial for
very large problem sizes. Hence the work is divided in 2 ways depending
on the section of the code :

\begin{itemize}
\item
For operations that are orbital based, a 1-D block cyclic distribution
has been used to divide the work over processors. This is controlled
by the parameter {\bf BlockSize}.\index{BlockSize@{\bf Blocksize}}
For optimal performance, this parameter
should be adjusted according to the size of problem and the machine
being used. Very small and very large values tend to be inefficient
and typically values in the range 8 - 32 tend to be optimal. Parts of
the code that parallelise in this way are, evaluation of the kinetic
energy, the non-local pseudopotential contribution, determination of
the overlap integrals and matrix diagonalisation/order N. Note that
for matrix diagonalisation, the default option is now to transform the
Hamiltonian and Overlap matrices into a 2-D blocked distribution since
this gives better scaling within Scalapack. The 1-D block cyclic
data distribution can be maintained by setting the option {\bf Diag.Use2D}
to false.

\item
For operations that are grid based, a 2-D block cyclic distribution
over mesh points has been used to divide the work. The mesh is divided
in the Y and Z directions, but not currently in the X direction. How
the mesh points are divided is controlled by the {\bf ProcessorY}
\index{ProcessorY@{\bf ProcessorY}}
option which must be a factor of the total number of processors.
Performance will be optimal when the load is balanced evenly
over all processors. For dense bulk materials this is straightforward
to achieve. For surfaces, where there is a region of vacuum, it is
worth ensuring that the mesh is divided so as to ensure that some
processors do not have just vacuum regions. Parts of the code that
parallelise in this way are anything connected to the mesh (i.e. within
DHSCF), including the evaluation of the Hartree and exchange-correlation
energies.
\end{itemize}

There is also a second mode in which the parallel version can be used. For
systems where the number of K points is very large and the size of the
Hamiltonian/Overlap matrices is small, then the work can be parallelised
over K points. This is far more efficient in the diagonalisation step
since this phase becomes embarrassingly parallel once the matrices have
been distributed to each Node. This mode is selected using the
{\bf ParallelOverK} \index{ParallelOverk@{\bf ParallelOverK}}
option.

The order-N facility of {\sc Siesta} was rewritten as of version 2.0
to parallelise over spatial regions with a domain decomposition. In the
ideal situation, each domain interacts with only the neighbouring domains
if the size of the domains is greater than the Wannier function radius and
the range of matrix elements in the Hamiltonian. In order to achieve load
balance, it may be advantageous to use smaller domain sizes. The domain
size can be controlled through the {\bf RcSpatial} option.

(A new option for domain decomposition, based on an abstract
partitioning of the interaction graph associated to the Hamiltonian,
has been added as of version 3.1.)

In the current implementation of the domain decomposition parallelisation,
both the local elements of the orbital coefficients in the Wannier functions
and those connected via the transpose are locally stored on each node in order
to minimise communication. However, this leads to greater demands on the memory
and works best when the system size to processor ratio is high. Work is in
progress to offer a modified algorithm with higher communication, but lower
memory demands.

In order to use the parallel version of the code you must have the following
libraries installed on your computer :

\begin{verbatim}

(a) MPI :       The Message Passing Interface library - this allows the
                processors to communicate. Most machine vendors have their
                own implementations available for their own platforms.
                However, there are two freely available versions that can
                be installed :

                MPICH :

                  http://www-unix.mcs.anl.gov/mpi/mpich/

                LAMMPI :

                  http://www.lam-mpi.org/

(b) Blacs :     This is a communications library that runs on top of MPI. Again
                if can be obtained for free from :

                  http://www.netlib.org/

                Both source code and pre-compiled binaries are available.

(c) Scalapack : This is a parallel library for dense linear algebra, equivalent
                to "lapack" but for parallel systems. Once again this is freely
                available as source code or in precompiled form from :

                  http://www.netlib.org/

\end{verbatim}

\noindent
Parallel versions of the files for {\tt arch.make} suitable for a
number of systems are provided in the {\tt Src/Sys} directory. Should
there be no suitable file there for your system, then the following
are the key variables to be set in the {\tt arch.make} file (see also
the commented {\tt arch.make} file in {\tt Src/Sys/DOCUMENTED-TEMPLATE.make}):

\begin{verbatim}
MPI_INTERFACE=libmpi_f90.a
MPI_INCLUDE=/usr/local/include
DEFS_MPI=-DMPI
#
LIBS= -lscalapack -lblacs -lmpi
\end{verbatim}

Here {\tt MPI\_INTERFACE} indicates that the interface to MPI provided
should be used which handles the issue of the variable type being
passed. This will be needed in nearly all cases. {\tt MPI\_INCLUDE}
indicates the directory where the header file "mpif.h" can be found on
the present machine. The environment variable {\tt DEFS\_MPI} should always
be set to {\tt "-DMPI"}, since this causes the preprocessor to include the
parallel code in the source. Finally {\tt LIBS} must now include all the
libraries required - namely Scalapack, Blacs and MPI, in addition to
any machine optimised Blas, etc.

To execute the parallel version, on most machine, the command will now
be of the form :

{\tt mpirun -np <nproc> siesta < input.fdf > output}

Where {\tt <nproc>} is the desired number of processors, {\tt
input.fdf} is the {\sc Siesta} input file and {\tt output} is the name
of the output file.

Finally, a word concerning performance of parallel execution. This is
a very variable quantity and depends on the exact system you are using
since it will vary according to the latency and bandwidth of the
communication mechanism.  This is a function of the means by which the
processors are physically connected and by software factors relating
to the implementation of MPI. The one almost universal truth is that,
for significant system sizes, parallel diagonalisation becomes
the bottleneck and the place where efficiency is most readily
lost. This is basically just the nature of diagonalisation, but it is
always worth tuning the BlockSize parameter.

\newpage
\section{APPENDIX: File Formats}

The file formats in Siesta are in a state of flux. On the one hand,
some of the legacy formats were inefficient or incomplete, so new ones
have been devised, and appropriate translators provided when
necessary.  Examples are the WFS (WFSX) wavefunction file, and the HS
(HSX) Hamiltonian-and-overlap file. On the other hand, we are
introducing new files in netCDF format which facilitate the exchange
of information among different computers and offer new functionality
in Siesta. Examples are the DM.nc and the .Grid.nc files.

Here we provide an overview of some of the most important files and their
associated tools.

\begin{itemize}
\item{Density matrix}

DM

Traditional Density Matrix (DM) file. The DM is written by default at
the end of each SCF step, {\em after mixing}, so it can be directly used
in a restart. It is a binary file.

DM.nc

DM in netCDF format. It contains the same information as DM, plus the
number of orbitals in the auxiliary supercell and the array {\tt indxuo}
which maps the orbitals in the supercell to the unit cell.  If the history
option is used, this file will store all the DMs in an SCF cycle.

DMHS.nc

DMin, DMout, Hamiltonian, and Overlap matrix in netCDF format. If the
appropriate fdf history option is used, this file will store the
corresponding information for all the steps in an SCF cycle.

Associated tools:

\begin{verbatim}
Util/DensityMatrix:  cdf2dm, dm2cdf: DM <--> DM.nc conversion
                     experimental octave/matlab scripts to process DM .nc files
Util/SCF:            experimental python scripts to process DM .nc files
\end{verbatim}

\item{Hamiltonian and overlap matrices}

HS

The old format, very inefficient in terms of space used. It contains
(if produced by a calculation using k-points) also the $x_ij$ array
and information about the atomic species and orbitals. As of
{\tt siesta-3.0-rc2}, it has been superseded by the HSX format. If some
legacy utility needs the HS format, it can be re-generated using
the tools in {\tt Util/HSX}.

HSX

The new format, with better packing of binary records.

DMHS

See above

\item{Wavefunctions}

WFS

Old format, now superseded by WFSX.

WFSX

New format, without redundant information, and in single precision.

WFS.nc

A netCDF file to store the eigenvectors (in routine diagk\_file) as they
are computed, thus saving a second round of diagonalization after the
calculation of the Fermi level.

Associated tools:
\begin{verbatim}
Util/WFS: readwfx, wfsnc2wfsx, readwf,  wfs2wfsx, wfsx2wfs
\end{verbatim}

\item{Grid magnitudes}

RHO, VT, DRHO, VH...

These are binary files, read directly by (for example) Andrei
Postnikov's utilities.

...Grid.nc

netCDF files which can be directly processed by a number of programs
and scripts.  The Rho.Grid.nc and DeltaRho.Grid.nc files can also be
read by Siesta to start a new SCF cycle.

Associated tools:

\begin{verbatim}
Util/Grid:

 Operating on old-style files: grid2val, grid2cube, grid2cdf
 Operating on netCDF files:    average_x.m	cdf2xsf,
                               average_z.m  cdf_diff, cdf2grid, cdf_fft

Util/Contrib/APostnikov:       rho2xsf, etc.

\end{verbatim}
\end{itemize}

\newpage
\section{APPENDIX: XML Output}
\index{XML}
\index{CML}

>From version 2.0, {\sc Siesta} includes an option to write its output to an
XML file. The XML it produces is in accordance with the CMLComp subset of
version 2.2 of the Chemical Markup Language. Further information
and resources can be found at \url{http://cmlcomp.org/} and tools for working
with the XML file can be found in the \texttt{Util/CMLComp} directory.

As of June 2009, the engine for CML output production is a subset of
the FoX library\index{FoX XML library} (see {\tt
  http://www.uszla.me.uk/FoX}).

The main motivation for standarised XML (CML) output is as a step
towards standarising formats for uses like the following.

\begin{itemize}

\item To have {\sc Siesta} communicating with other software, either
for postprocessing or as part of a larger workflow scheme. In such a
scenario, the XML output of one {\sc Siesta} simulation may be easily parsed
in order to direct further simulations. Detailed discussion of this is
out of the scope of this manual.

\item To generate webpages showing {\sc Siesta} output in a more accessible,
graphically rich, fashion. This section will explain how to do this.

\end{itemize}

\subsection{Controlling XML output}

\begin{description}
\itemsep 10pt
\parsep 0pt


\item[{\bf XML.Write}] ({\it logical}): 
\index{XML.Write@{\bf XML.Write}} 
Determine if the main XML file should be created for this run.

{\it Default value:} {\tt true}

\item[{\bf XML.AbortOnErrors}] ({\it logical}): 
\index{XML.AbortOnErrors@{\bf XML.AbortOnErrors}} 
This controls the behaviour of the XML output library when it detects 
internal errors or erroneous use of the API and is intended to aid debugging.
When this option is false, the library will emit a diagnostic message to 
standard error before stopping execution with a Fortran stop statement.
When this option is true, the message is generated but execution will be 
terminated by generating a runtime exception leading to an abort signal. 
Depending on the execution environment and compiler options, this can lead 
to the generation of a core file or stack trace. 

{\it Default value:} {\tt false}

\item[{\bf XML.AbortOnWarnings}] ({\it logical}): 
\index{XML.AbortOnWarnings@{\bf XML.AbortOnWarnings}} 
This controls the behaviour of the XML output library when it detects 
minor errors and is intended to aid debugging.  When this option is false,
the library will emit a diagnostic message to standard error before 
continuing execution. When this option is true, the message is generated 
but execution will also be terminated by generating a runtime exception 
leading to an abort signal. Depending on the execution environment and 
compiler options, this can lead to the generation of a core file or 
stack trace.

{\it Default value:} {\tt false}

\end{description}

\subsection{Converting XML to XHTML}

The translation of the {\sc Siesta} XML output to a HTML-based webpage is
done using XSLT technology. The stylesheets conform to XSLT-1.0 plus
EXSLT extensions; an xslt processor capable of dealing with this is
necessary. However, in order to make the system easy to use, a script
called ccViz is provided in \texttt{Util/CMLComp} that works on most Unix or
Mac OS X systems. It is run like so:

\texttt{./ccViz SystemLabel.xml}

A new file will be produced. Point your web-browser at \texttt{SystemLabel.xhtml}
to view the output.

The generated webpages include support for viewing three-dimensional
interactive images of the system. If you want to do this, you will
either need jMol (\url{http://jmol.sourceforge.net}) installed or access
to the internet. As this
is a Java applet, you will also need a working Java Runtime
Environment and browser plugin - installation instructions for these
are outside the scope of this manual, though. However, the webpages
are still useful and may be viewed without this plugin.

An online version of this tool is avalable from
\url{http://cmlcomp.org/ccViz/}, as are updated versions of
the ccViz script.

\newpage
\section{APPENDIX: Selection of precision for storage}
\index{Precision selection}

Some of the real arrays used in Siesta are by default
single-precision, to save memory. This applies to the grid-related
magnitudes, and to the historical data sets in Broyden mixing. 
Unless you have memory problems running Siesta, we recommend that 
the defaults are changed by using pre-processing symbols at compile
time:

\begin{itemize}
\item Add {\tt -DGRID\_DP} to the {\tt DEFS} variable in {\tt
  arch.make} to use double-precision arrays on the grid (but
  consider using also {\tt -DPHI\_GRID\_SP} to safely keep a large orbital-values
  array in single precision.)

\item Add {\tt -DBROYDEN\_DP} to the {\tt DEFS} variable in {\tt
  arch.make} to use double-precision arrays for the Broyden historical
  data sets. (Remember that the Broyden mixing for SCF convergence
  acceleration is an experimental feature.)\index{Broyden mixing}
\end{itemize}

\addcontentsline{toc}{section}{Index}
\printindex

\end{document}

